# -*- coding: utf-8 -*-
# (C) Copyright IBM Corp. 2025.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Unit Tests for WatsonxDataV2
"""

from ibm_cloud_sdk_core.authenticators.no_auth_authenticator import NoAuthAuthenticator
from ibm_cloud_sdk_core.utils import date_to_string, string_to_date
import inspect
import io
import json
import os
import pytest
import re
import requests
import responses
import tempfile
import urllib
from ibm_watsonxdata.watsonx_data_v2 import *


_service = WatsonxDataV2(
    authenticator=NoAuthAuthenticator()
)

_base_url = 'https://region.lakehouse.cloud.ibm.com/lakehouse/api/v2'
_service.set_service_url(_base_url)


def preprocess_url(operation_path: str):
    """
    Returns the request url associated with the specified operation path.
    This will be base_url concatenated with a quoted version of operation_path.
    The returned request URL is used to register the mock response so it needs
    to match the request URL that is formed by the requests library.
    """

    # Form the request URL from the base URL and operation path.
    request_url = _base_url + operation_path

    # If the request url does NOT end with a /, then just return it as-is.
    # Otherwise, return a regular expression that matches one or more trailing /.
    if not request_url.endswith('/'):
        return request_url
    return re.compile(request_url.rstrip('/') + '/+')


##############################################################################
# Start of Service: Buckets
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListBucketRegistrations:
    """
    Test Class for list_bucket_registrations
    """

    @responses.activate
    def test_list_bucket_registrations_all_params(self):
        """
        list_bucket_registrations()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations')
        mock_response = '{"bucket_registrations": [{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_bucket_registrations(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_bucket_registrations_all_params_with_retries(self):
        # Enable retries and run test_list_bucket_registrations_all_params.
        _service.enable_retries()
        self.test_list_bucket_registrations_all_params()

        # Disable retries and run test_list_bucket_registrations_all_params.
        _service.disable_retries()
        self.test_list_bucket_registrations_all_params()

    @responses.activate
    def test_list_bucket_registrations_required_params(self):
        """
        test_list_bucket_registrations_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations')
        mock_response = '{"bucket_registrations": [{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_bucket_registrations()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_bucket_registrations_required_params_with_retries(self):
        # Enable retries and run test_list_bucket_registrations_required_params.
        _service.enable_retries()
        self.test_list_bucket_registrations_required_params()

        # Disable retries and run test_list_bucket_registrations_required_params.
        _service.disable_retries()
        self.test_list_bucket_registrations_required_params()


class TestCreateBucketRegistration:
    """
    Test Class for create_bucket_registration
    """

    @responses.activate
    def test_create_bucket_registration_all_params(self):
        """
        create_bucket_registration()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a BucketCatalog model
        bucket_catalog_model = {}
        bucket_catalog_model['catalog_name'] = 'sampleCatalog'
        bucket_catalog_model['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        bucket_catalog_model['catalog_type'] = 'iceberg'

        # Construct a dict representation of a BucketDetails model
        bucket_details_model = {}
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a dict representation of a StorageDetails model
        storage_details_model = {}
        storage_details_model['access_key'] = '<access_key>'
        storage_details_model['application_id'] = '<application_id>'
        storage_details_model['auth_mode'] = '<account_key/sas/service_principle>'
        storage_details_model['container_name'] = 'sample-container'
        storage_details_model['directory_id'] = '<directory_id>'
        storage_details_model['endpoint'] = 'abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/'
        storage_details_model['sas_token'] = '<sas_token>'
        storage_details_model['secret_key'] = 'secret_key'
        storage_details_model['storage_account_name'] = 'sample-storage'

        # Set up parameter values
        bucket_display_name = 'sample-bucket-displayname'
        bucket_type = 'ibm_cos'
        description = 'COS bucket for customer data'
        managed_by = 'ibm'
        associated_catalog = bucket_catalog_model
        bucket_details = bucket_details_model
        region = 'us-south'
        storage_details = storage_details_model
        tags = ['bucket-tag1', 'bucket-tag2']
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_bucket_registration(
            bucket_display_name,
            bucket_type,
            description,
            managed_by,
            associated_catalog=associated_catalog,
            bucket_details=bucket_details,
            region=region,
            storage_details=storage_details,
            tags=tags,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['bucket_display_name'] == 'sample-bucket-displayname'
        assert req_body['bucket_type'] == 'ibm_cos'
        assert req_body['description'] == 'COS bucket for customer data'
        assert req_body['managed_by'] == 'ibm'
        assert req_body['associated_catalog'] == bucket_catalog_model
        assert req_body['bucket_details'] == bucket_details_model
        assert req_body['region'] == 'us-south'
        assert req_body['storage_details'] == storage_details_model
        assert req_body['tags'] == ['bucket-tag1', 'bucket-tag2']

    def test_create_bucket_registration_all_params_with_retries(self):
        # Enable retries and run test_create_bucket_registration_all_params.
        _service.enable_retries()
        self.test_create_bucket_registration_all_params()

        # Disable retries and run test_create_bucket_registration_all_params.
        _service.disable_retries()
        self.test_create_bucket_registration_all_params()

    @responses.activate
    def test_create_bucket_registration_required_params(self):
        """
        test_create_bucket_registration_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a BucketCatalog model
        bucket_catalog_model = {}
        bucket_catalog_model['catalog_name'] = 'sampleCatalog'
        bucket_catalog_model['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        bucket_catalog_model['catalog_type'] = 'iceberg'

        # Construct a dict representation of a BucketDetails model
        bucket_details_model = {}
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a dict representation of a StorageDetails model
        storage_details_model = {}
        storage_details_model['access_key'] = '<access_key>'
        storage_details_model['application_id'] = '<application_id>'
        storage_details_model['auth_mode'] = '<account_key/sas/service_principle>'
        storage_details_model['container_name'] = 'sample-container'
        storage_details_model['directory_id'] = '<directory_id>'
        storage_details_model['endpoint'] = 'abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/'
        storage_details_model['sas_token'] = '<sas_token>'
        storage_details_model['secret_key'] = 'secret_key'
        storage_details_model['storage_account_name'] = 'sample-storage'

        # Set up parameter values
        bucket_display_name = 'sample-bucket-displayname'
        bucket_type = 'ibm_cos'
        description = 'COS bucket for customer data'
        managed_by = 'ibm'
        associated_catalog = bucket_catalog_model
        bucket_details = bucket_details_model
        region = 'us-south'
        storage_details = storage_details_model
        tags = ['bucket-tag1', 'bucket-tag2']

        # Invoke method
        response = _service.create_bucket_registration(
            bucket_display_name,
            bucket_type,
            description,
            managed_by,
            associated_catalog=associated_catalog,
            bucket_details=bucket_details,
            region=region,
            storage_details=storage_details,
            tags=tags,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['bucket_display_name'] == 'sample-bucket-displayname'
        assert req_body['bucket_type'] == 'ibm_cos'
        assert req_body['description'] == 'COS bucket for customer data'
        assert req_body['managed_by'] == 'ibm'
        assert req_body['associated_catalog'] == bucket_catalog_model
        assert req_body['bucket_details'] == bucket_details_model
        assert req_body['region'] == 'us-south'
        assert req_body['storage_details'] == storage_details_model
        assert req_body['tags'] == ['bucket-tag1', 'bucket-tag2']

    def test_create_bucket_registration_required_params_with_retries(self):
        # Enable retries and run test_create_bucket_registration_required_params.
        _service.enable_retries()
        self.test_create_bucket_registration_required_params()

        # Disable retries and run test_create_bucket_registration_required_params.
        _service.disable_retries()
        self.test_create_bucket_registration_required_params()

    @responses.activate
    def test_create_bucket_registration_value_error(self):
        """
        test_create_bucket_registration_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a BucketCatalog model
        bucket_catalog_model = {}
        bucket_catalog_model['catalog_name'] = 'sampleCatalog'
        bucket_catalog_model['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        bucket_catalog_model['catalog_type'] = 'iceberg'

        # Construct a dict representation of a BucketDetails model
        bucket_details_model = {}
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a dict representation of a StorageDetails model
        storage_details_model = {}
        storage_details_model['access_key'] = '<access_key>'
        storage_details_model['application_id'] = '<application_id>'
        storage_details_model['auth_mode'] = '<account_key/sas/service_principle>'
        storage_details_model['container_name'] = 'sample-container'
        storage_details_model['directory_id'] = '<directory_id>'
        storage_details_model['endpoint'] = 'abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/'
        storage_details_model['sas_token'] = '<sas_token>'
        storage_details_model['secret_key'] = 'secret_key'
        storage_details_model['storage_account_name'] = 'sample-storage'

        # Set up parameter values
        bucket_display_name = 'sample-bucket-displayname'
        bucket_type = 'ibm_cos'
        description = 'COS bucket for customer data'
        managed_by = 'ibm'
        associated_catalog = bucket_catalog_model
        bucket_details = bucket_details_model
        region = 'us-south'
        storage_details = storage_details_model
        tags = ['bucket-tag1', 'bucket-tag2']

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_display_name": bucket_display_name,
            "bucket_type": bucket_type,
            "description": description,
            "managed_by": managed_by,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_bucket_registration(**req_copy)

    def test_create_bucket_registration_value_error_with_retries(self):
        # Enable retries and run test_create_bucket_registration_value_error.
        _service.enable_retries()
        self.test_create_bucket_registration_value_error()

        # Disable retries and run test_create_bucket_registration_value_error.
        _service.disable_retries()
        self.test_create_bucket_registration_value_error()


class TestGetBucketRegistration:
    """
    Test Class for get_bucket_registration
    """

    @responses.activate
    def test_get_bucket_registration_all_params(self):
        """
        get_bucket_registration()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_bucket_registration(
            bucket_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_bucket_registration_all_params_with_retries(self):
        # Enable retries and run test_get_bucket_registration_all_params.
        _service.enable_retries()
        self.test_get_bucket_registration_all_params()

        # Disable retries and run test_get_bucket_registration_all_params.
        _service.disable_retries()
        self.test_get_bucket_registration_all_params()

    @responses.activate
    def test_get_bucket_registration_required_params(self):
        """
        test_get_bucket_registration_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Invoke method
        response = _service.get_bucket_registration(
            bucket_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_bucket_registration_required_params_with_retries(self):
        # Enable retries and run test_get_bucket_registration_required_params.
        _service.enable_retries()
        self.test_get_bucket_registration_required_params()

        # Disable retries and run test_get_bucket_registration_required_params.
        _service.disable_retries()
        self.test_get_bucket_registration_required_params()

    @responses.activate
    def test_get_bucket_registration_value_error(self):
        """
        test_get_bucket_registration_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_bucket_registration(**req_copy)

    def test_get_bucket_registration_value_error_with_retries(self):
        # Enable retries and run test_get_bucket_registration_value_error.
        _service.enable_retries()
        self.test_get_bucket_registration_value_error()

        # Disable retries and run test_get_bucket_registration_value_error.
        _service.disable_retries()
        self.test_get_bucket_registration_value_error()


class TestDeleteBucketRegistration:
    """
    Test Class for delete_bucket_registration
    """

    @responses.activate
    def test_delete_bucket_registration_all_params(self):
        """
        delete_bucket_registration()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        bucket_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_bucket_registration(
            bucket_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_bucket_registration_all_params_with_retries(self):
        # Enable retries and run test_delete_bucket_registration_all_params.
        _service.enable_retries()
        self.test_delete_bucket_registration_all_params()

        # Disable retries and run test_delete_bucket_registration_all_params.
        _service.disable_retries()
        self.test_delete_bucket_registration_all_params()

    @responses.activate
    def test_delete_bucket_registration_required_params(self):
        """
        test_delete_bucket_registration_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Invoke method
        response = _service.delete_bucket_registration(
            bucket_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_bucket_registration_required_params_with_retries(self):
        # Enable retries and run test_delete_bucket_registration_required_params.
        _service.enable_retries()
        self.test_delete_bucket_registration_required_params()

        # Disable retries and run test_delete_bucket_registration_required_params.
        _service.disable_retries()
        self.test_delete_bucket_registration_required_params()

    @responses.activate
    def test_delete_bucket_registration_value_error(self):
        """
        test_delete_bucket_registration_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_bucket_registration(**req_copy)

    def test_delete_bucket_registration_value_error_with_retries(self):
        # Enable retries and run test_delete_bucket_registration_value_error.
        _service.enable_retries()
        self.test_delete_bucket_registration_value_error()

        # Disable retries and run test_delete_bucket_registration_value_error.
        _service.disable_retries()
        self.test_delete_bucket_registration_value_error()


class TestUpdateBucketRegistration:
    """
    Test Class for update_bucket_registration
    """

    @responses.activate
    def test_update_bucket_registration_all_params(self):
        """
        update_bucket_registration()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a BucketDetails model
        bucket_details_model = {}
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a dict representation of a BucketRegistrationPatch model
        bucket_registration_patch_model = {}
        bucket_registration_patch_model['bucket_details'] = bucket_details_model
        bucket_registration_patch_model['bucket_display_name'] = 'sample-bucket-displayname'
        bucket_registration_patch_model['description'] = 'COS bucket for customer data'
        bucket_registration_patch_model['system_bucket_update_credentials'] = True
        bucket_registration_patch_model['tags'] = ['testbucket', 'userbucket']

        # Set up parameter values
        bucket_id = 'testString'
        body = bucket_registration_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_bucket_registration(
            bucket_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_bucket_registration_all_params_with_retries(self):
        # Enable retries and run test_update_bucket_registration_all_params.
        _service.enable_retries()
        self.test_update_bucket_registration_all_params()

        # Disable retries and run test_update_bucket_registration_all_params.
        _service.disable_retries()
        self.test_update_bucket_registration_all_params()

    @responses.activate
    def test_update_bucket_registration_required_params(self):
        """
        test_update_bucket_registration_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a BucketDetails model
        bucket_details_model = {}
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a dict representation of a BucketRegistrationPatch model
        bucket_registration_patch_model = {}
        bucket_registration_patch_model['bucket_details'] = bucket_details_model
        bucket_registration_patch_model['bucket_display_name'] = 'sample-bucket-displayname'
        bucket_registration_patch_model['description'] = 'COS bucket for customer data'
        bucket_registration_patch_model['system_bucket_update_credentials'] = True
        bucket_registration_patch_model['tags'] = ['testbucket', 'userbucket']

        # Set up parameter values
        bucket_id = 'testString'
        body = bucket_registration_patch_model

        # Invoke method
        response = _service.update_bucket_registration(
            bucket_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_bucket_registration_required_params_with_retries(self):
        # Enable retries and run test_update_bucket_registration_required_params.
        _service.enable_retries()
        self.test_update_bucket_registration_required_params()

        # Disable retries and run test_update_bucket_registration_required_params.
        _service.disable_retries()
        self.test_update_bucket_registration_required_params()

    @responses.activate
    def test_update_bucket_registration_value_error(self):
        """
        test_update_bucket_registration_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_details": {"access_key": "<access_key>", "bucket_name": "sample-bucket", "endpoint": "https://s3.us-south.cloud-object-storage.appdomain.cloud/", "key_file": "key_file", "provider": "ibm-cos", "region": "us-south", "secret_key": "secret_key"}, "bucket_display_name": "sample-bucket-displayname", "bucket_id": "samplebucket123", "bucket_type": "ibm_cos", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "COS bucket for customer data", "managed_by": "ibm", "region": "us-south", "state": "active", "storage_details": {"access_key": "<access_key>", "application_id": "<application_id>", "auth_mode": "<account_key/sas/service_principle>", "container_name": "sample-container", "directory_id": "<directory_id>", "endpoint": "abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/", "sas_token": "<sas_token>", "secret_key": "secret_key", "storage_account_name": "sample-storage"}, "system_bucket_update_credentials": true, "tags": ["tags"]}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a BucketDetails model
        bucket_details_model = {}
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a dict representation of a BucketRegistrationPatch model
        bucket_registration_patch_model = {}
        bucket_registration_patch_model['bucket_details'] = bucket_details_model
        bucket_registration_patch_model['bucket_display_name'] = 'sample-bucket-displayname'
        bucket_registration_patch_model['description'] = 'COS bucket for customer data'
        bucket_registration_patch_model['system_bucket_update_credentials'] = True
        bucket_registration_patch_model['tags'] = ['testbucket', 'userbucket']

        # Set up parameter values
        bucket_id = 'testString'
        body = bucket_registration_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_bucket_registration(**req_copy)

    def test_update_bucket_registration_value_error_with_retries(self):
        # Enable retries and run test_update_bucket_registration_value_error.
        _service.enable_retries()
        self.test_update_bucket_registration_value_error()

        # Disable retries and run test_update_bucket_registration_value_error.
        _service.disable_retries()
        self.test_update_bucket_registration_value_error()


class TestCreateActivateBucket:
    """
    Test Class for create_activate_bucket
    """

    @responses.activate
    def test_create_activate_bucket_all_params(self):
        """
        create_activate_bucket()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/activate')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_activate_bucket(
            bucket_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_activate_bucket_all_params_with_retries(self):
        # Enable retries and run test_create_activate_bucket_all_params.
        _service.enable_retries()
        self.test_create_activate_bucket_all_params()

        # Disable retries and run test_create_activate_bucket_all_params.
        _service.disable_retries()
        self.test_create_activate_bucket_all_params()

    @responses.activate
    def test_create_activate_bucket_required_params(self):
        """
        test_create_activate_bucket_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/activate')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Invoke method
        response = _service.create_activate_bucket(
            bucket_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_activate_bucket_required_params_with_retries(self):
        # Enable retries and run test_create_activate_bucket_required_params.
        _service.enable_retries()
        self.test_create_activate_bucket_required_params()

        # Disable retries and run test_create_activate_bucket_required_params.
        _service.disable_retries()
        self.test_create_activate_bucket_required_params()

    @responses.activate
    def test_create_activate_bucket_value_error(self):
        """
        test_create_activate_bucket_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/activate')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_activate_bucket(**req_copy)

    def test_create_activate_bucket_value_error_with_retries(self):
        # Enable retries and run test_create_activate_bucket_value_error.
        _service.enable_retries()
        self.test_create_activate_bucket_value_error()

        # Disable retries and run test_create_activate_bucket_value_error.
        _service.disable_retries()
        self.test_create_activate_bucket_value_error()


class TestDeleteDeactivateBucket:
    """
    Test Class for delete_deactivate_bucket
    """

    @responses.activate
    def test_delete_deactivate_bucket_all_params(self):
        """
        delete_deactivate_bucket()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/deactivate')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        bucket_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_deactivate_bucket(
            bucket_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_deactivate_bucket_all_params_with_retries(self):
        # Enable retries and run test_delete_deactivate_bucket_all_params.
        _service.enable_retries()
        self.test_delete_deactivate_bucket_all_params()

        # Disable retries and run test_delete_deactivate_bucket_all_params.
        _service.disable_retries()
        self.test_delete_deactivate_bucket_all_params()

    @responses.activate
    def test_delete_deactivate_bucket_required_params(self):
        """
        test_delete_deactivate_bucket_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/deactivate')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Invoke method
        response = _service.delete_deactivate_bucket(
            bucket_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_deactivate_bucket_required_params_with_retries(self):
        # Enable retries and run test_delete_deactivate_bucket_required_params.
        _service.enable_retries()
        self.test_delete_deactivate_bucket_required_params()

        # Disable retries and run test_delete_deactivate_bucket_required_params.
        _service.disable_retries()
        self.test_delete_deactivate_bucket_required_params()

    @responses.activate
    def test_delete_deactivate_bucket_value_error(self):
        """
        test_delete_deactivate_bucket_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/deactivate')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_deactivate_bucket(**req_copy)

    def test_delete_deactivate_bucket_value_error_with_retries(self):
        # Enable retries and run test_delete_deactivate_bucket_value_error.
        _service.enable_retries()
        self.test_delete_deactivate_bucket_value_error()

        # Disable retries and run test_delete_deactivate_bucket_value_error.
        _service.disable_retries()
        self.test_delete_deactivate_bucket_value_error()


class TestListBucketObjects:
    """
    Test Class for list_bucket_objects
    """

    @responses.activate
    def test_list_bucket_objects_all_params(self):
        """
        list_bucket_objects()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/objects')
        mock_response = '{"objects": ["objects"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_id = 'testString'
        auth_instance_id = 'testString'
        path = 'testString'

        # Invoke method
        response = _service.list_bucket_objects(
            bucket_id,
            auth_instance_id=auth_instance_id,
            path=path,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'path={}'.format(path) in query_string

    def test_list_bucket_objects_all_params_with_retries(self):
        # Enable retries and run test_list_bucket_objects_all_params.
        _service.enable_retries()
        self.test_list_bucket_objects_all_params()

        # Disable retries and run test_list_bucket_objects_all_params.
        _service.disable_retries()
        self.test_list_bucket_objects_all_params()

    @responses.activate
    def test_list_bucket_objects_required_params(self):
        """
        test_list_bucket_objects_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/objects')
        mock_response = '{"objects": ["objects"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Invoke method
        response = _service.list_bucket_objects(
            bucket_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_bucket_objects_required_params_with_retries(self):
        # Enable retries and run test_list_bucket_objects_required_params.
        _service.enable_retries()
        self.test_list_bucket_objects_required_params()

        # Disable retries and run test_list_bucket_objects_required_params.
        _service.disable_retries()
        self.test_list_bucket_objects_required_params()

    @responses.activate
    def test_list_bucket_objects_value_error(self):
        """
        test_list_bucket_objects_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/objects')
        mock_response = '{"objects": ["objects"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_bucket_objects(**req_copy)

    def test_list_bucket_objects_value_error_with_retries(self):
        # Enable retries and run test_list_bucket_objects_value_error.
        _service.enable_retries()
        self.test_list_bucket_objects_value_error()

        # Disable retries and run test_list_bucket_objects_value_error.
        _service.disable_retries()
        self.test_list_bucket_objects_value_error()


class TestGetBucketObjectProperties:
    """
    Test Class for get_bucket_object_properties
    """

    @responses.activate
    def test_get_bucket_object_properties_all_params(self):
        """
        get_bucket_object_properties()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/object_properties')
        mock_response = '{"object_properties": [{"content_type": "string", "file_type": "string", "last_modified": "utc-2014-07", "metadata": {"mapKey": "inner"}, "path": "abc/abc/data", "size": "1024"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a BucketObjectSizePathsItems model
        bucket_object_size_paths_items_model = {}
        bucket_object_size_paths_items_model['path'] = 'testString'

        # Set up parameter values
        bucket_id = 'testString'
        paths = [bucket_object_size_paths_items_model]
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_bucket_object_properties(
            bucket_id,
            paths=paths,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['paths'] == [bucket_object_size_paths_items_model]

    def test_get_bucket_object_properties_all_params_with_retries(self):
        # Enable retries and run test_get_bucket_object_properties_all_params.
        _service.enable_retries()
        self.test_get_bucket_object_properties_all_params()

        # Disable retries and run test_get_bucket_object_properties_all_params.
        _service.disable_retries()
        self.test_get_bucket_object_properties_all_params()

    @responses.activate
    def test_get_bucket_object_properties_required_params(self):
        """
        test_get_bucket_object_properties_required_params()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/object_properties')
        mock_response = '{"object_properties": [{"content_type": "string", "file_type": "string", "last_modified": "utc-2014-07", "metadata": {"mapKey": "inner"}, "path": "abc/abc/data", "size": "1024"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a BucketObjectSizePathsItems model
        bucket_object_size_paths_items_model = {}
        bucket_object_size_paths_items_model['path'] = 'testString'

        # Set up parameter values
        bucket_id = 'testString'
        paths = [bucket_object_size_paths_items_model]

        # Invoke method
        response = _service.get_bucket_object_properties(
            bucket_id,
            paths=paths,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['paths'] == [bucket_object_size_paths_items_model]

    def test_get_bucket_object_properties_required_params_with_retries(self):
        # Enable retries and run test_get_bucket_object_properties_required_params.
        _service.enable_retries()
        self.test_get_bucket_object_properties_required_params()

        # Disable retries and run test_get_bucket_object_properties_required_params.
        _service.disable_retries()
        self.test_get_bucket_object_properties_required_params()

    @responses.activate
    def test_get_bucket_object_properties_value_error(self):
        """
        test_get_bucket_object_properties_value_error()
        """
        # Set up mock
        url = preprocess_url('/bucket_registrations/testString/object_properties')
        mock_response = '{"object_properties": [{"content_type": "string", "file_type": "string", "last_modified": "utc-2014-07", "metadata": {"mapKey": "inner"}, "path": "abc/abc/data", "size": "1024"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a BucketObjectSizePathsItems model
        bucket_object_size_paths_items_model = {}
        bucket_object_size_paths_items_model['path'] = 'testString'

        # Set up parameter values
        bucket_id = 'testString'
        paths = [bucket_object_size_paths_items_model]

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_id": bucket_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_bucket_object_properties(**req_copy)

    def test_get_bucket_object_properties_value_error_with_retries(self):
        # Enable retries and run test_get_bucket_object_properties_value_error.
        _service.enable_retries()
        self.test_get_bucket_object_properties_value_error()

        # Disable retries and run test_get_bucket_object_properties_value_error.
        _service.disable_retries()
        self.test_get_bucket_object_properties_value_error()


class TestGenerateBenchmarkReport:
    """
    Test Class for generate_benchmark_report
    """

    @responses.activate
    def test_generate_benchmark_report_all_params(self):
        """
        generate_benchmark_report()
        """
        # Set up mock
        url = preprocess_url('/generate_benchmark_report')
        mock_response = '{"response": {"message": "message", "req_id": "req_id", "status": "status"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_name = 'testString'
        engine_id = 'testString'
        pod_name = 'testString'
        file_count = 'testString'
        file_size = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.generate_benchmark_report(
            bucket_name,
            engine_id,
            pod_name,
            file_count=file_count,
            file_size=file_size,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'bucket_name={}'.format(bucket_name) in query_string
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'pod_name={}'.format(pod_name) in query_string
        assert 'file_count={}'.format(file_count) in query_string
        assert 'file_size={}'.format(file_size) in query_string

    def test_generate_benchmark_report_all_params_with_retries(self):
        # Enable retries and run test_generate_benchmark_report_all_params.
        _service.enable_retries()
        self.test_generate_benchmark_report_all_params()

        # Disable retries and run test_generate_benchmark_report_all_params.
        _service.disable_retries()
        self.test_generate_benchmark_report_all_params()

    @responses.activate
    def test_generate_benchmark_report_required_params(self):
        """
        test_generate_benchmark_report_required_params()
        """
        # Set up mock
        url = preprocess_url('/generate_benchmark_report')
        mock_response = '{"response": {"message": "message", "req_id": "req_id", "status": "status"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_name = 'testString'
        engine_id = 'testString'
        pod_name = 'testString'

        # Invoke method
        response = _service.generate_benchmark_report(
            bucket_name,
            engine_id,
            pod_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'bucket_name={}'.format(bucket_name) in query_string
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'pod_name={}'.format(pod_name) in query_string

    def test_generate_benchmark_report_required_params_with_retries(self):
        # Enable retries and run test_generate_benchmark_report_required_params.
        _service.enable_retries()
        self.test_generate_benchmark_report_required_params()

        # Disable retries and run test_generate_benchmark_report_required_params.
        _service.disable_retries()
        self.test_generate_benchmark_report_required_params()

    @responses.activate
    def test_generate_benchmark_report_value_error(self):
        """
        test_generate_benchmark_report_value_error()
        """
        # Set up mock
        url = preprocess_url('/generate_benchmark_report')
        mock_response = '{"response": {"message": "message", "req_id": "req_id", "status": "status"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        bucket_name = 'testString'
        engine_id = 'testString'
        pod_name = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_name": bucket_name,
            "engine_id": engine_id,
            "pod_name": pod_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.generate_benchmark_report(**req_copy)

    def test_generate_benchmark_report_value_error_with_retries(self):
        # Enable retries and run test_generate_benchmark_report_value_error.
        _service.enable_retries()
        self.test_generate_benchmark_report_value_error()

        # Disable retries and run test_generate_benchmark_report_value_error.
        _service.disable_retries()
        self.test_generate_benchmark_report_value_error()


class TestGenerateBenchmarkReportStatus:
    """
    Test Class for generate_benchmark_report_status
    """

    @responses.activate
    def test_generate_benchmark_report_status_all_params(self):
        """
        generate_benchmark_report_status()
        """
        # Set up mock
        url = preprocess_url('/generate_benchmark_report/status/testString')
        mock_response = '{"data": {"bandwidth": {"download_bandwidth_mbps": "download_bandwidth_mbps", "upload_bandwidth_mbps": "upload_bandwidth_mbps"}, "date": "2019-01-01", "num_files": 0, "results": {"create_bucket_time_sec": "create_bucket_time_sec", "download_files_time_sec": "download_files_time_sec", "erase_bucket_time_sec": "erase_bucket_time_sec", "erase_objects_time_sec": "erase_objects_time_sec", "list_files_time_sec": "list_files_time_sec", "total_operations_time_sec": "total_operations_time_sec", "upload_files_time_sec": "upload_files_time_sec"}, "size_files": 0, "time": "time"}, "error": "error", "message": "message", "status": "status"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        req_id = 'testString'
        engine_id = 'testString'
        bucket_name = 'testString'
        pod_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.generate_benchmark_report_status(
            req_id,
            engine_id,
            bucket_name,
            pod_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'bucket_name={}'.format(bucket_name) in query_string
        assert 'pod_name={}'.format(pod_name) in query_string

    def test_generate_benchmark_report_status_all_params_with_retries(self):
        # Enable retries and run test_generate_benchmark_report_status_all_params.
        _service.enable_retries()
        self.test_generate_benchmark_report_status_all_params()

        # Disable retries and run test_generate_benchmark_report_status_all_params.
        _service.disable_retries()
        self.test_generate_benchmark_report_status_all_params()

    @responses.activate
    def test_generate_benchmark_report_status_required_params(self):
        """
        test_generate_benchmark_report_status_required_params()
        """
        # Set up mock
        url = preprocess_url('/generate_benchmark_report/status/testString')
        mock_response = '{"data": {"bandwidth": {"download_bandwidth_mbps": "download_bandwidth_mbps", "upload_bandwidth_mbps": "upload_bandwidth_mbps"}, "date": "2019-01-01", "num_files": 0, "results": {"create_bucket_time_sec": "create_bucket_time_sec", "download_files_time_sec": "download_files_time_sec", "erase_bucket_time_sec": "erase_bucket_time_sec", "erase_objects_time_sec": "erase_objects_time_sec", "list_files_time_sec": "list_files_time_sec", "total_operations_time_sec": "total_operations_time_sec", "upload_files_time_sec": "upload_files_time_sec"}, "size_files": 0, "time": "time"}, "error": "error", "message": "message", "status": "status"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        req_id = 'testString'
        engine_id = 'testString'
        bucket_name = 'testString'
        pod_name = 'testString'

        # Invoke method
        response = _service.generate_benchmark_report_status(
            req_id,
            engine_id,
            bucket_name,
            pod_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'bucket_name={}'.format(bucket_name) in query_string
        assert 'pod_name={}'.format(pod_name) in query_string

    def test_generate_benchmark_report_status_required_params_with_retries(self):
        # Enable retries and run test_generate_benchmark_report_status_required_params.
        _service.enable_retries()
        self.test_generate_benchmark_report_status_required_params()

        # Disable retries and run test_generate_benchmark_report_status_required_params.
        _service.disable_retries()
        self.test_generate_benchmark_report_status_required_params()

    @responses.activate
    def test_generate_benchmark_report_status_value_error(self):
        """
        test_generate_benchmark_report_status_value_error()
        """
        # Set up mock
        url = preprocess_url('/generate_benchmark_report/status/testString')
        mock_response = '{"data": {"bandwidth": {"download_bandwidth_mbps": "download_bandwidth_mbps", "upload_bandwidth_mbps": "upload_bandwidth_mbps"}, "date": "2019-01-01", "num_files": 0, "results": {"create_bucket_time_sec": "create_bucket_time_sec", "download_files_time_sec": "download_files_time_sec", "erase_bucket_time_sec": "erase_bucket_time_sec", "erase_objects_time_sec": "erase_objects_time_sec", "list_files_time_sec": "list_files_time_sec", "total_operations_time_sec": "total_operations_time_sec", "upload_files_time_sec": "upload_files_time_sec"}, "size_files": 0, "time": "time"}, "error": "error", "message": "message", "status": "status"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        req_id = 'testString'
        engine_id = 'testString'
        bucket_name = 'testString'
        pod_name = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "req_id": req_id,
            "engine_id": engine_id,
            "bucket_name": bucket_name,
            "pod_name": pod_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.generate_benchmark_report_status(**req_copy)

    def test_generate_benchmark_report_status_value_error_with_retries(self):
        # Enable retries and run test_generate_benchmark_report_status_value_error.
        _service.enable_retries()
        self.test_generate_benchmark_report_status_value_error()

        # Disable retries and run test_generate_benchmark_report_status_value_error.
        _service.disable_retries()
        self.test_generate_benchmark_report_status_value_error()


class TestCreateHdfsStorage:
    """
    Test Class for create_hdfs_storage
    """

    @responses.activate
    def test_create_hdfs_storage_all_params(self):
        """
        create_hdfs_storage()
        """
        # Set up mock
        url = preprocess_url('/storage_hdfs_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_display_name": "sample hdfs displayname", "bucket_id": "hdfs123", "bucket_type": "hdfs", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "HDFS description for storage", "managed_by": "customer", "state": "active", "tags": ["tags"]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_display_name = 'testString'
        bucket_type = 'testString'
        hms_thrift_uri = 'testString'
        hms_thrift_port = 1
        core_site = 'testString'
        hdfs_site = 'testString'
        kerberos = 'testString'
        catalog_name = 'testString'
        catalog_type = 'testString'
        krb5_config = 'testString'
        hive_keytab = io.BytesIO(b'This is a mock file.').getvalue()
        hive_keytab_content_type = 'testString'
        hdfs_keytab = io.BytesIO(b'This is a mock file.').getvalue()
        hdfs_keytab_content_type = 'testString'
        hive_server_principal = 'testString'
        hive_client_principal = 'testString'
        hdfs_principal = 'testString'
        description = 'testString'
        created_on = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_hdfs_storage(
            bucket_display_name,
            bucket_type,
            hms_thrift_uri,
            hms_thrift_port,
            core_site,
            hdfs_site,
            kerberos,
            catalog_name,
            catalog_type,
            krb5_config=krb5_config,
            hive_keytab=hive_keytab,
            hive_keytab_content_type=hive_keytab_content_type,
            hdfs_keytab=hdfs_keytab,
            hdfs_keytab_content_type=hdfs_keytab_content_type,
            hive_server_principal=hive_server_principal,
            hive_client_principal=hive_client_principal,
            hdfs_principal=hdfs_principal,
            description=description,
            created_on=created_on,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_hdfs_storage_all_params_with_retries(self):
        # Enable retries and run test_create_hdfs_storage_all_params.
        _service.enable_retries()
        self.test_create_hdfs_storage_all_params()

        # Disable retries and run test_create_hdfs_storage_all_params.
        _service.disable_retries()
        self.test_create_hdfs_storage_all_params()

    @responses.activate
    def test_create_hdfs_storage_required_params(self):
        """
        test_create_hdfs_storage_required_params()
        """
        # Set up mock
        url = preprocess_url('/storage_hdfs_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_display_name": "sample hdfs displayname", "bucket_id": "hdfs123", "bucket_type": "hdfs", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "HDFS description for storage", "managed_by": "customer", "state": "active", "tags": ["tags"]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_display_name = 'testString'
        bucket_type = 'testString'
        hms_thrift_uri = 'testString'
        hms_thrift_port = 1
        core_site = 'testString'
        hdfs_site = 'testString'
        kerberos = 'testString'
        catalog_name = 'testString'
        catalog_type = 'testString'

        # Invoke method
        response = _service.create_hdfs_storage(
            bucket_display_name,
            bucket_type,
            hms_thrift_uri,
            hms_thrift_port,
            core_site,
            hdfs_site,
            kerberos,
            catalog_name,
            catalog_type,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_hdfs_storage_required_params_with_retries(self):
        # Enable retries and run test_create_hdfs_storage_required_params.
        _service.enable_retries()
        self.test_create_hdfs_storage_required_params()

        # Disable retries and run test_create_hdfs_storage_required_params.
        _service.disable_retries()
        self.test_create_hdfs_storage_required_params()

    @responses.activate
    def test_create_hdfs_storage_value_error(self):
        """
        test_create_hdfs_storage_value_error()
        """
        # Set up mock
        url = preprocess_url('/storage_hdfs_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "bucket_display_name": "sample hdfs displayname", "bucket_id": "hdfs123", "bucket_type": "hdfs", "created_by": "<username>@<domain>.com", "created_on": "1686120645", "description": "HDFS description for storage", "managed_by": "customer", "state": "active", "tags": ["tags"]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_display_name = 'testString'
        bucket_type = 'testString'
        hms_thrift_uri = 'testString'
        hms_thrift_port = 1
        core_site = 'testString'
        hdfs_site = 'testString'
        kerberos = 'testString'
        catalog_name = 'testString'
        catalog_type = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_display_name": bucket_display_name,
            "bucket_type": bucket_type,
            "hms_thrift_uri": hms_thrift_uri,
            "hms_thrift_port": hms_thrift_port,
            "core_site": core_site,
            "hdfs_site": hdfs_site,
            "kerberos": kerberos,
            "catalog_name": catalog_name,
            "catalog_type": catalog_type,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_hdfs_storage(**req_copy)

    def test_create_hdfs_storage_value_error_with_retries(self):
        # Enable retries and run test_create_hdfs_storage_value_error.
        _service.enable_retries()
        self.test_create_hdfs_storage_value_error()

        # Disable retries and run test_create_hdfs_storage_value_error.
        _service.disable_retries()
        self.test_create_hdfs_storage_value_error()


# endregion
##############################################################################
# End of Service: Buckets
##############################################################################

##############################################################################
# Start of Service: Databases
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListDatabaseRegistrations:
    """
    Test Class for list_database_registrations
    """

    @responses.activate
    def test_list_database_registrations_all_params(self):
        """
        list_database_registrations()
        """
        # Set up mock
        url = preprocess_url('/database_registrations')
        mock_response = '{"database_registrations": [{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_database_registrations(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_database_registrations_all_params_with_retries(self):
        # Enable retries and run test_list_database_registrations_all_params.
        _service.enable_retries()
        self.test_list_database_registrations_all_params()

        # Disable retries and run test_list_database_registrations_all_params.
        _service.disable_retries()
        self.test_list_database_registrations_all_params()

    @responses.activate
    def test_list_database_registrations_required_params(self):
        """
        test_list_database_registrations_required_params()
        """
        # Set up mock
        url = preprocess_url('/database_registrations')
        mock_response = '{"database_registrations": [{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_database_registrations()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_database_registrations_required_params_with_retries(self):
        # Enable retries and run test_list_database_registrations_required_params.
        _service.enable_retries()
        self.test_list_database_registrations_required_params()

        # Disable retries and run test_list_database_registrations_required_params.
        _service.disable_retries()
        self.test_list_database_registrations_required_params()


class TestCreateDatabaseRegistration:
    """
    Test Class for create_database_registration
    """

    @responses.activate
    def test_create_database_registration_all_params(self):
        """
        create_database_registration()
        """
        # Set up mock
        url = preprocess_url('/database_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a DatabaseCatalogPrototype model
        database_catalog_prototype_model = {}
        database_catalog_prototype_model['catalog_name'] = 'sampleCatalog'
        database_catalog_prototype_model['catalog_type'] = 'iceberg'

        # Construct a dict representation of a DatabaseDetails model
        database_details_model = {}
        database_details_model['authentication_type'] = 'LDAP'
        database_details_model['authentication_value'] = 'LDAP'
        database_details_model['broker_authentication_password'] = 'samplepassword'
        database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_details_model['broker_authentication_user'] = 'sampleuser'
        database_details_model['broker_host'] = 'samplehost'
        database_details_model['broker_port'] = 4553
        database_details_model['certificate'] = 'exampleCertificate'
        database_details_model['certificate_extension'] = 'pem'
        database_details_model['connection_method'] = 'basic, apikey'
        database_details_model['connection_mode'] = 'service_name'
        database_details_model['connection_mode_value'] = 'orclpdb'
        database_details_model['connection_type'] = 'JDBC, Arrow flight'
        database_details_model['controller_authentication_password'] = 'samplepassword'
        database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_details_model['controller_authentication_user'] = 'sampleuser'
        database_details_model['coordinator_host'] = 'samplehost'
        database_details_model['coordinator_port'] = 4553
        database_details_model['cpd_hostname'] = 'samplecpdhostname'
        database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_details_model['database_name'] = 'new_database'
        database_details_model['hostname'] = 'http://db2@localhost:9900.com'
        database_details_model['hostname_in_certificate'] = 'samplehostname'
        database_details_model['hosts'] = 'abc.com:1234,xyz.com:4321'
        database_details_model['informix_server'] = 'ol_informix1410'
        database_details_model['password'] = 'samplepassword'
        database_details_model['port'] = 4553
        database_details_model['project_id'] = 'conops-bigquery'
        database_details_model['sasl'] = True
        database_details_model['sasl_mechanism'] = 'plain'
        database_details_model['schema_name'] = 'sampleSchema'
        database_details_model['schemas'] = 'redis__name'
        database_details_model['service_api_key'] = 'sampleapikey'
        database_details_model['service_hostname'] = 'api.dataplatform.dev.cloud.ibm.com'
        database_details_model['service_password'] = 'samplepassword'
        database_details_model['service_port'] = 443
        database_details_model['service_ssl'] = True
        database_details_model['service_token_url'] = 'sampletoakenurl'
        database_details_model['service_username'] = 'sampleusername'
        database_details_model['ssl'] = True
        database_details_model['tables'] = 'kafka_table_name, redis_table_name'
        database_details_model['username'] = 'sampleuser'
        database_details_model['validate_server_certificate'] = True
        database_details_model['verify_host_name'] = True
        database_details_model['warehouse_name'] = 'samplewrehouse'

        # Construct a dict representation of a DatabaseRegistrationPrototypeDatabasePropertiesItems model
        database_registration_prototype_database_properties_items_model = {}
        database_registration_prototype_database_properties_items_model['encrypt'] = True
        database_registration_prototype_database_properties_items_model['key'] = 'abc'
        database_registration_prototype_database_properties_items_model['value'] = 'xyz'

        # Set up parameter values
        database_display_name = 'new_database'
        database_type = 'db2'
        associated_catalog = database_catalog_prototype_model
        created_on = '1686792721'
        database_details = database_details_model
        database_properties = [database_registration_prototype_database_properties_items_model]
        description = 'db2 extenal database description'
        tags = ['testdatabase', 'userdatabase']
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_database_registration(
            database_display_name,
            database_type,
            associated_catalog=associated_catalog,
            created_on=created_on,
            database_details=database_details,
            database_properties=database_properties,
            description=description,
            tags=tags,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['database_display_name'] == 'new_database'
        assert req_body['database_type'] == 'db2'
        assert req_body['associated_catalog'] == database_catalog_prototype_model
        assert req_body['created_on'] == '1686792721'
        assert req_body['database_details'] == database_details_model
        assert req_body['database_properties'] == [database_registration_prototype_database_properties_items_model]
        assert req_body['description'] == 'db2 extenal database description'
        assert req_body['tags'] == ['testdatabase', 'userdatabase']

    def test_create_database_registration_all_params_with_retries(self):
        # Enable retries and run test_create_database_registration_all_params.
        _service.enable_retries()
        self.test_create_database_registration_all_params()

        # Disable retries and run test_create_database_registration_all_params.
        _service.disable_retries()
        self.test_create_database_registration_all_params()

    @responses.activate
    def test_create_database_registration_required_params(self):
        """
        test_create_database_registration_required_params()
        """
        # Set up mock
        url = preprocess_url('/database_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a DatabaseCatalogPrototype model
        database_catalog_prototype_model = {}
        database_catalog_prototype_model['catalog_name'] = 'sampleCatalog'
        database_catalog_prototype_model['catalog_type'] = 'iceberg'

        # Construct a dict representation of a DatabaseDetails model
        database_details_model = {}
        database_details_model['authentication_type'] = 'LDAP'
        database_details_model['authentication_value'] = 'LDAP'
        database_details_model['broker_authentication_password'] = 'samplepassword'
        database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_details_model['broker_authentication_user'] = 'sampleuser'
        database_details_model['broker_host'] = 'samplehost'
        database_details_model['broker_port'] = 4553
        database_details_model['certificate'] = 'exampleCertificate'
        database_details_model['certificate_extension'] = 'pem'
        database_details_model['connection_method'] = 'basic, apikey'
        database_details_model['connection_mode'] = 'service_name'
        database_details_model['connection_mode_value'] = 'orclpdb'
        database_details_model['connection_type'] = 'JDBC, Arrow flight'
        database_details_model['controller_authentication_password'] = 'samplepassword'
        database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_details_model['controller_authentication_user'] = 'sampleuser'
        database_details_model['coordinator_host'] = 'samplehost'
        database_details_model['coordinator_port'] = 4553
        database_details_model['cpd_hostname'] = 'samplecpdhostname'
        database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_details_model['database_name'] = 'new_database'
        database_details_model['hostname'] = 'http://db2@localhost:9900.com'
        database_details_model['hostname_in_certificate'] = 'samplehostname'
        database_details_model['hosts'] = 'abc.com:1234,xyz.com:4321'
        database_details_model['informix_server'] = 'ol_informix1410'
        database_details_model['password'] = 'samplepassword'
        database_details_model['port'] = 4553
        database_details_model['project_id'] = 'conops-bigquery'
        database_details_model['sasl'] = True
        database_details_model['sasl_mechanism'] = 'plain'
        database_details_model['schema_name'] = 'sampleSchema'
        database_details_model['schemas'] = 'redis__name'
        database_details_model['service_api_key'] = 'sampleapikey'
        database_details_model['service_hostname'] = 'api.dataplatform.dev.cloud.ibm.com'
        database_details_model['service_password'] = 'samplepassword'
        database_details_model['service_port'] = 443
        database_details_model['service_ssl'] = True
        database_details_model['service_token_url'] = 'sampletoakenurl'
        database_details_model['service_username'] = 'sampleusername'
        database_details_model['ssl'] = True
        database_details_model['tables'] = 'kafka_table_name, redis_table_name'
        database_details_model['username'] = 'sampleuser'
        database_details_model['validate_server_certificate'] = True
        database_details_model['verify_host_name'] = True
        database_details_model['warehouse_name'] = 'samplewrehouse'

        # Construct a dict representation of a DatabaseRegistrationPrototypeDatabasePropertiesItems model
        database_registration_prototype_database_properties_items_model = {}
        database_registration_prototype_database_properties_items_model['encrypt'] = True
        database_registration_prototype_database_properties_items_model['key'] = 'abc'
        database_registration_prototype_database_properties_items_model['value'] = 'xyz'

        # Set up parameter values
        database_display_name = 'new_database'
        database_type = 'db2'
        associated_catalog = database_catalog_prototype_model
        created_on = '1686792721'
        database_details = database_details_model
        database_properties = [database_registration_prototype_database_properties_items_model]
        description = 'db2 extenal database description'
        tags = ['testdatabase', 'userdatabase']

        # Invoke method
        response = _service.create_database_registration(
            database_display_name,
            database_type,
            associated_catalog=associated_catalog,
            created_on=created_on,
            database_details=database_details,
            database_properties=database_properties,
            description=description,
            tags=tags,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['database_display_name'] == 'new_database'
        assert req_body['database_type'] == 'db2'
        assert req_body['associated_catalog'] == database_catalog_prototype_model
        assert req_body['created_on'] == '1686792721'
        assert req_body['database_details'] == database_details_model
        assert req_body['database_properties'] == [database_registration_prototype_database_properties_items_model]
        assert req_body['description'] == 'db2 extenal database description'
        assert req_body['tags'] == ['testdatabase', 'userdatabase']

    def test_create_database_registration_required_params_with_retries(self):
        # Enable retries and run test_create_database_registration_required_params.
        _service.enable_retries()
        self.test_create_database_registration_required_params()

        # Disable retries and run test_create_database_registration_required_params.
        _service.disable_retries()
        self.test_create_database_registration_required_params()

    @responses.activate
    def test_create_database_registration_value_error(self):
        """
        test_create_database_registration_value_error()
        """
        # Set up mock
        url = preprocess_url('/database_registrations')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a DatabaseCatalogPrototype model
        database_catalog_prototype_model = {}
        database_catalog_prototype_model['catalog_name'] = 'sampleCatalog'
        database_catalog_prototype_model['catalog_type'] = 'iceberg'

        # Construct a dict representation of a DatabaseDetails model
        database_details_model = {}
        database_details_model['authentication_type'] = 'LDAP'
        database_details_model['authentication_value'] = 'LDAP'
        database_details_model['broker_authentication_password'] = 'samplepassword'
        database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_details_model['broker_authentication_user'] = 'sampleuser'
        database_details_model['broker_host'] = 'samplehost'
        database_details_model['broker_port'] = 4553
        database_details_model['certificate'] = 'exampleCertificate'
        database_details_model['certificate_extension'] = 'pem'
        database_details_model['connection_method'] = 'basic, apikey'
        database_details_model['connection_mode'] = 'service_name'
        database_details_model['connection_mode_value'] = 'orclpdb'
        database_details_model['connection_type'] = 'JDBC, Arrow flight'
        database_details_model['controller_authentication_password'] = 'samplepassword'
        database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_details_model['controller_authentication_user'] = 'sampleuser'
        database_details_model['coordinator_host'] = 'samplehost'
        database_details_model['coordinator_port'] = 4553
        database_details_model['cpd_hostname'] = 'samplecpdhostname'
        database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_details_model['database_name'] = 'new_database'
        database_details_model['hostname'] = 'http://db2@localhost:9900.com'
        database_details_model['hostname_in_certificate'] = 'samplehostname'
        database_details_model['hosts'] = 'abc.com:1234,xyz.com:4321'
        database_details_model['informix_server'] = 'ol_informix1410'
        database_details_model['password'] = 'samplepassword'
        database_details_model['port'] = 4553
        database_details_model['project_id'] = 'conops-bigquery'
        database_details_model['sasl'] = True
        database_details_model['sasl_mechanism'] = 'plain'
        database_details_model['schema_name'] = 'sampleSchema'
        database_details_model['schemas'] = 'redis__name'
        database_details_model['service_api_key'] = 'sampleapikey'
        database_details_model['service_hostname'] = 'api.dataplatform.dev.cloud.ibm.com'
        database_details_model['service_password'] = 'samplepassword'
        database_details_model['service_port'] = 443
        database_details_model['service_ssl'] = True
        database_details_model['service_token_url'] = 'sampletoakenurl'
        database_details_model['service_username'] = 'sampleusername'
        database_details_model['ssl'] = True
        database_details_model['tables'] = 'kafka_table_name, redis_table_name'
        database_details_model['username'] = 'sampleuser'
        database_details_model['validate_server_certificate'] = True
        database_details_model['verify_host_name'] = True
        database_details_model['warehouse_name'] = 'samplewrehouse'

        # Construct a dict representation of a DatabaseRegistrationPrototypeDatabasePropertiesItems model
        database_registration_prototype_database_properties_items_model = {}
        database_registration_prototype_database_properties_items_model['encrypt'] = True
        database_registration_prototype_database_properties_items_model['key'] = 'abc'
        database_registration_prototype_database_properties_items_model['value'] = 'xyz'

        # Set up parameter values
        database_display_name = 'new_database'
        database_type = 'db2'
        associated_catalog = database_catalog_prototype_model
        created_on = '1686792721'
        database_details = database_details_model
        database_properties = [database_registration_prototype_database_properties_items_model]
        description = 'db2 extenal database description'
        tags = ['testdatabase', 'userdatabase']

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "database_display_name": database_display_name,
            "database_type": database_type,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_database_registration(**req_copy)

    def test_create_database_registration_value_error_with_retries(self):
        # Enable retries and run test_create_database_registration_value_error.
        _service.enable_retries()
        self.test_create_database_registration_value_error()

        # Disable retries and run test_create_database_registration_value_error.
        _service.disable_retries()
        self.test_create_database_registration_value_error()


class TestGetDatabase:
    """
    Test Class for get_database
    """

    @responses.activate
    def test_get_database_all_params(self):
        """
        get_database()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        database_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_database(
            database_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_database_all_params_with_retries(self):
        # Enable retries and run test_get_database_all_params.
        _service.enable_retries()
        self.test_get_database_all_params()

        # Disable retries and run test_get_database_all_params.
        _service.disable_retries()
        self.test_get_database_all_params()

    @responses.activate
    def test_get_database_required_params(self):
        """
        test_get_database_required_params()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        database_id = 'testString'

        # Invoke method
        response = _service.get_database(
            database_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_database_required_params_with_retries(self):
        # Enable retries and run test_get_database_required_params.
        _service.enable_retries()
        self.test_get_database_required_params()

        # Disable retries and run test_get_database_required_params.
        _service.disable_retries()
        self.test_get_database_required_params()

    @responses.activate
    def test_get_database_value_error(self):
        """
        test_get_database_value_error()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        database_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "database_id": database_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_database(**req_copy)

    def test_get_database_value_error_with_retries(self):
        # Enable retries and run test_get_database_value_error.
        _service.enable_retries()
        self.test_get_database_value_error()

        # Disable retries and run test_get_database_value_error.
        _service.disable_retries()
        self.test_get_database_value_error()


class TestDeleteDatabaseCatalog:
    """
    Test Class for delete_database_catalog
    """

    @responses.activate
    def test_delete_database_catalog_all_params(self):
        """
        delete_database_catalog()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        database_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_database_catalog(
            database_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_database_catalog_all_params_with_retries(self):
        # Enable retries and run test_delete_database_catalog_all_params.
        _service.enable_retries()
        self.test_delete_database_catalog_all_params()

        # Disable retries and run test_delete_database_catalog_all_params.
        _service.disable_retries()
        self.test_delete_database_catalog_all_params()

    @responses.activate
    def test_delete_database_catalog_required_params(self):
        """
        test_delete_database_catalog_required_params()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        database_id = 'testString'

        # Invoke method
        response = _service.delete_database_catalog(
            database_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_database_catalog_required_params_with_retries(self):
        # Enable retries and run test_delete_database_catalog_required_params.
        _service.enable_retries()
        self.test_delete_database_catalog_required_params()

        # Disable retries and run test_delete_database_catalog_required_params.
        _service.disable_retries()
        self.test_delete_database_catalog_required_params()

    @responses.activate
    def test_delete_database_catalog_value_error(self):
        """
        test_delete_database_catalog_value_error()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        database_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "database_id": database_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_database_catalog(**req_copy)

    def test_delete_database_catalog_value_error_with_retries(self):
        # Enable retries and run test_delete_database_catalog_value_error.
        _service.enable_retries()
        self.test_delete_database_catalog_value_error()

        # Disable retries and run test_delete_database_catalog_value_error.
        _service.disable_retries()
        self.test_delete_database_catalog_value_error()


class TestUpdateDatabase:
    """
    Test Class for update_database
    """

    @responses.activate
    def test_update_database_all_params(self):
        """
        update_database()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems model
        database_registration_patch_database_details_database_properties_items_model = {}
        database_registration_patch_database_details_database_properties_items_model['encrypt'] = True
        database_registration_patch_database_details_database_properties_items_model['key'] = 'abc'
        database_registration_patch_database_details_database_properties_items_model['value'] = 'xyz'

        # Construct a dict representation of a DatabaseRegistrationPatchDatabaseDetails model
        database_registration_patch_database_details_model = {}
        database_registration_patch_database_details_model['authentication_value'] = 'LDAP'
        database_registration_patch_database_details_model['broker_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['broker_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['controller_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['controller_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_registration_patch_database_details_model['database_properties'] = [database_registration_patch_database_details_database_properties_items_model]
        database_registration_patch_database_details_model['password'] = 'samplepassword'
        database_registration_patch_database_details_model['username'] = 'sampleuser'

        # Construct a dict representation of a DatabaseRegistrationPatchTablesItems model
        database_registration_patch_tables_items_model = {}
        database_registration_patch_tables_items_model['created_on'] = '1686792721'
        database_registration_patch_tables_items_model['file_contents'] = 'sample file content'
        database_registration_patch_tables_items_model['file_name'] = 'test.json'
        database_registration_patch_tables_items_model['schema_name'] = 'customer'
        database_registration_patch_tables_items_model['table_name'] = 'customer'

        # Construct a dict representation of a DatabaseRegistrationPatchTopicsItems model
        database_registration_patch_topics_items_model = {}
        database_registration_patch_topics_items_model['created_on'] = '1686792721'
        database_registration_patch_topics_items_model['file_contents'] = 'sample file contents'
        database_registration_patch_topics_items_model['file_name'] = 'test.json'
        database_registration_patch_topics_items_model['topic_name'] = 'customer'

        # Construct a dict representation of a DatabaseRegistrationPatch model
        database_registration_patch_model = {}
        database_registration_patch_model['database_details'] = database_registration_patch_database_details_model
        database_registration_patch_model['database_display_name'] = 'new_database'
        database_registration_patch_model['description'] = 'External database description'
        database_registration_patch_model['tables'] = [database_registration_patch_tables_items_model]
        database_registration_patch_model['tags'] = ['testdatabase', 'userdatabase']
        database_registration_patch_model['topics'] = [database_registration_patch_topics_items_model]

        # Set up parameter values
        database_id = 'testString'
        body = database_registration_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_database(
            database_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_database_all_params_with_retries(self):
        # Enable retries and run test_update_database_all_params.
        _service.enable_retries()
        self.test_update_database_all_params()

        # Disable retries and run test_update_database_all_params.
        _service.disable_retries()
        self.test_update_database_all_params()

    @responses.activate
    def test_update_database_required_params(self):
        """
        test_update_database_required_params()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems model
        database_registration_patch_database_details_database_properties_items_model = {}
        database_registration_patch_database_details_database_properties_items_model['encrypt'] = True
        database_registration_patch_database_details_database_properties_items_model['key'] = 'abc'
        database_registration_patch_database_details_database_properties_items_model['value'] = 'xyz'

        # Construct a dict representation of a DatabaseRegistrationPatchDatabaseDetails model
        database_registration_patch_database_details_model = {}
        database_registration_patch_database_details_model['authentication_value'] = 'LDAP'
        database_registration_patch_database_details_model['broker_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['broker_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['controller_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['controller_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_registration_patch_database_details_model['database_properties'] = [database_registration_patch_database_details_database_properties_items_model]
        database_registration_patch_database_details_model['password'] = 'samplepassword'
        database_registration_patch_database_details_model['username'] = 'sampleuser'

        # Construct a dict representation of a DatabaseRegistrationPatchTablesItems model
        database_registration_patch_tables_items_model = {}
        database_registration_patch_tables_items_model['created_on'] = '1686792721'
        database_registration_patch_tables_items_model['file_contents'] = 'sample file content'
        database_registration_patch_tables_items_model['file_name'] = 'test.json'
        database_registration_patch_tables_items_model['schema_name'] = 'customer'
        database_registration_patch_tables_items_model['table_name'] = 'customer'

        # Construct a dict representation of a DatabaseRegistrationPatchTopicsItems model
        database_registration_patch_topics_items_model = {}
        database_registration_patch_topics_items_model['created_on'] = '1686792721'
        database_registration_patch_topics_items_model['file_contents'] = 'sample file contents'
        database_registration_patch_topics_items_model['file_name'] = 'test.json'
        database_registration_patch_topics_items_model['topic_name'] = 'customer'

        # Construct a dict representation of a DatabaseRegistrationPatch model
        database_registration_patch_model = {}
        database_registration_patch_model['database_details'] = database_registration_patch_database_details_model
        database_registration_patch_model['database_display_name'] = 'new_database'
        database_registration_patch_model['description'] = 'External database description'
        database_registration_patch_model['tables'] = [database_registration_patch_tables_items_model]
        database_registration_patch_model['tags'] = ['testdatabase', 'userdatabase']
        database_registration_patch_model['topics'] = [database_registration_patch_topics_items_model]

        # Set up parameter values
        database_id = 'testString'
        body = database_registration_patch_model

        # Invoke method
        response = _service.update_database(
            database_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_database_required_params_with_retries(self):
        # Enable retries and run test_update_database_required_params.
        _service.enable_retries()
        self.test_update_database_required_params()

        # Disable retries and run test_update_database_required_params.
        _service.disable_retries()
        self.test_update_database_required_params()

    @responses.activate
    def test_update_database_value_error(self):
        """
        test_update_database_value_error()
        """
        # Set up mock
        url = preprocess_url('/database_registrations/testString')
        mock_response = '{"actions": ["actions"], "associated_catalog": {"catalog_name": "sampleCatalog", "catalog_tags": ["catalog_tags"], "catalog_type": "iceberg"}, "catalog_name": "sampleCatalog", "created_by": "user1@ibm.com", "created_on": "1686792721", "database_details": {"authentication_type": "LDAP", "authentication_value": "LDAP", "broker_authentication_password": "samplepassword", "broker_authentication_type": "PASSWORD", "broker_authentication_user": "sampleuser", "broker_host": "samplehost", "broker_port": 4553, "certificate": "exampleCertificate", "certificate_extension": "pem", "connection_method": "basic, apikey", "connection_mode": "service_name", "connection_mode_value": "orclpdb", "connection_type": "JDBC, Arrow flight", "controller_authentication_password": "samplepassword", "controller_authentication_type": "PASSWORD", "controller_authentication_user": "sampleuser", "coordinator_host": "samplehost", "coordinator_port": 4553, "cpd_hostname": "samplecpdhostname", "credentials_key": "eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......", "database_name": "new_database", "hostname": "http://db2@localhost:9900.com", "hostname_in_certificate": "samplehostname", "hosts": "abc.com:1234,xyz.com:4321", "informix_server": "ol_informix1410", "password": "samplepassword", "port": 4553, "project_id": "conops-bigquery", "sasl": true, "sasl_mechanism": "plain", "schema_name": "sampleSchema", "schemas": "redis__name", "service_api_key": "sampleapikey", "service_hostname": "api.dataplatform.dev.cloud.ibm.com", "service_password": "samplepassword", "service_port": 443, "service_ssl": true, "service_token_url": "sampletoakenurl", "service_username": "sampleusername", "ssl": true, "tables": "kafka_table_name, redis_table_name", "username": "sampleuser", "validate_server_certificate": true, "verify_host_name": true, "warehouse_name": "samplewrehouse"}, "database_display_name": "new_database", "database_id": "mysql123", "database_properties": [{"encrypt": true, "key": "hive.metastore", "value": "glue"}], "database_type": "netezza", "description": "Description of the external database", "tables": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "test.json", "schema_name": "customer", "table_name": "customer"}], "tags": ["tags"], "topics": [{"created_on": "1686792721", "file_contents": "sample file content", "file_name": "employee.json", "topic_name": "customer"}]}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems model
        database_registration_patch_database_details_database_properties_items_model = {}
        database_registration_patch_database_details_database_properties_items_model['encrypt'] = True
        database_registration_patch_database_details_database_properties_items_model['key'] = 'abc'
        database_registration_patch_database_details_database_properties_items_model['value'] = 'xyz'

        # Construct a dict representation of a DatabaseRegistrationPatchDatabaseDetails model
        database_registration_patch_database_details_model = {}
        database_registration_patch_database_details_model['authentication_value'] = 'LDAP'
        database_registration_patch_database_details_model['broker_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['broker_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['controller_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['controller_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_registration_patch_database_details_model['database_properties'] = [database_registration_patch_database_details_database_properties_items_model]
        database_registration_patch_database_details_model['password'] = 'samplepassword'
        database_registration_patch_database_details_model['username'] = 'sampleuser'

        # Construct a dict representation of a DatabaseRegistrationPatchTablesItems model
        database_registration_patch_tables_items_model = {}
        database_registration_patch_tables_items_model['created_on'] = '1686792721'
        database_registration_patch_tables_items_model['file_contents'] = 'sample file content'
        database_registration_patch_tables_items_model['file_name'] = 'test.json'
        database_registration_patch_tables_items_model['schema_name'] = 'customer'
        database_registration_patch_tables_items_model['table_name'] = 'customer'

        # Construct a dict representation of a DatabaseRegistrationPatchTopicsItems model
        database_registration_patch_topics_items_model = {}
        database_registration_patch_topics_items_model['created_on'] = '1686792721'
        database_registration_patch_topics_items_model['file_contents'] = 'sample file contents'
        database_registration_patch_topics_items_model['file_name'] = 'test.json'
        database_registration_patch_topics_items_model['topic_name'] = 'customer'

        # Construct a dict representation of a DatabaseRegistrationPatch model
        database_registration_patch_model = {}
        database_registration_patch_model['database_details'] = database_registration_patch_database_details_model
        database_registration_patch_model['database_display_name'] = 'new_database'
        database_registration_patch_model['description'] = 'External database description'
        database_registration_patch_model['tables'] = [database_registration_patch_tables_items_model]
        database_registration_patch_model['tags'] = ['testdatabase', 'userdatabase']
        database_registration_patch_model['topics'] = [database_registration_patch_topics_items_model]

        # Set up parameter values
        database_id = 'testString'
        body = database_registration_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "database_id": database_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_database(**req_copy)

    def test_update_database_value_error_with_retries(self):
        # Enable retries and run test_update_database_value_error.
        _service.enable_retries()
        self.test_update_database_value_error()

        # Disable retries and run test_update_database_value_error.
        _service.disable_retries()
        self.test_update_database_value_error()


# endregion
##############################################################################
# End of Service: Databases
##############################################################################

##############################################################################
# Start of Service: Engines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestGenerateEngineDump:
    """
    Test Class for generate_engine_dump
    """

    @responses.activate
    def test_generate_engine_dump_all_params(self):
        """
        generate_engine_dump()
        """
        # Set up mock
        url = preprocess_url('/generate_engine_dump')
        mock_response = '{"response": {"message": "message", "status": "status"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        dump_file_name = 'prestodump'
        dump_type = 'heat'
        engine_id = 'presto-123'
        pod_name = 'presto'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.generate_engine_dump(
            dump_file_name,
            dump_type,
            engine_id,
            pod_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['dump_file_name'] == 'prestodump'
        assert req_body['dump_type'] == 'heat'
        assert req_body['engine_id'] == 'presto-123'
        assert req_body['pod_name'] == 'presto'

    def test_generate_engine_dump_all_params_with_retries(self):
        # Enable retries and run test_generate_engine_dump_all_params.
        _service.enable_retries()
        self.test_generate_engine_dump_all_params()

        # Disable retries and run test_generate_engine_dump_all_params.
        _service.disable_retries()
        self.test_generate_engine_dump_all_params()

    @responses.activate
    def test_generate_engine_dump_required_params(self):
        """
        test_generate_engine_dump_required_params()
        """
        # Set up mock
        url = preprocess_url('/generate_engine_dump')
        mock_response = '{"response": {"message": "message", "status": "status"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        dump_file_name = 'prestodump'
        dump_type = 'heat'
        engine_id = 'presto-123'
        pod_name = 'presto'

        # Invoke method
        response = _service.generate_engine_dump(
            dump_file_name,
            dump_type,
            engine_id,
            pod_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['dump_file_name'] == 'prestodump'
        assert req_body['dump_type'] == 'heat'
        assert req_body['engine_id'] == 'presto-123'
        assert req_body['pod_name'] == 'presto'

    def test_generate_engine_dump_required_params_with_retries(self):
        # Enable retries and run test_generate_engine_dump_required_params.
        _service.enable_retries()
        self.test_generate_engine_dump_required_params()

        # Disable retries and run test_generate_engine_dump_required_params.
        _service.disable_retries()
        self.test_generate_engine_dump_required_params()

    @responses.activate
    def test_generate_engine_dump_value_error(self):
        """
        test_generate_engine_dump_value_error()
        """
        # Set up mock
        url = preprocess_url('/generate_engine_dump')
        mock_response = '{"response": {"message": "message", "status": "status"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        dump_file_name = 'prestodump'
        dump_type = 'heat'
        engine_id = 'presto-123'
        pod_name = 'presto'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "dump_file_name": dump_file_name,
            "dump_type": dump_type,
            "engine_id": engine_id,
            "pod_name": pod_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.generate_engine_dump(**req_copy)

    def test_generate_engine_dump_value_error_with_retries(self):
        # Enable retries and run test_generate_engine_dump_value_error.
        _service.enable_retries()
        self.test_generate_engine_dump_value_error()

        # Disable retries and run test_generate_engine_dump_value_error.
        _service.disable_retries()
        self.test_generate_engine_dump_value_error()


# endregion
##############################################################################
# End of Service: Engines
##############################################################################

##############################################################################
# Start of Service: OtherEngines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListOtherEngines:
    """
    Test Class for list_other_engines
    """

    @responses.activate
    def test_list_other_engines_all_params(self):
        """
        list_other_engines()
        """
        # Set up mock
        url = preprocess_url('/other_engines')
        mock_response = '{"other_engines": [{"actions": ["actions"], "created_by": "<username>@<domain>.com", "created_on": 10, "description": "engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "engine_type": "netezza", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 4, "status": "registered", "tags": ["tags"], "type": "external"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_other_engines(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_other_engines_all_params_with_retries(self):
        # Enable retries and run test_list_other_engines_all_params.
        _service.enable_retries()
        self.test_list_other_engines_all_params()

        # Disable retries and run test_list_other_engines_all_params.
        _service.disable_retries()
        self.test_list_other_engines_all_params()

    @responses.activate
    def test_list_other_engines_required_params(self):
        """
        test_list_other_engines_required_params()
        """
        # Set up mock
        url = preprocess_url('/other_engines')
        mock_response = '{"other_engines": [{"actions": ["actions"], "created_by": "<username>@<domain>.com", "created_on": 10, "description": "engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "engine_type": "netezza", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 4, "status": "registered", "tags": ["tags"], "type": "external"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_other_engines()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_other_engines_required_params_with_retries(self):
        # Enable retries and run test_list_other_engines_required_params.
        _service.enable_retries()
        self.test_list_other_engines_required_params()

        # Disable retries and run test_list_other_engines_required_params.
        _service.disable_retries()
        self.test_list_other_engines_required_params()


class TestCreateOtherEngine:
    """
    Test Class for create_other_engine
    """

    @responses.activate
    def test_create_other_engine_all_params(self):
        """
        create_other_engine()
        """
        # Set up mock
        url = preprocess_url('/other_engines')
        mock_response = '{"actions": ["actions"], "created_by": "<username>@<domain>.com", "created_on": 10, "description": "engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "engine_type": "netezza", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 4, "status": "registered", "tags": ["tags"], "type": "external"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a OtherEngineDetailsBody model
        other_engine_details_body_model = {}
        other_engine_details_body_model['connection_string'] = '1.2.3.4'
        other_engine_details_body_model['engine_type'] = 'netezza'

        # Set up parameter values
        engine_details = other_engine_details_body_model
        engine_display_name = 'sampleEngine01'
        description = 'external engine description'
        origin = 'external'
        tags = ['tag1', 'tag2']
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_other_engine(
            engine_details,
            engine_display_name,
            description=description,
            origin=origin,
            tags=tags,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['engine_details'] == other_engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine01'
        assert req_body['description'] == 'external engine description'
        assert req_body['origin'] == 'external'
        assert req_body['tags'] == ['tag1', 'tag2']

    def test_create_other_engine_all_params_with_retries(self):
        # Enable retries and run test_create_other_engine_all_params.
        _service.enable_retries()
        self.test_create_other_engine_all_params()

        # Disable retries and run test_create_other_engine_all_params.
        _service.disable_retries()
        self.test_create_other_engine_all_params()

    @responses.activate
    def test_create_other_engine_required_params(self):
        """
        test_create_other_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/other_engines')
        mock_response = '{"actions": ["actions"], "created_by": "<username>@<domain>.com", "created_on": 10, "description": "engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "engine_type": "netezza", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 4, "status": "registered", "tags": ["tags"], "type": "external"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a OtherEngineDetailsBody model
        other_engine_details_body_model = {}
        other_engine_details_body_model['connection_string'] = '1.2.3.4'
        other_engine_details_body_model['engine_type'] = 'netezza'

        # Set up parameter values
        engine_details = other_engine_details_body_model
        engine_display_name = 'sampleEngine01'
        description = 'external engine description'
        origin = 'external'
        tags = ['tag1', 'tag2']

        # Invoke method
        response = _service.create_other_engine(
            engine_details,
            engine_display_name,
            description=description,
            origin=origin,
            tags=tags,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['engine_details'] == other_engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine01'
        assert req_body['description'] == 'external engine description'
        assert req_body['origin'] == 'external'
        assert req_body['tags'] == ['tag1', 'tag2']

    def test_create_other_engine_required_params_with_retries(self):
        # Enable retries and run test_create_other_engine_required_params.
        _service.enable_retries()
        self.test_create_other_engine_required_params()

        # Disable retries and run test_create_other_engine_required_params.
        _service.disable_retries()
        self.test_create_other_engine_required_params()

    @responses.activate
    def test_create_other_engine_value_error(self):
        """
        test_create_other_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/other_engines')
        mock_response = '{"actions": ["actions"], "created_by": "<username>@<domain>.com", "created_on": 10, "description": "engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "engine_type": "netezza", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 4, "status": "registered", "tags": ["tags"], "type": "external"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a OtherEngineDetailsBody model
        other_engine_details_body_model = {}
        other_engine_details_body_model['connection_string'] = '1.2.3.4'
        other_engine_details_body_model['engine_type'] = 'netezza'

        # Set up parameter values
        engine_details = other_engine_details_body_model
        engine_display_name = 'sampleEngine01'
        description = 'external engine description'
        origin = 'external'
        tags = ['tag1', 'tag2']

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_details": engine_details,
            "engine_display_name": engine_display_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_other_engine(**req_copy)

    def test_create_other_engine_value_error_with_retries(self):
        # Enable retries and run test_create_other_engine_value_error.
        _service.enable_retries()
        self.test_create_other_engine_value_error()

        # Disable retries and run test_create_other_engine_value_error.
        _service.disable_retries()
        self.test_create_other_engine_value_error()


class TestDeleteOtherEngine:
    """
    Test Class for delete_other_engine
    """

    @responses.activate
    def test_delete_other_engine_all_params(self):
        """
        delete_other_engine()
        """
        # Set up mock
        url = preprocess_url('/other_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_other_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_other_engine_all_params_with_retries(self):
        # Enable retries and run test_delete_other_engine_all_params.
        _service.enable_retries()
        self.test_delete_other_engine_all_params()

        # Disable retries and run test_delete_other_engine_all_params.
        _service.disable_retries()
        self.test_delete_other_engine_all_params()

    @responses.activate
    def test_delete_other_engine_required_params(self):
        """
        test_delete_other_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/other_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_other_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_other_engine_required_params_with_retries(self):
        # Enable retries and run test_delete_other_engine_required_params.
        _service.enable_retries()
        self.test_delete_other_engine_required_params()

        # Disable retries and run test_delete_other_engine_required_params.
        _service.disable_retries()
        self.test_delete_other_engine_required_params()

    @responses.activate
    def test_delete_other_engine_value_error(self):
        """
        test_delete_other_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/other_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_other_engine(**req_copy)

    def test_delete_other_engine_value_error_with_retries(self):
        # Enable retries and run test_delete_other_engine_value_error.
        _service.enable_retries()
        self.test_delete_other_engine_value_error()

        # Disable retries and run test_delete_other_engine_value_error.
        _service.disable_retries()
        self.test_delete_other_engine_value_error()


# endregion
##############################################################################
# End of Service: OtherEngines
##############################################################################

##############################################################################
# Start of Service: Integrations
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListAllIntegrations:
    """
    Test Class for list_all_integrations
    """

    @responses.activate
    def test_list_all_integrations_all_params(self):
        """
        list_all_integrations()
        """
        # Set up mock
        url = preprocess_url('/integrations')
        mock_response = '{"integrations": [{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'
        secret = 'testString'
        service_type = 'testString'
        state = ['testString']

        # Invoke method
        response = _service.list_all_integrations(
            auth_instance_id=auth_instance_id,
            secret=secret,
            service_type=service_type,
            state=state,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'service_type={}'.format(service_type) in query_string
        assert 'state={}'.format(','.join(state)) in query_string

    def test_list_all_integrations_all_params_with_retries(self):
        # Enable retries and run test_list_all_integrations_all_params.
        _service.enable_retries()
        self.test_list_all_integrations_all_params()

        # Disable retries and run test_list_all_integrations_all_params.
        _service.disable_retries()
        self.test_list_all_integrations_all_params()

    @responses.activate
    def test_list_all_integrations_required_params(self):
        """
        test_list_all_integrations_required_params()
        """
        # Set up mock
        url = preprocess_url('/integrations')
        mock_response = '{"integrations": [{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_all_integrations()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_all_integrations_required_params_with_retries(self):
        # Enable retries and run test_list_all_integrations_required_params.
        _service.enable_retries()
        self.test_list_all_integrations_required_params()

        # Disable retries and run test_list_all_integrations_required_params.
        _service.disable_retries()
        self.test_list_all_integrations_required_params()


class TestCreateIntegration:
    """
    Test Class for create_integration
    """

    @responses.activate
    def test_create_integration_all_params(self):
        """
        create_integration()
        """
        # Set up mock
        url = preprocess_url('/integrations')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        access_token = 'testString'
        apikey = 'testString'
        cross_account_integration = True
        enable_data_policy_within_wxd = False
        ikc_user_account_id = 'testString'
        password = 'password'
        resource = 'resource_name'
        service_type = 'ranger'
        storage_catalogs = ['testString']
        url = 'http://abcd.efgh.com:9876/'
        username = 'username'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_integration(
            access_token=access_token,
            apikey=apikey,
            cross_account_integration=cross_account_integration,
            enable_data_policy_within_wxd=enable_data_policy_within_wxd,
            ikc_user_account_id=ikc_user_account_id,
            password=password,
            resource=resource,
            service_type=service_type,
            storage_catalogs=storage_catalogs,
            url=url,
            username=username,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['access_token'] == 'testString'
        assert req_body['apikey'] == 'testString'
        assert req_body['cross_account_integration'] == True
        assert req_body['enable_data_policy_within_wxd'] == False
        assert req_body['ikc_user_account_id'] == 'testString'
        assert req_body['password'] == 'password'
        assert req_body['resource'] == 'resource_name'
        assert req_body['service_type'] == 'ranger'
        assert req_body['storage_catalogs'] == ['testString']
        assert req_body['url'] == 'http://abcd.efgh.com:9876/'
        assert req_body['username'] == 'username'

    def test_create_integration_all_params_with_retries(self):
        # Enable retries and run test_create_integration_all_params.
        _service.enable_retries()
        self.test_create_integration_all_params()

        # Disable retries and run test_create_integration_all_params.
        _service.disable_retries()
        self.test_create_integration_all_params()

    @responses.activate
    def test_create_integration_required_params(self):
        """
        test_create_integration_required_params()
        """
        # Set up mock
        url = preprocess_url('/integrations')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        access_token = 'testString'
        apikey = 'testString'
        cross_account_integration = True
        enable_data_policy_within_wxd = False
        ikc_user_account_id = 'testString'
        password = 'password'
        resource = 'resource_name'
        service_type = 'ranger'
        storage_catalogs = ['testString']
        url = 'http://abcd.efgh.com:9876/'
        username = 'username'

        # Invoke method
        response = _service.create_integration(
            access_token=access_token,
            apikey=apikey,
            cross_account_integration=cross_account_integration,
            enable_data_policy_within_wxd=enable_data_policy_within_wxd,
            ikc_user_account_id=ikc_user_account_id,
            password=password,
            resource=resource,
            service_type=service_type,
            storage_catalogs=storage_catalogs,
            url=url,
            username=username,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['access_token'] == 'testString'
        assert req_body['apikey'] == 'testString'
        assert req_body['cross_account_integration'] == True
        assert req_body['enable_data_policy_within_wxd'] == False
        assert req_body['ikc_user_account_id'] == 'testString'
        assert req_body['password'] == 'password'
        assert req_body['resource'] == 'resource_name'
        assert req_body['service_type'] == 'ranger'
        assert req_body['storage_catalogs'] == ['testString']
        assert req_body['url'] == 'http://abcd.efgh.com:9876/'
        assert req_body['username'] == 'username'

    def test_create_integration_required_params_with_retries(self):
        # Enable retries and run test_create_integration_required_params.
        _service.enable_retries()
        self.test_create_integration_required_params()

        # Disable retries and run test_create_integration_required_params.
        _service.disable_retries()
        self.test_create_integration_required_params()


class TestGetIntegrations:
    """
    Test Class for get_integrations
    """

    @responses.activate
    def test_get_integrations_all_params(self):
        """
        get_integrations()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        integration_id = 'testString'
        auth_instance_id = 'testString'
        secret = 'testString'

        # Invoke method
        response = _service.get_integrations(
            integration_id,
            auth_instance_id=auth_instance_id,
            secret=secret,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_integrations_all_params_with_retries(self):
        # Enable retries and run test_get_integrations_all_params.
        _service.enable_retries()
        self.test_get_integrations_all_params()

        # Disable retries and run test_get_integrations_all_params.
        _service.disable_retries()
        self.test_get_integrations_all_params()

    @responses.activate
    def test_get_integrations_required_params(self):
        """
        test_get_integrations_required_params()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        integration_id = 'testString'

        # Invoke method
        response = _service.get_integrations(
            integration_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_integrations_required_params_with_retries(self):
        # Enable retries and run test_get_integrations_required_params.
        _service.enable_retries()
        self.test_get_integrations_required_params()

        # Disable retries and run test_get_integrations_required_params.
        _service.disable_retries()
        self.test_get_integrations_required_params()

    @responses.activate
    def test_get_integrations_value_error(self):
        """
        test_get_integrations_value_error()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        integration_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "integration_id": integration_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_integrations(**req_copy)

    def test_get_integrations_value_error_with_retries(self):
        # Enable retries and run test_get_integrations_value_error.
        _service.enable_retries()
        self.test_get_integrations_value_error()

        # Disable retries and run test_get_integrations_value_error.
        _service.disable_retries()
        self.test_get_integrations_value_error()


class TestDeleteIntegration:
    """
    Test Class for delete_integration
    """

    @responses.activate
    def test_delete_integration_all_params(self):
        """
        delete_integration()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        integration_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_integration(
            integration_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_integration_all_params_with_retries(self):
        # Enable retries and run test_delete_integration_all_params.
        _service.enable_retries()
        self.test_delete_integration_all_params()

        # Disable retries and run test_delete_integration_all_params.
        _service.disable_retries()
        self.test_delete_integration_all_params()

    @responses.activate
    def test_delete_integration_required_params(self):
        """
        test_delete_integration_required_params()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        integration_id = 'testString'

        # Invoke method
        response = _service.delete_integration(
            integration_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_integration_required_params_with_retries(self):
        # Enable retries and run test_delete_integration_required_params.
        _service.enable_retries()
        self.test_delete_integration_required_params()

        # Disable retries and run test_delete_integration_required_params.
        _service.disable_retries()
        self.test_delete_integration_required_params()

    @responses.activate
    def test_delete_integration_value_error(self):
        """
        test_delete_integration_value_error()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        integration_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "integration_id": integration_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_integration(**req_copy)

    def test_delete_integration_value_error_with_retries(self):
        # Enable retries and run test_delete_integration_value_error.
        _service.enable_retries()
        self.test_delete_integration_value_error()

        # Disable retries and run test_delete_integration_value_error.
        _service.disable_retries()
        self.test_delete_integration_value_error()


class TestUpdateIntegration:
    """
    Test Class for update_integration
    """

    @responses.activate
    def test_update_integration_all_params(self):
        """
        update_integration()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a IntegrationPatch model
        integration_patch_model = {}
        integration_patch_model['access_token'] = 'uiOO90kklop'
        integration_patch_model['apikey'] = 'apikey'
        integration_patch_model['cross_account_integration'] = False
        integration_patch_model['enable_data_policy_within_wxd'] = True
        integration_patch_model['ikc_user_account_id'] = 'abcdefghijklmnopqrstuvwxyz'
        integration_patch_model['password'] = 'password'
        integration_patch_model['resource'] = 'resource_name'
        integration_patch_model['state'] = 'active'
        integration_patch_model['storage_catalogs'] = ['iceberg_data', 'hive_data']
        integration_patch_model['url'] = 'http://abcd.efgh.com:9876/'
        integration_patch_model['username'] = 'username'

        # Set up parameter values
        integration_id = 'testString'
        integration_patch = integration_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_integration(
            integration_id,
            integration_patch,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == integration_patch

    def test_update_integration_all_params_with_retries(self):
        # Enable retries and run test_update_integration_all_params.
        _service.enable_retries()
        self.test_update_integration_all_params()

        # Disable retries and run test_update_integration_all_params.
        _service.disable_retries()
        self.test_update_integration_all_params()

    @responses.activate
    def test_update_integration_required_params(self):
        """
        test_update_integration_required_params()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a IntegrationPatch model
        integration_patch_model = {}
        integration_patch_model['access_token'] = 'uiOO90kklop'
        integration_patch_model['apikey'] = 'apikey'
        integration_patch_model['cross_account_integration'] = False
        integration_patch_model['enable_data_policy_within_wxd'] = True
        integration_patch_model['ikc_user_account_id'] = 'abcdefghijklmnopqrstuvwxyz'
        integration_patch_model['password'] = 'password'
        integration_patch_model['resource'] = 'resource_name'
        integration_patch_model['state'] = 'active'
        integration_patch_model['storage_catalogs'] = ['iceberg_data', 'hive_data']
        integration_patch_model['url'] = 'http://abcd.efgh.com:9876/'
        integration_patch_model['username'] = 'username'

        # Set up parameter values
        integration_id = 'testString'
        integration_patch = integration_patch_model

        # Invoke method
        response = _service.update_integration(
            integration_id,
            integration_patch,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == integration_patch

    def test_update_integration_required_params_with_retries(self):
        # Enable retries and run test_update_integration_required_params.
        _service.enable_retries()
        self.test_update_integration_required_params()

        # Disable retries and run test_update_integration_required_params.
        _service.disable_retries()
        self.test_update_integration_required_params()

    @responses.activate
    def test_update_integration_value_error(self):
        """
        test_update_integration_value_error()
        """
        # Set up mock
        url = preprocess_url('/integrations/testString')
        mock_response = '{"access_token": "accessToken", "apikey": "apikey", "auth_url": "https://abc.ibm.com", "config_properties": "ikc-env.password=ibm-abcefghijklmno==\nikc-env.url=ikc\nikc-enabled-catalogs=\nikc-username=\nlh-unique-identifier=1711796957622126\nlh-crn=1711796957622126", "cross_account_integration": true, "enable_data_policy_within_wxd": false, "governance_properties": "query-governance.name=external", "ikc_user_account_id": "abcdefghijklmnopqrstuvwxyz", "integration_id": "ikc001", "manta_url": "https://abcd.com/gov_lineage/v2/lineage_events/openlineage", "modified_at": 123456789, "modified_by": "username@email.com", "password": "password", "resource": "presto01", "service_type": "ikc", "state": "active", "storage_catalogs": ["storage_catalogs"], "url": "http://abcd.efgh.com:9876/", "username": "username@email.com"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a IntegrationPatch model
        integration_patch_model = {}
        integration_patch_model['access_token'] = 'uiOO90kklop'
        integration_patch_model['apikey'] = 'apikey'
        integration_patch_model['cross_account_integration'] = False
        integration_patch_model['enable_data_policy_within_wxd'] = True
        integration_patch_model['ikc_user_account_id'] = 'abcdefghijklmnopqrstuvwxyz'
        integration_patch_model['password'] = 'password'
        integration_patch_model['resource'] = 'resource_name'
        integration_patch_model['state'] = 'active'
        integration_patch_model['storage_catalogs'] = ['iceberg_data', 'hive_data']
        integration_patch_model['url'] = 'http://abcd.efgh.com:9876/'
        integration_patch_model['username'] = 'username'

        # Set up parameter values
        integration_id = 'testString'
        integration_patch = integration_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "integration_id": integration_id,
            "integration_patch": integration_patch,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_integration(**req_copy)

    def test_update_integration_value_error_with_retries(self):
        # Enable retries and run test_update_integration_value_error.
        _service.enable_retries()
        self.test_update_integration_value_error()

        # Disable retries and run test_update_integration_value_error.
        _service.disable_retries()
        self.test_update_integration_value_error()


# endregion
##############################################################################
# End of Service: Integrations
##############################################################################

##############################################################################
# Start of Service: Db2Engines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListDb2Engines:
    """
    Test Class for list_db2_engines
    """

    @responses.activate
    def test_list_db2_engines_all_params(self):
        """
        list_db2_engines()
        """
        # Set up mock
        url = preprocess_url('/db2_engines')
        mock_response = '{"db2_engines": [{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_db2_engines(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_db2_engines_all_params_with_retries(self):
        # Enable retries and run test_list_db2_engines_all_params.
        _service.enable_retries()
        self.test_list_db2_engines_all_params()

        # Disable retries and run test_list_db2_engines_all_params.
        _service.disable_retries()
        self.test_list_db2_engines_all_params()

    @responses.activate
    def test_list_db2_engines_required_params(self):
        """
        test_list_db2_engines_required_params()
        """
        # Set up mock
        url = preprocess_url('/db2_engines')
        mock_response = '{"db2_engines": [{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_db2_engines()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_db2_engines_required_params_with_retries(self):
        # Enable retries and run test_list_db2_engines_required_params.
        _service.enable_retries()
        self.test_list_db2_engines_required_params()

        # Disable retries and run test_list_db2_engines_required_params.
        _service.disable_retries()
        self.test_list_db2_engines_required_params()


class TestCreateDb2Engine:
    """
    Test Class for create_db2_engine
    """

    @responses.activate
    def test_create_db2_engine_all_params(self):
        """
        create_db2_engine()
        """
        # Set up mock
        url = preprocess_url('/db2_engines')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a Db2EngineDetailsBody model
        db2_engine_details_body_model = {}
        db2_engine_details_body_model['connection_string'] = '1.2.3.4'

        # Set up parameter values
        origin = 'external'
        description = 'db2 engine description'
        engine_details = db2_engine_details_body_model
        engine_display_name = 'sampleEngine'
        tags = ['tag1', 'tag2']
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_db2_engine(
            origin,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            tags=tags,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'external'
        assert req_body['description'] == 'db2 engine description'
        assert req_body['engine_details'] == db2_engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['tags'] == ['tag1', 'tag2']

    def test_create_db2_engine_all_params_with_retries(self):
        # Enable retries and run test_create_db2_engine_all_params.
        _service.enable_retries()
        self.test_create_db2_engine_all_params()

        # Disable retries and run test_create_db2_engine_all_params.
        _service.disable_retries()
        self.test_create_db2_engine_all_params()

    @responses.activate
    def test_create_db2_engine_required_params(self):
        """
        test_create_db2_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/db2_engines')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a Db2EngineDetailsBody model
        db2_engine_details_body_model = {}
        db2_engine_details_body_model['connection_string'] = '1.2.3.4'

        # Set up parameter values
        origin = 'external'
        description = 'db2 engine description'
        engine_details = db2_engine_details_body_model
        engine_display_name = 'sampleEngine'
        tags = ['tag1', 'tag2']

        # Invoke method
        response = _service.create_db2_engine(
            origin,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            tags=tags,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'external'
        assert req_body['description'] == 'db2 engine description'
        assert req_body['engine_details'] == db2_engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['tags'] == ['tag1', 'tag2']

    def test_create_db2_engine_required_params_with_retries(self):
        # Enable retries and run test_create_db2_engine_required_params.
        _service.enable_retries()
        self.test_create_db2_engine_required_params()

        # Disable retries and run test_create_db2_engine_required_params.
        _service.disable_retries()
        self.test_create_db2_engine_required_params()

    @responses.activate
    def test_create_db2_engine_value_error(self):
        """
        test_create_db2_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/db2_engines')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a Db2EngineDetailsBody model
        db2_engine_details_body_model = {}
        db2_engine_details_body_model['connection_string'] = '1.2.3.4'

        # Set up parameter values
        origin = 'external'
        description = 'db2 engine description'
        engine_details = db2_engine_details_body_model
        engine_display_name = 'sampleEngine'
        tags = ['tag1', 'tag2']

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "origin": origin,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_db2_engine(**req_copy)

    def test_create_db2_engine_value_error_with_retries(self):
        # Enable retries and run test_create_db2_engine_value_error.
        _service.enable_retries()
        self.test_create_db2_engine_value_error()

        # Disable retries and run test_create_db2_engine_value_error.
        _service.disable_retries()
        self.test_create_db2_engine_value_error()


class TestDeleteDb2Engine:
    """
    Test Class for delete_db2_engine
    """

    @responses.activate
    def test_delete_db2_engine_all_params(self):
        """
        delete_db2_engine()
        """
        # Set up mock
        url = preprocess_url('/db2_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_db2_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_db2_engine_all_params_with_retries(self):
        # Enable retries and run test_delete_db2_engine_all_params.
        _service.enable_retries()
        self.test_delete_db2_engine_all_params()

        # Disable retries and run test_delete_db2_engine_all_params.
        _service.disable_retries()
        self.test_delete_db2_engine_all_params()

    @responses.activate
    def test_delete_db2_engine_required_params(self):
        """
        test_delete_db2_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/db2_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_db2_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_db2_engine_required_params_with_retries(self):
        # Enable retries and run test_delete_db2_engine_required_params.
        _service.enable_retries()
        self.test_delete_db2_engine_required_params()

        # Disable retries and run test_delete_db2_engine_required_params.
        _service.disable_retries()
        self.test_delete_db2_engine_required_params()

    @responses.activate
    def test_delete_db2_engine_value_error(self):
        """
        test_delete_db2_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/db2_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_db2_engine(**req_copy)

    def test_delete_db2_engine_value_error_with_retries(self):
        # Enable retries and run test_delete_db2_engine_value_error.
        _service.enable_retries()
        self.test_delete_db2_engine_value_error()

        # Disable retries and run test_delete_db2_engine_value_error.
        _service.disable_retries()
        self.test_delete_db2_engine_value_error()


class TestUpdateDb2Engine:
    """
    Test Class for update_db2_engine
    """

    @responses.activate
    def test_update_db2_engine_all_params(self):
        """
        update_db2_engine()
        """
        # Set up mock
        url = preprocess_url('/db2_engines/testString')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a Db2EnginePatch model
        db2_engine_patch_model = {}
        db2_engine_patch_model['description'] = 'db2 engine updated description'
        db2_engine_patch_model['engine_display_name'] = 'sampleEngine'
        db2_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = db2_engine_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_db2_engine(
            engine_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_db2_engine_all_params_with_retries(self):
        # Enable retries and run test_update_db2_engine_all_params.
        _service.enable_retries()
        self.test_update_db2_engine_all_params()

        # Disable retries and run test_update_db2_engine_all_params.
        _service.disable_retries()
        self.test_update_db2_engine_all_params()

    @responses.activate
    def test_update_db2_engine_required_params(self):
        """
        test_update_db2_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/db2_engines/testString')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a Db2EnginePatch model
        db2_engine_patch_model = {}
        db2_engine_patch_model['description'] = 'db2 engine updated description'
        db2_engine_patch_model['engine_display_name'] = 'sampleEngine'
        db2_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = db2_engine_patch_model

        # Invoke method
        response = _service.update_db2_engine(
            engine_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_db2_engine_required_params_with_retries(self):
        # Enable retries and run test_update_db2_engine_required_params.
        _service.enable_retries()
        self.test_update_db2_engine_required_params()

        # Disable retries and run test_update_db2_engine_required_params.
        _service.disable_retries()
        self.test_update_db2_engine_required_params()

    @responses.activate
    def test_update_db2_engine_value_error(self):
        """
        test_update_db2_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/db2_engines/testString')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "db2 engine to run sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sample-engine", "engine_id": "sampleEngine123", "host_name": "xyz-db2-01-db2-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "db2"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a Db2EnginePatch model
        db2_engine_patch_model = {}
        db2_engine_patch_model['description'] = 'db2 engine updated description'
        db2_engine_patch_model['engine_display_name'] = 'sampleEngine'
        db2_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = db2_engine_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_db2_engine(**req_copy)

    def test_update_db2_engine_value_error_with_retries(self):
        # Enable retries and run test_update_db2_engine_value_error.
        _service.enable_retries()
        self.test_update_db2_engine_value_error()

        # Disable retries and run test_update_db2_engine_value_error.
        _service.disable_retries()
        self.test_update_db2_engine_value_error()


# endregion
##############################################################################
# End of Service: Db2Engines
##############################################################################

##############################################################################
# Start of Service: NetezzaEngines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListNetezzaEngines:
    """
    Test Class for list_netezza_engines
    """

    @responses.activate
    def test_list_netezza_engines_all_params(self):
        """
        list_netezza_engines()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines')
        mock_response = '{"netezza_engines": [{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_netezza_engines(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_netezza_engines_all_params_with_retries(self):
        # Enable retries and run test_list_netezza_engines_all_params.
        _service.enable_retries()
        self.test_list_netezza_engines_all_params()

        # Disable retries and run test_list_netezza_engines_all_params.
        _service.disable_retries()
        self.test_list_netezza_engines_all_params()

    @responses.activate
    def test_list_netezza_engines_required_params(self):
        """
        test_list_netezza_engines_required_params()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines')
        mock_response = '{"netezza_engines": [{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_netezza_engines()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_netezza_engines_required_params_with_retries(self):
        # Enable retries and run test_list_netezza_engines_required_params.
        _service.enable_retries()
        self.test_list_netezza_engines_required_params()

        # Disable retries and run test_list_netezza_engines_required_params.
        _service.disable_retries()
        self.test_list_netezza_engines_required_params()


class TestCreateNetezzaEngine:
    """
    Test Class for create_netezza_engine
    """

    @responses.activate
    def test_create_netezza_engine_all_params(self):
        """
        create_netezza_engine()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a NetezzaEngineDetailsBody model
        netezza_engine_details_body_model = {}
        netezza_engine_details_body_model['connection_string'] = '1.2.3.4'

        # Set up parameter values
        origin = 'external'
        description = 'netezza engine description'
        engine_details = netezza_engine_details_body_model
        engine_display_name = 'sampleEngine'
        tags = ['tag1', 'tag2']
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_netezza_engine(
            origin,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            tags=tags,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'external'
        assert req_body['description'] == 'netezza engine description'
        assert req_body['engine_details'] == netezza_engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['tags'] == ['tag1', 'tag2']

    def test_create_netezza_engine_all_params_with_retries(self):
        # Enable retries and run test_create_netezza_engine_all_params.
        _service.enable_retries()
        self.test_create_netezza_engine_all_params()

        # Disable retries and run test_create_netezza_engine_all_params.
        _service.disable_retries()
        self.test_create_netezza_engine_all_params()

    @responses.activate
    def test_create_netezza_engine_required_params(self):
        """
        test_create_netezza_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a NetezzaEngineDetailsBody model
        netezza_engine_details_body_model = {}
        netezza_engine_details_body_model['connection_string'] = '1.2.3.4'

        # Set up parameter values
        origin = 'external'
        description = 'netezza engine description'
        engine_details = netezza_engine_details_body_model
        engine_display_name = 'sampleEngine'
        tags = ['tag1', 'tag2']

        # Invoke method
        response = _service.create_netezza_engine(
            origin,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            tags=tags,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'external'
        assert req_body['description'] == 'netezza engine description'
        assert req_body['engine_details'] == netezza_engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['tags'] == ['tag1', 'tag2']

    def test_create_netezza_engine_required_params_with_retries(self):
        # Enable retries and run test_create_netezza_engine_required_params.
        _service.enable_retries()
        self.test_create_netezza_engine_required_params()

        # Disable retries and run test_create_netezza_engine_required_params.
        _service.disable_retries()
        self.test_create_netezza_engine_required_params()

    @responses.activate
    def test_create_netezza_engine_value_error(self):
        """
        test_create_netezza_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a NetezzaEngineDetailsBody model
        netezza_engine_details_body_model = {}
        netezza_engine_details_body_model['connection_string'] = '1.2.3.4'

        # Set up parameter values
        origin = 'external'
        description = 'netezza engine description'
        engine_details = netezza_engine_details_body_model
        engine_display_name = 'sampleEngine'
        tags = ['tag1', 'tag2']

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "origin": origin,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_netezza_engine(**req_copy)

    def test_create_netezza_engine_value_error_with_retries(self):
        # Enable retries and run test_create_netezza_engine_value_error.
        _service.enable_retries()
        self.test_create_netezza_engine_value_error()

        # Disable retries and run test_create_netezza_engine_value_error.
        _service.disable_retries()
        self.test_create_netezza_engine_value_error()


class TestDeleteNetezzaEngine:
    """
    Test Class for delete_netezza_engine
    """

    @responses.activate
    def test_delete_netezza_engine_all_params(self):
        """
        delete_netezza_engine()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_netezza_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_netezza_engine_all_params_with_retries(self):
        # Enable retries and run test_delete_netezza_engine_all_params.
        _service.enable_retries()
        self.test_delete_netezza_engine_all_params()

        # Disable retries and run test_delete_netezza_engine_all_params.
        _service.disable_retries()
        self.test_delete_netezza_engine_all_params()

    @responses.activate
    def test_delete_netezza_engine_required_params(self):
        """
        test_delete_netezza_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_netezza_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_netezza_engine_required_params_with_retries(self):
        # Enable retries and run test_delete_netezza_engine_required_params.
        _service.enable_retries()
        self.test_delete_netezza_engine_required_params()

        # Disable retries and run test_delete_netezza_engine_required_params.
        _service.disable_retries()
        self.test_delete_netezza_engine_required_params()

    @responses.activate
    def test_delete_netezza_engine_value_error(self):
        """
        test_delete_netezza_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_netezza_engine(**req_copy)

    def test_delete_netezza_engine_value_error_with_retries(self):
        # Enable retries and run test_delete_netezza_engine_value_error.
        _service.enable_retries()
        self.test_delete_netezza_engine_value_error()

        # Disable retries and run test_delete_netezza_engine_value_error.
        _service.disable_retries()
        self.test_delete_netezza_engine_value_error()


class TestUpdateNetezzaEngine:
    """
    Test Class for update_netezza_engine
    """

    @responses.activate
    def test_update_netezza_engine_all_params(self):
        """
        update_netezza_engine()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines/testString')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a NetezzaEnginePatch model
        netezza_engine_patch_model = {}
        netezza_engine_patch_model['description'] = 'netezza engine updated description'
        netezza_engine_patch_model['engine_display_name'] = 'sampleEngine'
        netezza_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = netezza_engine_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_netezza_engine(
            engine_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_netezza_engine_all_params_with_retries(self):
        # Enable retries and run test_update_netezza_engine_all_params.
        _service.enable_retries()
        self.test_update_netezza_engine_all_params()

        # Disable retries and run test_update_netezza_engine_all_params.
        _service.disable_retries()
        self.test_update_netezza_engine_all_params()

    @responses.activate
    def test_update_netezza_engine_required_params(self):
        """
        test_update_netezza_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines/testString')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a NetezzaEnginePatch model
        netezza_engine_patch_model = {}
        netezza_engine_patch_model['description'] = 'netezza engine updated description'
        netezza_engine_patch_model['engine_display_name'] = 'sampleEngine'
        netezza_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = netezza_engine_patch_model

        # Invoke method
        response = _service.update_netezza_engine(
            engine_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_netezza_engine_required_params_with_retries(self):
        # Enable retries and run test_update_netezza_engine_required_params.
        _service.enable_retries()
        self.test_update_netezza_engine_required_params()

        # Disable retries and run test_update_netezza_engine_required_params.
        _service.disable_retries()
        self.test_update_netezza_engine_required_params()

    @responses.activate
    def test_update_netezza_engine_value_error(self):
        """
        test_update_netezza_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/netezza_engines/testString')
        mock_response = '{"actions": ["actions"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 0, "description": "netezza engine for running sql queries", "engine_details": {"connection_string": "1.2.3.4", "metastore_host": "1.2.3.4"}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "host_name": "xyz-netezza-01-netezza-svc", "origin": "ibm", "port": 0, "status": "REGISTERED", "tags": ["tags"], "type": "netezza"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a NetezzaEnginePatch model
        netezza_engine_patch_model = {}
        netezza_engine_patch_model['description'] = 'netezza engine updated description'
        netezza_engine_patch_model['engine_display_name'] = 'sampleEngine'
        netezza_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = netezza_engine_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_netezza_engine(**req_copy)

    def test_update_netezza_engine_value_error_with_retries(self):
        # Enable retries and run test_update_netezza_engine_value_error.
        _service.enable_retries()
        self.test_update_netezza_engine_value_error()

        # Disable retries and run test_update_netezza_engine_value_error.
        _service.disable_retries()
        self.test_update_netezza_engine_value_error()


# endregion
##############################################################################
# End of Service: NetezzaEngines
##############################################################################

##############################################################################
# Start of Service: Queries
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestCreateExecuteQuery:
    """
    Test Class for create_execute_query
    """

    @responses.activate
    def test_create_execute_query_all_params(self):
        """
        create_execute_query()
        """
        # Set up mock
        url = preprocess_url('/queries/execute/testString')
        mock_response = '{"response": {"result": [{"mapKey": "inner"}]}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        sql_string = 'select expenses from expenditure'
        catalog_name = 'sampleCatalog'
        schema_name = 'SampleSchema1'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_execute_query(
            engine_id,
            sql_string,
            catalog_name=catalog_name,
            schema_name=schema_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['sql_string'] == 'select expenses from expenditure'
        assert req_body['catalog_name'] == 'sampleCatalog'
        assert req_body['schema_name'] == 'SampleSchema1'

    def test_create_execute_query_all_params_with_retries(self):
        # Enable retries and run test_create_execute_query_all_params.
        _service.enable_retries()
        self.test_create_execute_query_all_params()

        # Disable retries and run test_create_execute_query_all_params.
        _service.disable_retries()
        self.test_create_execute_query_all_params()

    @responses.activate
    def test_create_execute_query_required_params(self):
        """
        test_create_execute_query_required_params()
        """
        # Set up mock
        url = preprocess_url('/queries/execute/testString')
        mock_response = '{"response": {"result": [{"mapKey": "inner"}]}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        sql_string = 'select expenses from expenditure'
        catalog_name = 'sampleCatalog'
        schema_name = 'SampleSchema1'

        # Invoke method
        response = _service.create_execute_query(
            engine_id,
            sql_string,
            catalog_name=catalog_name,
            schema_name=schema_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['sql_string'] == 'select expenses from expenditure'
        assert req_body['catalog_name'] == 'sampleCatalog'
        assert req_body['schema_name'] == 'SampleSchema1'

    def test_create_execute_query_required_params_with_retries(self):
        # Enable retries and run test_create_execute_query_required_params.
        _service.enable_retries()
        self.test_create_execute_query_required_params()

        # Disable retries and run test_create_execute_query_required_params.
        _service.disable_retries()
        self.test_create_execute_query_required_params()

    @responses.activate
    def test_create_execute_query_value_error(self):
        """
        test_create_execute_query_value_error()
        """
        # Set up mock
        url = preprocess_url('/queries/execute/testString')
        mock_response = '{"response": {"result": [{"mapKey": "inner"}]}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        sql_string = 'select expenses from expenditure'
        catalog_name = 'sampleCatalog'
        schema_name = 'SampleSchema1'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "sql_string": sql_string,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_execute_query(**req_copy)

    def test_create_execute_query_value_error_with_retries(self):
        # Enable retries and run test_create_execute_query_value_error.
        _service.enable_retries()
        self.test_create_execute_query_value_error()

        # Disable retries and run test_create_execute_query_value_error.
        _service.disable_retries()
        self.test_create_execute_query_value_error()


# endregion
##############################################################################
# End of Service: Queries
##############################################################################

##############################################################################
# Start of Service: Instance
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListInstanceDetails:
    """
    Test Class for list_instance_details
    """

    @responses.activate
    def test_list_instance_details_all_params(self):
        """
        list_instance_details()
        """
        # Set up mock
        url = preprocess_url('/instance_details')
        mock_response = '{"engines_services": [{"details": [{"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}], "type": "presto"}], "watsonx_data_instance": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_instance_details(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_instance_details_all_params_with_retries(self):
        # Enable retries and run test_list_instance_details_all_params.
        _service.enable_retries()
        self.test_list_instance_details_all_params()

        # Disable retries and run test_list_instance_details_all_params.
        _service.disable_retries()
        self.test_list_instance_details_all_params()

    @responses.activate
    def test_list_instance_details_required_params(self):
        """
        test_list_instance_details_required_params()
        """
        # Set up mock
        url = preprocess_url('/instance_details')
        mock_response = '{"engines_services": [{"details": [{"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}], "type": "presto"}], "watsonx_data_instance": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_instance_details()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_instance_details_required_params_with_retries(self):
        # Enable retries and run test_list_instance_details_required_params.
        _service.enable_retries()
        self.test_list_instance_details_required_params()

        # Disable retries and run test_list_instance_details_required_params.
        _service.disable_retries()
        self.test_list_instance_details_required_params()


class TestListInstanceServiceDetails:
    """
    Test Class for list_instance_service_details
    """

    @responses.activate
    def test_list_instance_service_details_all_params(self):
        """
        list_instance_service_details()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services')
        mock_response = '{"engines_services": [{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        internal_host = False
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_instance_service_details(
            target,
            internal_host=internal_host,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'target={}'.format(target) in query_string
        assert 'internal_host={}'.format('true' if internal_host else 'false') in query_string

    def test_list_instance_service_details_all_params_with_retries(self):
        # Enable retries and run test_list_instance_service_details_all_params.
        _service.enable_retries()
        self.test_list_instance_service_details_all_params()

        # Disable retries and run test_list_instance_service_details_all_params.
        _service.disable_retries()
        self.test_list_instance_service_details_all_params()

    @responses.activate
    def test_list_instance_service_details_required_params(self):
        """
        test_list_instance_service_details_required_params()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services')
        mock_response = '{"engines_services": [{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'

        # Invoke method
        response = _service.list_instance_service_details(
            target,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'target={}'.format(target) in query_string

    def test_list_instance_service_details_required_params_with_retries(self):
        # Enable retries and run test_list_instance_service_details_required_params.
        _service.enable_retries()
        self.test_list_instance_service_details_required_params()

        # Disable retries and run test_list_instance_service_details_required_params.
        _service.disable_retries()
        self.test_list_instance_service_details_required_params()

    @responses.activate
    def test_list_instance_service_details_value_error(self):
        """
        test_list_instance_service_details_value_error()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services')
        mock_response = '{"engines_services": [{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "target": target,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_instance_service_details(**req_copy)

    def test_list_instance_service_details_value_error_with_retries(self):
        # Enable retries and run test_list_instance_service_details_value_error.
        _service.enable_retries()
        self.test_list_instance_service_details_value_error()

        # Disable retries and run test_list_instance_service_details_value_error.
        _service.disable_retries()
        self.test_list_instance_service_details_value_error()


class TestGetServicesDetails:
    """
    Test Class for get_services_details
    """

    @responses.activate
    def test_get_services_details_all_params(self):
        """
        get_services_details()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services/testString')
        mock_response = '{"engines_services": [{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        engine_or_service_type = 'testString'
        internal_host = False
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_services_details(
            target,
            engine_or_service_type,
            internal_host=internal_host,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'target={}'.format(target) in query_string
        assert 'internal_host={}'.format('true' if internal_host else 'false') in query_string

    def test_get_services_details_all_params_with_retries(self):
        # Enable retries and run test_get_services_details_all_params.
        _service.enable_retries()
        self.test_get_services_details_all_params()

        # Disable retries and run test_get_services_details_all_params.
        _service.disable_retries()
        self.test_get_services_details_all_params()

    @responses.activate
    def test_get_services_details_required_params(self):
        """
        test_get_services_details_required_params()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services/testString')
        mock_response = '{"engines_services": [{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        engine_or_service_type = 'testString'

        # Invoke method
        response = _service.get_services_details(
            target,
            engine_or_service_type,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'target={}'.format(target) in query_string

    def test_get_services_details_required_params_with_retries(self):
        # Enable retries and run test_get_services_details_required_params.
        _service.enable_retries()
        self.test_get_services_details_required_params()

        # Disable retries and run test_get_services_details_required_params.
        _service.disable_retries()
        self.test_get_services_details_required_params()

    @responses.activate
    def test_get_services_details_value_error(self):
        """
        test_get_services_details_value_error()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services/testString')
        mock_response = '{"engines_services": [{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        engine_or_service_type = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "target": target,
            "engine_or_service_type": engine_or_service_type,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_services_details(**req_copy)

    def test_get_services_details_value_error_with_retries(self):
        # Enable retries and run test_get_services_details_value_error.
        _service.enable_retries()
        self.test_get_services_details_value_error()

        # Disable retries and run test_get_services_details_value_error.
        _service.disable_retries()
        self.test_get_services_details_value_error()


class TestGetServiceDetail:
    """
    Test Class for get_service_detail
    """

    @responses.activate
    def test_get_service_detail_all_params(self):
        """
        get_service_detail()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services/testString/id/testString')
        mock_response = '{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        engine_or_service_type = 'testString'
        id = 'testString'
        database = 'testString'
        internal_host = False
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_service_detail(
            target,
            engine_or_service_type,
            id,
            database=database,
            internal_host=internal_host,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'target={}'.format(target) in query_string
        assert 'database={}'.format(database) in query_string
        assert 'internal_host={}'.format('true' if internal_host else 'false') in query_string

    def test_get_service_detail_all_params_with_retries(self):
        # Enable retries and run test_get_service_detail_all_params.
        _service.enable_retries()
        self.test_get_service_detail_all_params()

        # Disable retries and run test_get_service_detail_all_params.
        _service.disable_retries()
        self.test_get_service_detail_all_params()

    @responses.activate
    def test_get_service_detail_required_params(self):
        """
        test_get_service_detail_required_params()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services/testString/id/testString')
        mock_response = '{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        engine_or_service_type = 'testString'
        id = 'testString'

        # Invoke method
        response = _service.get_service_detail(
            target,
            engine_or_service_type,
            id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'target={}'.format(target) in query_string

    def test_get_service_detail_required_params_with_retries(self):
        # Enable retries and run test_get_service_detail_required_params.
        _service.enable_retries()
        self.test_get_service_detail_required_params()

        # Disable retries and run test_get_service_detail_required_params.
        _service.disable_retries()
        self.test_get_service_detail_required_params()

    @responses.activate
    def test_get_service_detail_value_error(self):
        """
        test_get_service_detail_value_error()
        """
        # Set up mock
        url = preprocess_url('/instance_details/engines_services/testString/id/testString')
        mock_response = '{"connection_name": "presto-01", "details": {"ca_certificate": "sample ca certificate", "default_configs": {"mapKey": "inner"}, "external": {"port": 4553, "hostname": "external hostname"}, "grpc_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "hostname": "sample hostname", "id": "sample ID", "instance_crn": "sample instance CRN", "instance_id": "sample instance ID", "internal": {"port": 4553, "hostname": "internal hostname"}, "jdbc_class": "com.facebook.presto.jdbc.PrestoDriver", "jdbc_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "name": "sample name", "port": 4553, "rest_api_endpoint": {"port": 4553, "hostname": "internal hostname"}, "spark_engine_endpoint": "Spark Engine endpoint", "ssl_certificate": "sample ssl certificate", "thrift_urls": {"external": "thrift://username:password@metastore1-internal-hostname:9083", "internal": "thrift://username:password@metastore1-internal-hostname:9083"}, "version": "java", "watsonx_data_application_endpoint": "sample application end point"}, "properties": {"connection": [{"name": "host", "value": "sample_value"}]}, "type": "presto"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        target = 'testString'
        engine_or_service_type = 'testString'
        id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "target": target,
            "engine_or_service_type": engine_or_service_type,
            "id": id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_service_detail(**req_copy)

    def test_get_service_detail_value_error_with_retries(self):
        # Enable retries and run test_get_service_detail_value_error.
        _service.enable_retries()
        self.test_get_service_detail_value_error()

        # Disable retries and run test_get_service_detail_value_error.
        _service.disable_retries()
        self.test_get_service_detail_value_error()


# endregion
##############################################################################
# End of Service: Instance
##############################################################################

##############################################################################
# Start of Service: PrestissimoEngines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListPrestissimoEngines:
    """
    Test Class for list_prestissimo_engines
    """

    @responses.activate
    def test_list_prestissimo_engines_all_params(self):
        """
        list_prestissimo_engines()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines')
        mock_response = '{"prestissimo_engines": [{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_prestissimo_engines(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_prestissimo_engines_all_params_with_retries(self):
        # Enable retries and run test_list_prestissimo_engines_all_params.
        _service.enable_retries()
        self.test_list_prestissimo_engines_all_params()

        # Disable retries and run test_list_prestissimo_engines_all_params.
        _service.disable_retries()
        self.test_list_prestissimo_engines_all_params()

    @responses.activate
    def test_list_prestissimo_engines_required_params(self):
        """
        test_list_prestissimo_engines_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines')
        mock_response = '{"prestissimo_engines": [{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_prestissimo_engines()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_prestissimo_engines_required_params_with_retries(self):
        # Enable retries and run test_list_prestissimo_engines_required_params.
        _service.enable_retries()
        self.test_list_prestissimo_engines_required_params()

        # Disable retries and run test_list_prestissimo_engines_required_params.
        _service.disable_retries()
        self.test_list_prestissimo_engines_required_params()


class TestCreatePrestissimoEngine:
    """
    Test Class for create_prestissimo_engine
    """

    @responses.activate
    def test_create_prestissimo_engine_all_params(self):
        """
        create_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a dict representation of a PrestissimoEndpoints model
        prestissimo_endpoints_model = {}
        prestissimo_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model['view_history_server'] = 'testString'
        prestissimo_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        # Construct a dict representation of a PrestissimoEngineDetails model
        prestissimo_engine_details_model = {}
        prestissimo_engine_details_model['api_key'] = '<api_key>'
        prestissimo_engine_details_model['connection_string'] = '1.2.3.4'
        prestissimo_engine_details_model['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_details_model['endpoints'] = prestissimo_endpoints_model
        prestissimo_engine_details_model['instance_id'] = 'instance_id'
        prestissimo_engine_details_model['managed_by'] = 'fully/self'
        prestissimo_engine_details_model['metastore_host'] = '1.2.3.4'
        prestissimo_engine_details_model['size_config'] = 'starter'
        prestissimo_engine_details_model['worker'] = prestissimo_node_description_body_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['hive_data']
        description = 'prestissimo engine description'
        engine_details = prestissimo_engine_details_model
        engine_display_name = 'sampleEngine'
        region = 'us-south'
        tags = ['tag1', 'tag2']
        version = '1.2.3'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_prestissimo_engine(
            origin,
            associated_catalogs=associated_catalogs,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            region=region,
            tags=tags,
            version=version,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'native'
        assert req_body['associated_catalogs'] == ['hive_data']
        assert req_body['description'] == 'prestissimo engine description'
        assert req_body['engine_details'] == prestissimo_engine_details_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['region'] == 'us-south'
        assert req_body['tags'] == ['tag1', 'tag2']
        assert req_body['version'] == '1.2.3'

    def test_create_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_create_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_create_prestissimo_engine_all_params()

        # Disable retries and run test_create_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_create_prestissimo_engine_all_params()

    @responses.activate
    def test_create_prestissimo_engine_required_params(self):
        """
        test_create_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a dict representation of a PrestissimoEndpoints model
        prestissimo_endpoints_model = {}
        prestissimo_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model['view_history_server'] = 'testString'
        prestissimo_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        # Construct a dict representation of a PrestissimoEngineDetails model
        prestissimo_engine_details_model = {}
        prestissimo_engine_details_model['api_key'] = '<api_key>'
        prestissimo_engine_details_model['connection_string'] = '1.2.3.4'
        prestissimo_engine_details_model['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_details_model['endpoints'] = prestissimo_endpoints_model
        prestissimo_engine_details_model['instance_id'] = 'instance_id'
        prestissimo_engine_details_model['managed_by'] = 'fully/self'
        prestissimo_engine_details_model['metastore_host'] = '1.2.3.4'
        prestissimo_engine_details_model['size_config'] = 'starter'
        prestissimo_engine_details_model['worker'] = prestissimo_node_description_body_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['hive_data']
        description = 'prestissimo engine description'
        engine_details = prestissimo_engine_details_model
        engine_display_name = 'sampleEngine'
        region = 'us-south'
        tags = ['tag1', 'tag2']
        version = '1.2.3'

        # Invoke method
        response = _service.create_prestissimo_engine(
            origin,
            associated_catalogs=associated_catalogs,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            region=region,
            tags=tags,
            version=version,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'native'
        assert req_body['associated_catalogs'] == ['hive_data']
        assert req_body['description'] == 'prestissimo engine description'
        assert req_body['engine_details'] == prestissimo_engine_details_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['region'] == 'us-south'
        assert req_body['tags'] == ['tag1', 'tag2']
        assert req_body['version'] == '1.2.3'

    def test_create_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_create_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_create_prestissimo_engine_required_params()

        # Disable retries and run test_create_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_create_prestissimo_engine_required_params()

    @responses.activate
    def test_create_prestissimo_engine_value_error(self):
        """
        test_create_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a dict representation of a PrestissimoEndpoints model
        prestissimo_endpoints_model = {}
        prestissimo_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model['view_history_server'] = 'testString'
        prestissimo_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        # Construct a dict representation of a PrestissimoEngineDetails model
        prestissimo_engine_details_model = {}
        prestissimo_engine_details_model['api_key'] = '<api_key>'
        prestissimo_engine_details_model['connection_string'] = '1.2.3.4'
        prestissimo_engine_details_model['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_details_model['endpoints'] = prestissimo_endpoints_model
        prestissimo_engine_details_model['instance_id'] = 'instance_id'
        prestissimo_engine_details_model['managed_by'] = 'fully/self'
        prestissimo_engine_details_model['metastore_host'] = '1.2.3.4'
        prestissimo_engine_details_model['size_config'] = 'starter'
        prestissimo_engine_details_model['worker'] = prestissimo_node_description_body_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['hive_data']
        description = 'prestissimo engine description'
        engine_details = prestissimo_engine_details_model
        engine_display_name = 'sampleEngine'
        region = 'us-south'
        tags = ['tag1', 'tag2']
        version = '1.2.3'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "origin": origin,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_prestissimo_engine(**req_copy)

    def test_create_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_create_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_create_prestissimo_engine_value_error()

        # Disable retries and run test_create_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_create_prestissimo_engine_value_error()


class TestGetPrestissimoEngine:
    """
    Test Class for get_prestissimo_engine
    """

    @responses.activate
    def test_get_prestissimo_engine_all_params(self):
        """
        get_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_prestissimo_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_get_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_get_prestissimo_engine_all_params()

        # Disable retries and run test_get_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_get_prestissimo_engine_all_params()

    @responses.activate
    def test_get_prestissimo_engine_required_params(self):
        """
        test_get_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.get_prestissimo_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_get_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_get_prestissimo_engine_required_params()

        # Disable retries and run test_get_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_get_prestissimo_engine_required_params()

    @responses.activate
    def test_get_prestissimo_engine_value_error(self):
        """
        test_get_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_prestissimo_engine(**req_copy)

    def test_get_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_get_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_get_prestissimo_engine_value_error()

        # Disable retries and run test_get_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_get_prestissimo_engine_value_error()


class TestDeletePrestissimoEngine:
    """
    Test Class for delete_prestissimo_engine
    """

    @responses.activate
    def test_delete_prestissimo_engine_all_params(self):
        """
        delete_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_prestissimo_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_delete_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_delete_prestissimo_engine_all_params()

        # Disable retries and run test_delete_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_delete_prestissimo_engine_all_params()

    @responses.activate
    def test_delete_prestissimo_engine_required_params(self):
        """
        test_delete_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_prestissimo_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_delete_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_delete_prestissimo_engine_required_params()

        # Disable retries and run test_delete_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_delete_prestissimo_engine_required_params()

    @responses.activate
    def test_delete_prestissimo_engine_value_error(self):
        """
        test_delete_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_prestissimo_engine(**req_copy)

    def test_delete_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_delete_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_delete_prestissimo_engine_value_error()

        # Disable retries and run test_delete_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_delete_prestissimo_engine_value_error()


class TestUpdatePrestissimoEngine:
    """
    Test Class for update_prestissimo_engine
    """

    @responses.activate
    def test_update_prestissimo_engine_all_params(self):
        """
        update_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a PrestissimoEnginePropertiesCatalog model
        prestissimo_engine_properties_catalog_model = {}
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EnginePropertiesOaiGenConfiguration model
        engine_properties_oai_gen_configuration_model = {}
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        # Construct a dict representation of a PrestissimoEnginePropertiesVelox model
        prestissimo_engine_properties_velox_model = {}
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a PrestissimoEnginePropertiesOaiGen1Jvm model
        prestissimo_engine_properties_oai_gen1_jvm_model = {}
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        # Construct a dict representation of a PrestissimoEngineEngineProperties model
        prestissimo_engine_engine_properties_model = {}
        prestissimo_engine_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        # Construct a dict representation of a RemoveEnginePropertiesConfiguration model
        remove_engine_properties_configuration_model = {}
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesPrestissimoOaiGenJvm model
        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        # Construct a dict representation of a RemoveEngineProperties model
        remove_engine_properties_model = {}
        remove_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model['velox'] = ['testString']

        # Construct a dict representation of a PrestissimoEnginePatch model
        prestissimo_engine_patch_model = {}
        prestissimo_engine_patch_model['description'] = 'updated description for prestissimo engine'
        prestissimo_engine_patch_model['engine_display_name'] = 'sampleEngine'
        prestissimo_engine_patch_model['engine_properties'] = prestissimo_engine_engine_properties_model
        prestissimo_engine_patch_model['engine_restart'] = 'force'
        prestissimo_engine_patch_model['remove_engine_properties'] = remove_engine_properties_model
        prestissimo_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = prestissimo_engine_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_prestissimo_engine(
            engine_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_update_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_update_prestissimo_engine_all_params()

        # Disable retries and run test_update_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_update_prestissimo_engine_all_params()

    @responses.activate
    def test_update_prestissimo_engine_required_params(self):
        """
        test_update_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a PrestissimoEnginePropertiesCatalog model
        prestissimo_engine_properties_catalog_model = {}
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EnginePropertiesOaiGenConfiguration model
        engine_properties_oai_gen_configuration_model = {}
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        # Construct a dict representation of a PrestissimoEnginePropertiesVelox model
        prestissimo_engine_properties_velox_model = {}
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a PrestissimoEnginePropertiesOaiGen1Jvm model
        prestissimo_engine_properties_oai_gen1_jvm_model = {}
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        # Construct a dict representation of a PrestissimoEngineEngineProperties model
        prestissimo_engine_engine_properties_model = {}
        prestissimo_engine_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        # Construct a dict representation of a RemoveEnginePropertiesConfiguration model
        remove_engine_properties_configuration_model = {}
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesPrestissimoOaiGenJvm model
        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        # Construct a dict representation of a RemoveEngineProperties model
        remove_engine_properties_model = {}
        remove_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model['velox'] = ['testString']

        # Construct a dict representation of a PrestissimoEnginePatch model
        prestissimo_engine_patch_model = {}
        prestissimo_engine_patch_model['description'] = 'updated description for prestissimo engine'
        prestissimo_engine_patch_model['engine_display_name'] = 'sampleEngine'
        prestissimo_engine_patch_model['engine_properties'] = prestissimo_engine_engine_properties_model
        prestissimo_engine_patch_model['engine_restart'] = 'force'
        prestissimo_engine_patch_model['remove_engine_properties'] = remove_engine_properties_model
        prestissimo_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = prestissimo_engine_patch_model

        # Invoke method
        response = _service.update_prestissimo_engine(
            engine_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_update_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_update_prestissimo_engine_required_params()

        # Disable retries and run test_update_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_update_prestissimo_engine_required_params()

    @responses.activate
    def test_update_prestissimo_engine_value_error(self):
        """
        test_update_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "prestissimo engine for running sql queries", "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications"}, "instance_id": "instance_id", "managed_by": "fully/self", "metastore_host": "1.2.3.4", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "velox": {"velox_property": ["velox_property"]}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "xyz-prestissimo-01-prestissimo-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": ["catalog_name"]}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"]}, "velox": ["velox"]}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "prestissimo", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a PrestissimoEnginePropertiesCatalog model
        prestissimo_engine_properties_catalog_model = {}
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EnginePropertiesOaiGenConfiguration model
        engine_properties_oai_gen_configuration_model = {}
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        # Construct a dict representation of a PrestissimoEnginePropertiesVelox model
        prestissimo_engine_properties_velox_model = {}
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a PrestissimoEnginePropertiesOaiGen1Jvm model
        prestissimo_engine_properties_oai_gen1_jvm_model = {}
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        # Construct a dict representation of a PrestissimoEngineEngineProperties model
        prestissimo_engine_engine_properties_model = {}
        prestissimo_engine_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        # Construct a dict representation of a RemoveEnginePropertiesConfiguration model
        remove_engine_properties_configuration_model = {}
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesPrestissimoOaiGenJvm model
        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        # Construct a dict representation of a RemoveEngineProperties model
        remove_engine_properties_model = {}
        remove_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model['velox'] = ['testString']

        # Construct a dict representation of a PrestissimoEnginePatch model
        prestissimo_engine_patch_model = {}
        prestissimo_engine_patch_model['description'] = 'updated description for prestissimo engine'
        prestissimo_engine_patch_model['engine_display_name'] = 'sampleEngine'
        prestissimo_engine_patch_model['engine_properties'] = prestissimo_engine_engine_properties_model
        prestissimo_engine_patch_model['engine_restart'] = 'force'
        prestissimo_engine_patch_model['remove_engine_properties'] = remove_engine_properties_model
        prestissimo_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = prestissimo_engine_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_prestissimo_engine(**req_copy)

    def test_update_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_update_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_update_prestissimo_engine_value_error()

        # Disable retries and run test_update_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_update_prestissimo_engine_value_error()


class TestListPrestissimoEngineCatalogs:
    """
    Test Class for list_prestissimo_engine_catalogs
    """

    @responses.activate
    def test_list_prestissimo_engine_catalogs_all_params(self):
        """
        list_prestissimo_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_prestissimo_engine_catalogs(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_prestissimo_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_list_prestissimo_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_list_prestissimo_engine_catalogs_all_params()

        # Disable retries and run test_list_prestissimo_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_list_prestissimo_engine_catalogs_all_params()

    @responses.activate
    def test_list_prestissimo_engine_catalogs_required_params(self):
        """
        test_list_prestissimo_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.list_prestissimo_engine_catalogs(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_prestissimo_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_list_prestissimo_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_list_prestissimo_engine_catalogs_required_params()

        # Disable retries and run test_list_prestissimo_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_list_prestissimo_engine_catalogs_required_params()

    @responses.activate
    def test_list_prestissimo_engine_catalogs_value_error(self):
        """
        test_list_prestissimo_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_prestissimo_engine_catalogs(**req_copy)

    def test_list_prestissimo_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_list_prestissimo_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_list_prestissimo_engine_catalogs_value_error()

        # Disable retries and run test_list_prestissimo_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_list_prestissimo_engine_catalogs_value_error()


class TestCreatePrestissimoEngineCatalogs:
    """
    Test Class for create_prestissimo_engine_catalogs
    """

    @responses.activate
    def test_create_prestissimo_engine_catalogs_all_params(self):
        """
        create_prestissimo_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_prestissimo_engine_catalogs(
            engine_id,
            catalog_names=catalog_names,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['catalog_names'] == 'testString'

    def test_create_prestissimo_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_create_prestissimo_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_create_prestissimo_engine_catalogs_all_params()

        # Disable retries and run test_create_prestissimo_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_create_prestissimo_engine_catalogs_all_params()

    @responses.activate
    def test_create_prestissimo_engine_catalogs_required_params(self):
        """
        test_create_prestissimo_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Invoke method
        response = _service.create_prestissimo_engine_catalogs(
            engine_id,
            catalog_names=catalog_names,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['catalog_names'] == 'testString'

    def test_create_prestissimo_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_create_prestissimo_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_create_prestissimo_engine_catalogs_required_params()

        # Disable retries and run test_create_prestissimo_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_create_prestissimo_engine_catalogs_required_params()

    @responses.activate
    def test_create_prestissimo_engine_catalogs_value_error(self):
        """
        test_create_prestissimo_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_prestissimo_engine_catalogs(**req_copy)

    def test_create_prestissimo_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_create_prestissimo_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_create_prestissimo_engine_catalogs_value_error()

        # Disable retries and run test_create_prestissimo_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_create_prestissimo_engine_catalogs_value_error()


class TestDeletePrestissimoEngineCatalogs:
    """
    Test Class for delete_prestissimo_engine_catalogs
    """

    @responses.activate
    def test_delete_prestissimo_engine_catalogs_all_params(self):
        """
        delete_prestissimo_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_prestissimo_engine_catalogs(
            engine_id,
            catalog_names,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_names={}'.format(catalog_names) in query_string

    def test_delete_prestissimo_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_delete_prestissimo_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_delete_prestissimo_engine_catalogs_all_params()

        # Disable retries and run test_delete_prestissimo_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_delete_prestissimo_engine_catalogs_all_params()

    @responses.activate
    def test_delete_prestissimo_engine_catalogs_required_params(self):
        """
        test_delete_prestissimo_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Invoke method
        response = _service.delete_prestissimo_engine_catalogs(
            engine_id,
            catalog_names,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_names={}'.format(catalog_names) in query_string

    def test_delete_prestissimo_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_delete_prestissimo_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_delete_prestissimo_engine_catalogs_required_params()

        # Disable retries and run test_delete_prestissimo_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_delete_prestissimo_engine_catalogs_required_params()

    @responses.activate
    def test_delete_prestissimo_engine_catalogs_value_error(self):
        """
        test_delete_prestissimo_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_names": catalog_names,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_prestissimo_engine_catalogs(**req_copy)

    def test_delete_prestissimo_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_delete_prestissimo_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_delete_prestissimo_engine_catalogs_value_error()

        # Disable retries and run test_delete_prestissimo_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_delete_prestissimo_engine_catalogs_value_error()


class TestGetPrestissimoEngineCatalog:
    """
    Test Class for get_prestissimo_engine_catalog
    """

    @responses.activate
    def test_get_prestissimo_engine_catalog_all_params(self):
        """
        get_prestissimo_engine_catalog()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_prestissimo_engine_catalog(
            engine_id,
            catalog_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_prestissimo_engine_catalog_all_params_with_retries(self):
        # Enable retries and run test_get_prestissimo_engine_catalog_all_params.
        _service.enable_retries()
        self.test_get_prestissimo_engine_catalog_all_params()

        # Disable retries and run test_get_prestissimo_engine_catalog_all_params.
        _service.disable_retries()
        self.test_get_prestissimo_engine_catalog_all_params()

    @responses.activate
    def test_get_prestissimo_engine_catalog_required_params(self):
        """
        test_get_prestissimo_engine_catalog_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Invoke method
        response = _service.get_prestissimo_engine_catalog(
            engine_id,
            catalog_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_prestissimo_engine_catalog_required_params_with_retries(self):
        # Enable retries and run test_get_prestissimo_engine_catalog_required_params.
        _service.enable_retries()
        self.test_get_prestissimo_engine_catalog_required_params()

        # Disable retries and run test_get_prestissimo_engine_catalog_required_params.
        _service.disable_retries()
        self.test_get_prestissimo_engine_catalog_required_params()

    @responses.activate
    def test_get_prestissimo_engine_catalog_value_error(self):
        """
        test_get_prestissimo_engine_catalog_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_prestissimo_engine_catalog(**req_copy)

    def test_get_prestissimo_engine_catalog_value_error_with_retries(self):
        # Enable retries and run test_get_prestissimo_engine_catalog_value_error.
        _service.enable_retries()
        self.test_get_prestissimo_engine_catalog_value_error()

        # Disable retries and run test_get_prestissimo_engine_catalog_value_error.
        _service.disable_retries()
        self.test_get_prestissimo_engine_catalog_value_error()


class TestPausePrestissimoEngine:
    """
    Test Class for pause_prestissimo_engine
    """

    @responses.activate
    def test_pause_prestissimo_engine_all_params(self):
        """
        pause_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.pause_prestissimo_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_pause_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_pause_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_pause_prestissimo_engine_all_params()

        # Disable retries and run test_pause_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_pause_prestissimo_engine_all_params()

    @responses.activate
    def test_pause_prestissimo_engine_required_params(self):
        """
        test_pause_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.pause_prestissimo_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_pause_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_pause_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_pause_prestissimo_engine_required_params()

        # Disable retries and run test_pause_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_pause_prestissimo_engine_required_params()

    @responses.activate
    def test_pause_prestissimo_engine_value_error(self):
        """
        test_pause_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.pause_prestissimo_engine(**req_copy)

    def test_pause_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_pause_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_pause_prestissimo_engine_value_error()

        # Disable retries and run test_pause_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_pause_prestissimo_engine_value_error()


class TestRunPrestissimoExplainStatement:
    """
    Test Class for run_prestissimo_explain_statement
    """

    @responses.activate
    def test_run_prestissimo_explain_statement_all_params(self):
        """
        run_prestissimo_explain_statement()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/query_explain')
        mock_response = '{"result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        format = 'json'
        type = 'io'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.run_prestissimo_explain_statement(
            engine_id,
            statement,
            format=format,
            type=type,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['format'] == 'json'
        assert req_body['type'] == 'io'

    def test_run_prestissimo_explain_statement_all_params_with_retries(self):
        # Enable retries and run test_run_prestissimo_explain_statement_all_params.
        _service.enable_retries()
        self.test_run_prestissimo_explain_statement_all_params()

        # Disable retries and run test_run_prestissimo_explain_statement_all_params.
        _service.disable_retries()
        self.test_run_prestissimo_explain_statement_all_params()

    @responses.activate
    def test_run_prestissimo_explain_statement_required_params(self):
        """
        test_run_prestissimo_explain_statement_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/query_explain')
        mock_response = '{"result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        format = 'json'
        type = 'io'

        # Invoke method
        response = _service.run_prestissimo_explain_statement(
            engine_id,
            statement,
            format=format,
            type=type,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['format'] == 'json'
        assert req_body['type'] == 'io'

    def test_run_prestissimo_explain_statement_required_params_with_retries(self):
        # Enable retries and run test_run_prestissimo_explain_statement_required_params.
        _service.enable_retries()
        self.test_run_prestissimo_explain_statement_required_params()

        # Disable retries and run test_run_prestissimo_explain_statement_required_params.
        _service.disable_retries()
        self.test_run_prestissimo_explain_statement_required_params()

    @responses.activate
    def test_run_prestissimo_explain_statement_value_error(self):
        """
        test_run_prestissimo_explain_statement_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/query_explain')
        mock_response = '{"result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        format = 'json'
        type = 'io'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "statement": statement,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.run_prestissimo_explain_statement(**req_copy)

    def test_run_prestissimo_explain_statement_value_error_with_retries(self):
        # Enable retries and run test_run_prestissimo_explain_statement_value_error.
        _service.enable_retries()
        self.test_run_prestissimo_explain_statement_value_error()

        # Disable retries and run test_run_prestissimo_explain_statement_value_error.
        _service.disable_retries()
        self.test_run_prestissimo_explain_statement_value_error()


class TestRunPrestissimoExplainAnalyzeStatement:
    """
    Test Class for run_prestissimo_explain_analyze_statement
    """

    @responses.activate
    def test_run_prestissimo_explain_analyze_statement_all_params(self):
        """
        run_prestissimo_explain_analyze_statement()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/query_explain_analyze')
        mock_response = '{"result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        verbose = True
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.run_prestissimo_explain_analyze_statement(
            engine_id,
            statement,
            verbose=verbose,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['verbose'] == True

    def test_run_prestissimo_explain_analyze_statement_all_params_with_retries(self):
        # Enable retries and run test_run_prestissimo_explain_analyze_statement_all_params.
        _service.enable_retries()
        self.test_run_prestissimo_explain_analyze_statement_all_params()

        # Disable retries and run test_run_prestissimo_explain_analyze_statement_all_params.
        _service.disable_retries()
        self.test_run_prestissimo_explain_analyze_statement_all_params()

    @responses.activate
    def test_run_prestissimo_explain_analyze_statement_required_params(self):
        """
        test_run_prestissimo_explain_analyze_statement_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/query_explain_analyze')
        mock_response = '{"result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        verbose = True

        # Invoke method
        response = _service.run_prestissimo_explain_analyze_statement(
            engine_id,
            statement,
            verbose=verbose,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['verbose'] == True

    def test_run_prestissimo_explain_analyze_statement_required_params_with_retries(self):
        # Enable retries and run test_run_prestissimo_explain_analyze_statement_required_params.
        _service.enable_retries()
        self.test_run_prestissimo_explain_analyze_statement_required_params()

        # Disable retries and run test_run_prestissimo_explain_analyze_statement_required_params.
        _service.disable_retries()
        self.test_run_prestissimo_explain_analyze_statement_required_params()

    @responses.activate
    def test_run_prestissimo_explain_analyze_statement_value_error(self):
        """
        test_run_prestissimo_explain_analyze_statement_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/query_explain_analyze')
        mock_response = '{"result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        verbose = True

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "statement": statement,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.run_prestissimo_explain_analyze_statement(**req_copy)

    def test_run_prestissimo_explain_analyze_statement_value_error_with_retries(self):
        # Enable retries and run test_run_prestissimo_explain_analyze_statement_value_error.
        _service.enable_retries()
        self.test_run_prestissimo_explain_analyze_statement_value_error()

        # Disable retries and run test_run_prestissimo_explain_analyze_statement_value_error.
        _service.disable_retries()
        self.test_run_prestissimo_explain_analyze_statement_value_error()


class TestRestartPrestissimoEngine:
    """
    Test Class for restart_prestissimo_engine
    """

    @responses.activate
    def test_restart_prestissimo_engine_all_params(self):
        """
        restart_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/restart')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.restart_prestissimo_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_restart_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_restart_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_restart_prestissimo_engine_all_params()

        # Disable retries and run test_restart_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_restart_prestissimo_engine_all_params()

    @responses.activate
    def test_restart_prestissimo_engine_required_params(self):
        """
        test_restart_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/restart')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.restart_prestissimo_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_restart_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_restart_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_restart_prestissimo_engine_required_params()

        # Disable retries and run test_restart_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_restart_prestissimo_engine_required_params()

    @responses.activate
    def test_restart_prestissimo_engine_value_error(self):
        """
        test_restart_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/restart')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.restart_prestissimo_engine(**req_copy)

    def test_restart_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_restart_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_restart_prestissimo_engine_value_error()

        # Disable retries and run test_restart_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_restart_prestissimo_engine_value_error()


class TestResumePrestissimoEngine:
    """
    Test Class for resume_prestissimo_engine
    """

    @responses.activate
    def test_resume_prestissimo_engine_all_params(self):
        """
        resume_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.resume_prestissimo_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_resume_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_resume_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_resume_prestissimo_engine_all_params()

        # Disable retries and run test_resume_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_resume_prestissimo_engine_all_params()

    @responses.activate
    def test_resume_prestissimo_engine_required_params(self):
        """
        test_resume_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.resume_prestissimo_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_resume_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_resume_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_resume_prestissimo_engine_required_params()

        # Disable retries and run test_resume_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_resume_prestissimo_engine_required_params()

    @responses.activate
    def test_resume_prestissimo_engine_value_error(self):
        """
        test_resume_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.resume_prestissimo_engine(**req_copy)

    def test_resume_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_resume_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_resume_prestissimo_engine_value_error()

        # Disable retries and run test_resume_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_resume_prestissimo_engine_value_error()


class TestScalePrestissimoEngine:
    """
    Test Class for scale_prestissimo_engine
    """

    @responses.activate
    def test_scale_prestissimo_engine_all_params(self):
        """
        scale_prestissimo_engine()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Set up parameter values
        engine_id = 'testString'
        coordinator = prestissimo_node_description_body_model
        worker = prestissimo_node_description_body_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.scale_prestissimo_engine(
            engine_id,
            coordinator=coordinator,
            worker=worker,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['coordinator'] == prestissimo_node_description_body_model
        assert req_body['worker'] == prestissimo_node_description_body_model

    def test_scale_prestissimo_engine_all_params_with_retries(self):
        # Enable retries and run test_scale_prestissimo_engine_all_params.
        _service.enable_retries()
        self.test_scale_prestissimo_engine_all_params()

        # Disable retries and run test_scale_prestissimo_engine_all_params.
        _service.disable_retries()
        self.test_scale_prestissimo_engine_all_params()

    @responses.activate
    def test_scale_prestissimo_engine_required_params(self):
        """
        test_scale_prestissimo_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Set up parameter values
        engine_id = 'testString'
        coordinator = prestissimo_node_description_body_model
        worker = prestissimo_node_description_body_model

        # Invoke method
        response = _service.scale_prestissimo_engine(
            engine_id,
            coordinator=coordinator,
            worker=worker,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['coordinator'] == prestissimo_node_description_body_model
        assert req_body['worker'] == prestissimo_node_description_body_model

    def test_scale_prestissimo_engine_required_params_with_retries(self):
        # Enable retries and run test_scale_prestissimo_engine_required_params.
        _service.enable_retries()
        self.test_scale_prestissimo_engine_required_params()

        # Disable retries and run test_scale_prestissimo_engine_required_params.
        _service.disable_retries()
        self.test_scale_prestissimo_engine_required_params()

    @responses.activate
    def test_scale_prestissimo_engine_value_error(self):
        """
        test_scale_prestissimo_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/prestissimo_engines/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model = {}
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Set up parameter values
        engine_id = 'testString'
        coordinator = prestissimo_node_description_body_model
        worker = prestissimo_node_description_body_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.scale_prestissimo_engine(**req_copy)

    def test_scale_prestissimo_engine_value_error_with_retries(self):
        # Enable retries and run test_scale_prestissimo_engine_value_error.
        _service.enable_retries()
        self.test_scale_prestissimo_engine_value_error()

        # Disable retries and run test_scale_prestissimo_engine_value_error.
        _service.disable_retries()
        self.test_scale_prestissimo_engine_value_error()


# endregion
##############################################################################
# End of Service: PrestissimoEngines
##############################################################################

##############################################################################
# Start of Service: PrestoEngines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListPrestoEngines:
    """
    Test Class for list_presto_engines
    """

    @responses.activate
    def test_list_presto_engines_all_params(self):
        """
        list_presto_engines()
        """
        # Set up mock
        url = preprocess_url('/presto_engines')
        mock_response = '{"presto_engines": [{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_presto_engines(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_presto_engines_all_params_with_retries(self):
        # Enable retries and run test_list_presto_engines_all_params.
        _service.enable_retries()
        self.test_list_presto_engines_all_params()

        # Disable retries and run test_list_presto_engines_all_params.
        _service.disable_retries()
        self.test_list_presto_engines_all_params()

    @responses.activate
    def test_list_presto_engines_required_params(self):
        """
        test_list_presto_engines_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines')
        mock_response = '{"presto_engines": [{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_presto_engines()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_presto_engines_required_params_with_retries(self):
        # Enable retries and run test_list_presto_engines_required_params.
        _service.enable_retries()
        self.test_list_presto_engines_required_params()

        # Disable retries and run test_list_presto_engines_required_params.
        _service.disable_retries()
        self.test_list_presto_engines_required_params()


class TestCreatePrestoEngine:
    """
    Test Class for create_presto_engine
    """

    @responses.activate
    def test_create_presto_engine_all_params(self):
        """
        create_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EngineDetailsBody model
        engine_details_body_model = {}
        engine_details_body_model['api_key'] = '<api_key>'
        engine_details_body_model['connection_string'] = '1.2.3.4'
        engine_details_body_model['coordinator'] = node_description_body_model
        engine_details_body_model['instance_id'] = 'instance_id'
        engine_details_body_model['managed_by'] = 'fully/self'
        engine_details_body_model['size_config'] = 'starter'
        engine_details_body_model['worker'] = node_description_body_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['iceberg-data', 'hive-data']
        description = 'presto engine for running sql queries'
        engine_details = engine_details_body_model
        engine_display_name = 'sampleEngine'
        region = 'us-south'
        tags = ['tag1', 'tag2']
        version = '1.2.3'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_presto_engine(
            origin,
            associated_catalogs=associated_catalogs,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            region=region,
            tags=tags,
            version=version,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'native'
        assert req_body['associated_catalogs'] == ['iceberg-data', 'hive-data']
        assert req_body['description'] == 'presto engine for running sql queries'
        assert req_body['engine_details'] == engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['region'] == 'us-south'
        assert req_body['tags'] == ['tag1', 'tag2']
        assert req_body['version'] == '1.2.3'

    def test_create_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_create_presto_engine_all_params.
        _service.enable_retries()
        self.test_create_presto_engine_all_params()

        # Disable retries and run test_create_presto_engine_all_params.
        _service.disable_retries()
        self.test_create_presto_engine_all_params()

    @responses.activate
    def test_create_presto_engine_required_params(self):
        """
        test_create_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EngineDetailsBody model
        engine_details_body_model = {}
        engine_details_body_model['api_key'] = '<api_key>'
        engine_details_body_model['connection_string'] = '1.2.3.4'
        engine_details_body_model['coordinator'] = node_description_body_model
        engine_details_body_model['instance_id'] = 'instance_id'
        engine_details_body_model['managed_by'] = 'fully/self'
        engine_details_body_model['size_config'] = 'starter'
        engine_details_body_model['worker'] = node_description_body_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['iceberg-data', 'hive-data']
        description = 'presto engine for running sql queries'
        engine_details = engine_details_body_model
        engine_display_name = 'sampleEngine'
        region = 'us-south'
        tags = ['tag1', 'tag2']
        version = '1.2.3'

        # Invoke method
        response = _service.create_presto_engine(
            origin,
            associated_catalogs=associated_catalogs,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            region=region,
            tags=tags,
            version=version,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'native'
        assert req_body['associated_catalogs'] == ['iceberg-data', 'hive-data']
        assert req_body['description'] == 'presto engine for running sql queries'
        assert req_body['engine_details'] == engine_details_body_model
        assert req_body['engine_display_name'] == 'sampleEngine'
        assert req_body['region'] == 'us-south'
        assert req_body['tags'] == ['tag1', 'tag2']
        assert req_body['version'] == '1.2.3'

    def test_create_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_create_presto_engine_required_params.
        _service.enable_retries()
        self.test_create_presto_engine_required_params()

        # Disable retries and run test_create_presto_engine_required_params.
        _service.disable_retries()
        self.test_create_presto_engine_required_params()

    @responses.activate
    def test_create_presto_engine_value_error(self):
        """
        test_create_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EngineDetailsBody model
        engine_details_body_model = {}
        engine_details_body_model['api_key'] = '<api_key>'
        engine_details_body_model['connection_string'] = '1.2.3.4'
        engine_details_body_model['coordinator'] = node_description_body_model
        engine_details_body_model['instance_id'] = 'instance_id'
        engine_details_body_model['managed_by'] = 'fully/self'
        engine_details_body_model['size_config'] = 'starter'
        engine_details_body_model['worker'] = node_description_body_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['iceberg-data', 'hive-data']
        description = 'presto engine for running sql queries'
        engine_details = engine_details_body_model
        engine_display_name = 'sampleEngine'
        region = 'us-south'
        tags = ['tag1', 'tag2']
        version = '1.2.3'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "origin": origin,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_presto_engine(**req_copy)

    def test_create_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_create_presto_engine_value_error.
        _service.enable_retries()
        self.test_create_presto_engine_value_error()

        # Disable retries and run test_create_presto_engine_value_error.
        _service.disable_retries()
        self.test_create_presto_engine_value_error()


class TestGetPrestoEngine:
    """
    Test Class for get_presto_engine
    """

    @responses.activate
    def test_get_presto_engine_all_params(self):
        """
        get_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_presto_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_get_presto_engine_all_params.
        _service.enable_retries()
        self.test_get_presto_engine_all_params()

        # Disable retries and run test_get_presto_engine_all_params.
        _service.disable_retries()
        self.test_get_presto_engine_all_params()

    @responses.activate
    def test_get_presto_engine_required_params(self):
        """
        test_get_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.get_presto_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_get_presto_engine_required_params.
        _service.enable_retries()
        self.test_get_presto_engine_required_params()

        # Disable retries and run test_get_presto_engine_required_params.
        _service.disable_retries()
        self.test_get_presto_engine_required_params()

    @responses.activate
    def test_get_presto_engine_value_error(self):
        """
        test_get_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_presto_engine(**req_copy)

    def test_get_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_get_presto_engine_value_error.
        _service.enable_retries()
        self.test_get_presto_engine_value_error()

        # Disable retries and run test_get_presto_engine_value_error.
        _service.disable_retries()
        self.test_get_presto_engine_value_error()


class TestDeleteEngine:
    """
    Test Class for delete_engine
    """

    @responses.activate
    def test_delete_engine_all_params(self):
        """
        delete_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_engine_all_params_with_retries(self):
        # Enable retries and run test_delete_engine_all_params.
        _service.enable_retries()
        self.test_delete_engine_all_params()

        # Disable retries and run test_delete_engine_all_params.
        _service.disable_retries()
        self.test_delete_engine_all_params()

    @responses.activate
    def test_delete_engine_required_params(self):
        """
        test_delete_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_engine_required_params_with_retries(self):
        # Enable retries and run test_delete_engine_required_params.
        _service.enable_retries()
        self.test_delete_engine_required_params()

        # Disable retries and run test_delete_engine_required_params.
        _service.disable_retries()
        self.test_delete_engine_required_params()

    @responses.activate
    def test_delete_engine_value_error(self):
        """
        test_delete_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_engine(**req_copy)

    def test_delete_engine_value_error_with_retries(self):
        # Enable retries and run test_delete_engine_value_error.
        _service.enable_retries()
        self.test_delete_engine_value_error()

        # Disable retries and run test_delete_engine_value_error.
        _service.disable_retries()
        self.test_delete_engine_value_error()


class TestUpdatePrestoEngine:
    """
    Test Class for update_presto_engine
    """

    @responses.activate
    def test_update_presto_engine_all_params(self):
        """
        update_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a PrestoEnginePropertiesCatalog model
        presto_engine_properties_catalog_model = {}
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EnginePropertiesOaiGen1Configuration model
        engine_properties_oai_gen1_configuration_model = {}
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEnginePropertiesEventListener model
        presto_engine_properties_event_listener_model = {}
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        # Construct a dict representation of a PrestoEnginePropertiesGlobal model
        presto_engine_properties_global_model = {}
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        # Construct a dict representation of a EnginePropertiesOaiGen1Jvm model
        engine_properties_oai_gen1_jvm_model = {}
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEnginePropertiesJMX model
        presto_engine_properties_jmx_model = {}
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        # Construct a dict representation of a EnginePropertiesLogConfiguration model
        engine_properties_log_configuration_model = {}
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEngineEngineProperties model
        presto_engine_engine_properties_model = {}
        presto_engine_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model['log_config'] = engine_properties_log_configuration_model

        # Construct a dict representation of a RemoveEnginePropertiesOaiGenConfiguration model
        remove_engine_properties_oai_gen_configuration_model = {}
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesOaiGenJvm model
        remove_engine_properties_oai_gen_jvm_model = {}
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesLogConfig model
        remove_engine_properties_log_config_model = {}
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        # Construct a dict representation of a PrestoEnginePatchRemoveEngineProperties model
        presto_engine_patch_remove_engine_properties_model = {}
        presto_engine_patch_remove_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['log_config'] = remove_engine_properties_log_config_model

        # Construct a dict representation of a PrestoEnginePatch model
        presto_engine_patch_model = {}
        presto_engine_patch_model['description'] = 'updated description for presto engine'
        presto_engine_patch_model['engine_display_name'] = 'sampleEngine'
        presto_engine_patch_model['engine_properties'] = presto_engine_engine_properties_model
        presto_engine_patch_model['engine_restart'] = 'force'
        presto_engine_patch_model['remove_engine_properties'] = presto_engine_patch_remove_engine_properties_model
        presto_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = presto_engine_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_presto_engine(
            engine_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_update_presto_engine_all_params.
        _service.enable_retries()
        self.test_update_presto_engine_all_params()

        # Disable retries and run test_update_presto_engine_all_params.
        _service.disable_retries()
        self.test_update_presto_engine_all_params()

    @responses.activate
    def test_update_presto_engine_required_params(self):
        """
        test_update_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a PrestoEnginePropertiesCatalog model
        presto_engine_properties_catalog_model = {}
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EnginePropertiesOaiGen1Configuration model
        engine_properties_oai_gen1_configuration_model = {}
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEnginePropertiesEventListener model
        presto_engine_properties_event_listener_model = {}
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        # Construct a dict representation of a PrestoEnginePropertiesGlobal model
        presto_engine_properties_global_model = {}
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        # Construct a dict representation of a EnginePropertiesOaiGen1Jvm model
        engine_properties_oai_gen1_jvm_model = {}
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEnginePropertiesJMX model
        presto_engine_properties_jmx_model = {}
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        # Construct a dict representation of a EnginePropertiesLogConfiguration model
        engine_properties_log_configuration_model = {}
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEngineEngineProperties model
        presto_engine_engine_properties_model = {}
        presto_engine_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model['log_config'] = engine_properties_log_configuration_model

        # Construct a dict representation of a RemoveEnginePropertiesOaiGenConfiguration model
        remove_engine_properties_oai_gen_configuration_model = {}
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesOaiGenJvm model
        remove_engine_properties_oai_gen_jvm_model = {}
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesLogConfig model
        remove_engine_properties_log_config_model = {}
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        # Construct a dict representation of a PrestoEnginePatchRemoveEngineProperties model
        presto_engine_patch_remove_engine_properties_model = {}
        presto_engine_patch_remove_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['log_config'] = remove_engine_properties_log_config_model

        # Construct a dict representation of a PrestoEnginePatch model
        presto_engine_patch_model = {}
        presto_engine_patch_model['description'] = 'updated description for presto engine'
        presto_engine_patch_model['engine_display_name'] = 'sampleEngine'
        presto_engine_patch_model['engine_properties'] = presto_engine_engine_properties_model
        presto_engine_patch_model['engine_restart'] = 'force'
        presto_engine_patch_model['remove_engine_properties'] = presto_engine_patch_remove_engine_properties_model
        presto_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = presto_engine_patch_model

        # Invoke method
        response = _service.update_presto_engine(
            engine_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_update_presto_engine_required_params.
        _service.enable_retries()
        self.test_update_presto_engine_required_params()

        # Disable retries and run test_update_presto_engine_required_params.
        _service.disable_retries()
        self.test_update_presto_engine_required_params()

    @responses.activate
    def test_update_presto_engine_value_error(self):
        """
        test_update_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "coordinator": {"node_type": "worker", "quantity": 8}, "created_by": "<username>@<domain>.com", "created_on": 10, "description": "presto engine for running sql queries", "drivers": [{"connection_type": "saphana", "driver_id": "saphanadriver123", "driver_name": "saphanadriver-1.2.3", "driver_version": "1.2.3"}], "engine_details": {"api_key": "<api_key>", "connection_string": "1.2.3.4", "coordinator": {"node_type": "worker", "quantity": 8}, "instance_id": "instance_id", "managed_by": "fully/self", "size_config": "starter", "worker": {"node_type": "worker", "quantity": 8}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "event_listener": {"event_listener_property": "event_listener_property"}, "global": {"global_property": "enable-mixed-case-support:true"}, "jvm": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}, "jmx_exporter_config": {"global_property": "watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes"}, "log_config": {"coordinator": {"node_type": "worker", "quantity": 8}, "worker": {"node_type": "worker", "quantity": 8}}}, "engine_restart": "force", "external_host_name": "your-hostname.apps.your-domain.com", "group_id": "new_group_id", "host_name": "ibm-lh-lakehouse-presto-01-presto-svc", "origin": "native", "port": 4, "region": "us-south", "remove_engine_properties": {"catalog": {"catalog_name": "catalog_name"}, "configuration": {"coordinator": ["coordinator"], "worker": ["worker"]}, "jvm": {"coordinator": ["coordinator"], "worker": ["worker"]}, "event_listener": ["event_listener"], "global": ["global_"], "jmx_exporter_config": ["jmx_exporter_config"], "log_config": {"coordinator": ["coordinator"], "worker": ["worker"]}}, "size_config": "starter", "status": "running", "status_code": 11, "tags": ["tags"], "type": "presto", "version": "1.2.0", "worker": {"node_type": "worker", "quantity": 8}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a PrestoEnginePropertiesCatalog model
        presto_engine_properties_catalog_model = {}
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        # Construct a dict representation of a NodeDescriptionBody model
        node_description_body_model = {}
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a dict representation of a EnginePropertiesOaiGen1Configuration model
        engine_properties_oai_gen1_configuration_model = {}
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEnginePropertiesEventListener model
        presto_engine_properties_event_listener_model = {}
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        # Construct a dict representation of a PrestoEnginePropertiesGlobal model
        presto_engine_properties_global_model = {}
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        # Construct a dict representation of a EnginePropertiesOaiGen1Jvm model
        engine_properties_oai_gen1_jvm_model = {}
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEnginePropertiesJMX model
        presto_engine_properties_jmx_model = {}
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        # Construct a dict representation of a EnginePropertiesLogConfiguration model
        engine_properties_log_configuration_model = {}
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        # Construct a dict representation of a PrestoEngineEngineProperties model
        presto_engine_engine_properties_model = {}
        presto_engine_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model['log_config'] = engine_properties_log_configuration_model

        # Construct a dict representation of a RemoveEnginePropertiesOaiGenConfiguration model
        remove_engine_properties_oai_gen_configuration_model = {}
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesOaiGenJvm model
        remove_engine_properties_oai_gen_jvm_model = {}
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        # Construct a dict representation of a RemoveEnginePropertiesLogConfig model
        remove_engine_properties_log_config_model = {}
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        # Construct a dict representation of a PrestoEnginePatchRemoveEngineProperties model
        presto_engine_patch_remove_engine_properties_model = {}
        presto_engine_patch_remove_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['log_config'] = remove_engine_properties_log_config_model

        # Construct a dict representation of a PrestoEnginePatch model
        presto_engine_patch_model = {}
        presto_engine_patch_model['description'] = 'updated description for presto engine'
        presto_engine_patch_model['engine_display_name'] = 'sampleEngine'
        presto_engine_patch_model['engine_properties'] = presto_engine_engine_properties_model
        presto_engine_patch_model['engine_restart'] = 'force'
        presto_engine_patch_model['remove_engine_properties'] = presto_engine_patch_remove_engine_properties_model
        presto_engine_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = presto_engine_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_presto_engine(**req_copy)

    def test_update_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_update_presto_engine_value_error.
        _service.enable_retries()
        self.test_update_presto_engine_value_error()

        # Disable retries and run test_update_presto_engine_value_error.
        _service.disable_retries()
        self.test_update_presto_engine_value_error()


class TestListPrestoEngineCatalogs:
    """
    Test Class for list_presto_engine_catalogs
    """

    @responses.activate
    def test_list_presto_engine_catalogs_all_params(self):
        """
        list_presto_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_presto_engine_catalogs(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_presto_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_list_presto_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_list_presto_engine_catalogs_all_params()

        # Disable retries and run test_list_presto_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_list_presto_engine_catalogs_all_params()

    @responses.activate
    def test_list_presto_engine_catalogs_required_params(self):
        """
        test_list_presto_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.list_presto_engine_catalogs(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_presto_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_list_presto_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_list_presto_engine_catalogs_required_params()

        # Disable retries and run test_list_presto_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_list_presto_engine_catalogs_required_params()

    @responses.activate
    def test_list_presto_engine_catalogs_value_error(self):
        """
        test_list_presto_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_presto_engine_catalogs(**req_copy)

    def test_list_presto_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_list_presto_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_list_presto_engine_catalogs_value_error()

        # Disable retries and run test_list_presto_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_list_presto_engine_catalogs_value_error()


class TestCreatePrestoEngineCatalogs:
    """
    Test Class for create_presto_engine_catalogs
    """

    @responses.activate
    def test_create_presto_engine_catalogs_all_params(self):
        """
        create_presto_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_presto_engine_catalogs(
            engine_id,
            catalog_names=catalog_names,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['catalog_names'] == 'testString'

    def test_create_presto_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_create_presto_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_create_presto_engine_catalogs_all_params()

        # Disable retries and run test_create_presto_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_create_presto_engine_catalogs_all_params()

    @responses.activate
    def test_create_presto_engine_catalogs_required_params(self):
        """
        test_create_presto_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Invoke method
        response = _service.create_presto_engine_catalogs(
            engine_id,
            catalog_names=catalog_names,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['catalog_names'] == 'testString'

    def test_create_presto_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_create_presto_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_create_presto_engine_catalogs_required_params()

        # Disable retries and run test_create_presto_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_create_presto_engine_catalogs_required_params()

    @responses.activate
    def test_create_presto_engine_catalogs_value_error(self):
        """
        test_create_presto_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_presto_engine_catalogs(**req_copy)

    def test_create_presto_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_create_presto_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_create_presto_engine_catalogs_value_error()

        # Disable retries and run test_create_presto_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_create_presto_engine_catalogs_value_error()


class TestDeletePrestoEngineCatalogs:
    """
    Test Class for delete_presto_engine_catalogs
    """

    @responses.activate
    def test_delete_presto_engine_catalogs_all_params(self):
        """
        delete_presto_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_presto_engine_catalogs(
            engine_id,
            catalog_names,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_names={}'.format(catalog_names) in query_string

    def test_delete_presto_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_delete_presto_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_delete_presto_engine_catalogs_all_params()

        # Disable retries and run test_delete_presto_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_delete_presto_engine_catalogs_all_params()

    @responses.activate
    def test_delete_presto_engine_catalogs_required_params(self):
        """
        test_delete_presto_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Invoke method
        response = _service.delete_presto_engine_catalogs(
            engine_id,
            catalog_names,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_names={}'.format(catalog_names) in query_string

    def test_delete_presto_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_delete_presto_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_delete_presto_engine_catalogs_required_params()

        # Disable retries and run test_delete_presto_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_delete_presto_engine_catalogs_required_params()

    @responses.activate
    def test_delete_presto_engine_catalogs_value_error(self):
        """
        test_delete_presto_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_names": catalog_names,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_presto_engine_catalogs(**req_copy)

    def test_delete_presto_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_delete_presto_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_delete_presto_engine_catalogs_value_error()

        # Disable retries and run test_delete_presto_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_delete_presto_engine_catalogs_value_error()


class TestGetPrestoEngineCatalog:
    """
    Test Class for get_presto_engine_catalog
    """

    @responses.activate
    def test_get_presto_engine_catalog_all_params(self):
        """
        get_presto_engine_catalog()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_presto_engine_catalog(
            engine_id,
            catalog_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_presto_engine_catalog_all_params_with_retries(self):
        # Enable retries and run test_get_presto_engine_catalog_all_params.
        _service.enable_retries()
        self.test_get_presto_engine_catalog_all_params()

        # Disable retries and run test_get_presto_engine_catalog_all_params.
        _service.disable_retries()
        self.test_get_presto_engine_catalog_all_params()

    @responses.activate
    def test_get_presto_engine_catalog_required_params(self):
        """
        test_get_presto_engine_catalog_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Invoke method
        response = _service.get_presto_engine_catalog(
            engine_id,
            catalog_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_presto_engine_catalog_required_params_with_retries(self):
        # Enable retries and run test_get_presto_engine_catalog_required_params.
        _service.enable_retries()
        self.test_get_presto_engine_catalog_required_params()

        # Disable retries and run test_get_presto_engine_catalog_required_params.
        _service.disable_retries()
        self.test_get_presto_engine_catalog_required_params()

    @responses.activate
    def test_get_presto_engine_catalog_value_error(self):
        """
        test_get_presto_engine_catalog_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_presto_engine_catalog(**req_copy)

    def test_get_presto_engine_catalog_value_error_with_retries(self):
        # Enable retries and run test_get_presto_engine_catalog_value_error.
        _service.enable_retries()
        self.test_get_presto_engine_catalog_value_error()

        # Disable retries and run test_get_presto_engine_catalog_value_error.
        _service.disable_retries()
        self.test_get_presto_engine_catalog_value_error()


class TestPausePrestoEngine:
    """
    Test Class for pause_presto_engine
    """

    @responses.activate
    def test_pause_presto_engine_all_params(self):
        """
        pause_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/pause')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.pause_presto_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_pause_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_pause_presto_engine_all_params.
        _service.enable_retries()
        self.test_pause_presto_engine_all_params()

        # Disable retries and run test_pause_presto_engine_all_params.
        _service.disable_retries()
        self.test_pause_presto_engine_all_params()

    @responses.activate
    def test_pause_presto_engine_required_params(self):
        """
        test_pause_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/pause')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.pause_presto_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_pause_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_pause_presto_engine_required_params.
        _service.enable_retries()
        self.test_pause_presto_engine_required_params()

        # Disable retries and run test_pause_presto_engine_required_params.
        _service.disable_retries()
        self.test_pause_presto_engine_required_params()

    @responses.activate
    def test_pause_presto_engine_value_error(self):
        """
        test_pause_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/pause')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.pause_presto_engine(**req_copy)

    def test_pause_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_pause_presto_engine_value_error.
        _service.enable_retries()
        self.test_pause_presto_engine_value_error()

        # Disable retries and run test_pause_presto_engine_value_error.
        _service.disable_retries()
        self.test_pause_presto_engine_value_error()


class TestRunExplainStatement:
    """
    Test Class for run_explain_statement
    """

    @responses.activate
    def test_run_explain_statement_all_params(self):
        """
        run_explain_statement()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/query_explain')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        format = 'json'
        type = 'io'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.run_explain_statement(
            engine_id,
            statement,
            format=format,
            type=type,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['format'] == 'json'
        assert req_body['type'] == 'io'

    def test_run_explain_statement_all_params_with_retries(self):
        # Enable retries and run test_run_explain_statement_all_params.
        _service.enable_retries()
        self.test_run_explain_statement_all_params()

        # Disable retries and run test_run_explain_statement_all_params.
        _service.disable_retries()
        self.test_run_explain_statement_all_params()

    @responses.activate
    def test_run_explain_statement_required_params(self):
        """
        test_run_explain_statement_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/query_explain')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        format = 'json'
        type = 'io'

        # Invoke method
        response = _service.run_explain_statement(
            engine_id,
            statement,
            format=format,
            type=type,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['format'] == 'json'
        assert req_body['type'] == 'io'

    def test_run_explain_statement_required_params_with_retries(self):
        # Enable retries and run test_run_explain_statement_required_params.
        _service.enable_retries()
        self.test_run_explain_statement_required_params()

        # Disable retries and run test_run_explain_statement_required_params.
        _service.disable_retries()
        self.test_run_explain_statement_required_params()

    @responses.activate
    def test_run_explain_statement_value_error(self):
        """
        test_run_explain_statement_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/query_explain')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        format = 'json'
        type = 'io'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "statement": statement,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.run_explain_statement(**req_copy)

    def test_run_explain_statement_value_error_with_retries(self):
        # Enable retries and run test_run_explain_statement_value_error.
        _service.enable_retries()
        self.test_run_explain_statement_value_error()

        # Disable retries and run test_run_explain_statement_value_error.
        _service.disable_retries()
        self.test_run_explain_statement_value_error()


class TestRunExplainAnalyzeStatement:
    """
    Test Class for run_explain_analyze_statement
    """

    @responses.activate
    def test_run_explain_analyze_statement_all_params(self):
        """
        run_explain_analyze_statement()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/query_explain_analyze')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        verbose = True
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.run_explain_analyze_statement(
            engine_id,
            statement,
            verbose=verbose,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['verbose'] == True

    def test_run_explain_analyze_statement_all_params_with_retries(self):
        # Enable retries and run test_run_explain_analyze_statement_all_params.
        _service.enable_retries()
        self.test_run_explain_analyze_statement_all_params()

        # Disable retries and run test_run_explain_analyze_statement_all_params.
        _service.disable_retries()
        self.test_run_explain_analyze_statement_all_params()

    @responses.activate
    def test_run_explain_analyze_statement_required_params(self):
        """
        test_run_explain_analyze_statement_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/query_explain_analyze')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        verbose = True

        # Invoke method
        response = _service.run_explain_analyze_statement(
            engine_id,
            statement,
            verbose=verbose,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['statement'] == 'show schemas in catalog_name'
        assert req_body['verbose'] == True

    def test_run_explain_analyze_statement_required_params_with_retries(self):
        # Enable retries and run test_run_explain_analyze_statement_required_params.
        _service.enable_retries()
        self.test_run_explain_analyze_statement_required_params()

        # Disable retries and run test_run_explain_analyze_statement_required_params.
        _service.disable_retries()
        self.test_run_explain_analyze_statement_required_params()

    @responses.activate
    def test_run_explain_analyze_statement_value_error(self):
        """
        test_run_explain_analyze_statement_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/query_explain_analyze')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "result": "result"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        statement = 'show schemas in catalog_name'
        verbose = True

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "statement": statement,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.run_explain_analyze_statement(**req_copy)

    def test_run_explain_analyze_statement_value_error_with_retries(self):
        # Enable retries and run test_run_explain_analyze_statement_value_error.
        _service.enable_retries()
        self.test_run_explain_analyze_statement_value_error()

        # Disable retries and run test_run_explain_analyze_statement_value_error.
        _service.disable_retries()
        self.test_run_explain_analyze_statement_value_error()


class TestRestartPrestoEngine:
    """
    Test Class for restart_presto_engine
    """

    @responses.activate
    def test_restart_presto_engine_all_params(self):
        """
        restart_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/restart')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.restart_presto_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_restart_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_restart_presto_engine_all_params.
        _service.enable_retries()
        self.test_restart_presto_engine_all_params()

        # Disable retries and run test_restart_presto_engine_all_params.
        _service.disable_retries()
        self.test_restart_presto_engine_all_params()

    @responses.activate
    def test_restart_presto_engine_required_params(self):
        """
        test_restart_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/restart')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.restart_presto_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_restart_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_restart_presto_engine_required_params.
        _service.enable_retries()
        self.test_restart_presto_engine_required_params()

        # Disable retries and run test_restart_presto_engine_required_params.
        _service.disable_retries()
        self.test_restart_presto_engine_required_params()

    @responses.activate
    def test_restart_presto_engine_value_error(self):
        """
        test_restart_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/restart')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.restart_presto_engine(**req_copy)

    def test_restart_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_restart_presto_engine_value_error.
        _service.enable_retries()
        self.test_restart_presto_engine_value_error()

        # Disable retries and run test_restart_presto_engine_value_error.
        _service.disable_retries()
        self.test_restart_presto_engine_value_error()


class TestResumePrestoEngine:
    """
    Test Class for resume_presto_engine
    """

    @responses.activate
    def test_resume_presto_engine_all_params(self):
        """
        resume_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/resume')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.resume_presto_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_resume_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_resume_presto_engine_all_params.
        _service.enable_retries()
        self.test_resume_presto_engine_all_params()

        # Disable retries and run test_resume_presto_engine_all_params.
        _service.disable_retries()
        self.test_resume_presto_engine_all_params()

    @responses.activate
    def test_resume_presto_engine_required_params(self):
        """
        test_resume_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/resume')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.resume_presto_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_resume_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_resume_presto_engine_required_params.
        _service.enable_retries()
        self.test_resume_presto_engine_required_params()

        # Disable retries and run test_resume_presto_engine_required_params.
        _service.disable_retries()
        self.test_resume_presto_engine_required_params()

    @responses.activate
    def test_resume_presto_engine_value_error(self):
        """
        test_resume_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/resume')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.resume_presto_engine(**req_copy)

    def test_resume_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_resume_presto_engine_value_error.
        _service.enable_retries()
        self.test_resume_presto_engine_value_error()

        # Disable retries and run test_resume_presto_engine_value_error.
        _service.disable_retries()
        self.test_resume_presto_engine_value_error()


class TestScalePrestoEngine:
    """
    Test Class for scale_presto_engine
    """

    @responses.activate
    def test_scale_presto_engine_all_params(self):
        """
        scale_presto_engine()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/scale')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a NodeDescription model
        node_description_model = {}
        node_description_model['node_type'] = 'worker'
        node_description_model['quantity'] = 38

        # Set up parameter values
        engine_id = 'testString'
        coordinator = node_description_model
        worker = node_description_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.scale_presto_engine(
            engine_id,
            coordinator=coordinator,
            worker=worker,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['coordinator'] == node_description_model
        assert req_body['worker'] == node_description_model

    def test_scale_presto_engine_all_params_with_retries(self):
        # Enable retries and run test_scale_presto_engine_all_params.
        _service.enable_retries()
        self.test_scale_presto_engine_all_params()

        # Disable retries and run test_scale_presto_engine_all_params.
        _service.disable_retries()
        self.test_scale_presto_engine_all_params()

    @responses.activate
    def test_scale_presto_engine_required_params(self):
        """
        test_scale_presto_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/scale')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a NodeDescription model
        node_description_model = {}
        node_description_model['node_type'] = 'worker'
        node_description_model['quantity'] = 38

        # Set up parameter values
        engine_id = 'testString'
        coordinator = node_description_model
        worker = node_description_model

        # Invoke method
        response = _service.scale_presto_engine(
            engine_id,
            coordinator=coordinator,
            worker=worker,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['coordinator'] == node_description_model
        assert req_body['worker'] == node_description_model

    def test_scale_presto_engine_required_params_with_retries(self):
        # Enable retries and run test_scale_presto_engine_required_params.
        _service.enable_retries()
        self.test_scale_presto_engine_required_params()

        # Disable retries and run test_scale_presto_engine_required_params.
        _service.disable_retries()
        self.test_scale_presto_engine_required_params()

    @responses.activate
    def test_scale_presto_engine_value_error(self):
        """
        test_scale_presto_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/presto_engines/testString/scale')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a NodeDescription model
        node_description_model = {}
        node_description_model['node_type'] = 'worker'
        node_description_model['quantity'] = 38

        # Set up parameter values
        engine_id = 'testString'
        coordinator = node_description_model
        worker = node_description_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.scale_presto_engine(**req_copy)

    def test_scale_presto_engine_value_error_with_retries(self):
        # Enable retries and run test_scale_presto_engine_value_error.
        _service.enable_retries()
        self.test_scale_presto_engine_value_error()

        # Disable retries and run test_scale_presto_engine_value_error.
        _service.disable_retries()
        self.test_scale_presto_engine_value_error()


# endregion
##############################################################################
# End of Service: PrestoEngines
##############################################################################

##############################################################################
# Start of Service: SemanticAutomationLayer
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestGetSalIntegration:
    """
    Test Class for get_sal_integration
    """

    @responses.activate
    def test_get_sal_integration_all_params(self):
        """
        get_sal_integration()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_all_params()

        # Disable retries and run test_get_sal_integration_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_all_params()

    @responses.activate
    def test_get_sal_integration_required_params(self):
        """
        test_get_sal_integration_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_required_params()

        # Disable retries and run test_get_sal_integration_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_required_params()


class TestCreateSalIntegration:
    """
    Test Class for create_sal_integration
    """

    @responses.activate
    def test_create_sal_integration_all_params(self):
        """
        create_sal_integration()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        apikey = '12efd3raq'
        engine_id = 'presto-01'
        storage_resource_crn = 'crn:v1:staging:public:cloud-object-storage:global:a/a7026b374f39f570d20984c1ac6ecf63:5778e94f-c8c7-46a8-9878-d5eeadb51161'
        storage_type = 'bmcos_object_storage'
        trial_plan = True
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_sal_integration(
            apikey,
            engine_id,
            storage_resource_crn=storage_resource_crn,
            storage_type=storage_type,
            trial_plan=trial_plan,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['apikey'] == '12efd3raq'
        assert req_body['engine_id'] == 'presto-01'
        assert req_body['storage_resource_crn'] == 'crn:v1:staging:public:cloud-object-storage:global:a/a7026b374f39f570d20984c1ac6ecf63:5778e94f-c8c7-46a8-9878-d5eeadb51161'
        assert req_body['storage_type'] == 'bmcos_object_storage'
        assert req_body['trial_plan'] == True

    def test_create_sal_integration_all_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_all_params.
        _service.enable_retries()
        self.test_create_sal_integration_all_params()

        # Disable retries and run test_create_sal_integration_all_params.
        _service.disable_retries()
        self.test_create_sal_integration_all_params()

    @responses.activate
    def test_create_sal_integration_required_params(self):
        """
        test_create_sal_integration_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        apikey = '12efd3raq'
        engine_id = 'presto-01'
        storage_resource_crn = 'crn:v1:staging:public:cloud-object-storage:global:a/a7026b374f39f570d20984c1ac6ecf63:5778e94f-c8c7-46a8-9878-d5eeadb51161'
        storage_type = 'bmcos_object_storage'
        trial_plan = True

        # Invoke method
        response = _service.create_sal_integration(
            apikey,
            engine_id,
            storage_resource_crn=storage_resource_crn,
            storage_type=storage_type,
            trial_plan=trial_plan,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['apikey'] == '12efd3raq'
        assert req_body['engine_id'] == 'presto-01'
        assert req_body['storage_resource_crn'] == 'crn:v1:staging:public:cloud-object-storage:global:a/a7026b374f39f570d20984c1ac6ecf63:5778e94f-c8c7-46a8-9878-d5eeadb51161'
        assert req_body['storage_type'] == 'bmcos_object_storage'
        assert req_body['trial_plan'] == True

    def test_create_sal_integration_required_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_required_params.
        _service.enable_retries()
        self.test_create_sal_integration_required_params()

        # Disable retries and run test_create_sal_integration_required_params.
        _service.disable_retries()
        self.test_create_sal_integration_required_params()

    @responses.activate
    def test_create_sal_integration_value_error(self):
        """
        test_create_sal_integration_value_error()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        apikey = '12efd3raq'
        engine_id = 'presto-01'
        storage_resource_crn = 'crn:v1:staging:public:cloud-object-storage:global:a/a7026b374f39f570d20984c1ac6ecf63:5778e94f-c8c7-46a8-9878-d5eeadb51161'
        storage_type = 'bmcos_object_storage'
        trial_plan = True

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "apikey": apikey,
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_sal_integration(**req_copy)

    def test_create_sal_integration_value_error_with_retries(self):
        # Enable retries and run test_create_sal_integration_value_error.
        _service.enable_retries()
        self.test_create_sal_integration_value_error()

        # Disable retries and run test_create_sal_integration_value_error.
        _service.disable_retries()
        self.test_create_sal_integration_value_error()


class TestDeleteSalIntegration:
    """
    Test Class for delete_sal_integration
    """

    @responses.activate
    def test_delete_sal_integration_all_params(self):
        """
        delete_sal_integration()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Invoke method
        response = _service.delete_sal_integration()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_sal_integration_all_params_with_retries(self):
        # Enable retries and run test_delete_sal_integration_all_params.
        _service.enable_retries()
        self.test_delete_sal_integration_all_params()

        # Disable retries and run test_delete_sal_integration_all_params.
        _service.disable_retries()
        self.test_delete_sal_integration_all_params()


class TestUpdateSalIntegration:
    """
    Test Class for update_sal_integration
    """

    @responses.activate
    def test_update_sal_integration_all_params(self):
        """
        update_sal_integration()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SalIntegrationPatch model
        sal_integration_patch_model = {}
        sal_integration_patch_model['op'] = 'add'
        sal_integration_patch_model['path'] = 'storage'
        sal_integration_patch_model['value'] = 'new-apikey'

        # Set up parameter values
        body = sal_integration_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_sal_integration(
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_sal_integration_all_params_with_retries(self):
        # Enable retries and run test_update_sal_integration_all_params.
        _service.enable_retries()
        self.test_update_sal_integration_all_params()

        # Disable retries and run test_update_sal_integration_all_params.
        _service.disable_retries()
        self.test_update_sal_integration_all_params()

    @responses.activate
    def test_update_sal_integration_required_params(self):
        """
        test_update_sal_integration_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SalIntegrationPatch model
        sal_integration_patch_model = {}
        sal_integration_patch_model['op'] = 'add'
        sal_integration_patch_model['path'] = 'storage'
        sal_integration_patch_model['value'] = 'new-apikey'

        # Set up parameter values
        body = sal_integration_patch_model

        # Invoke method
        response = _service.update_sal_integration(
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_sal_integration_required_params_with_retries(self):
        # Enable retries and run test_update_sal_integration_required_params.
        _service.enable_retries()
        self.test_update_sal_integration_required_params()

        # Disable retries and run test_update_sal_integration_required_params.
        _service.disable_retries()
        self.test_update_sal_integration_required_params()

    @responses.activate
    def test_update_sal_integration_value_error(self):
        """
        test_update_sal_integration_value_error()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations')
        mock_response = '{"category_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "engine_id": "presto-01", "errors": [{"code": "unable_to_perform", "message": "Failed to process integration settings for watsonx.data instance"}], "governance_scope_id": "10e64285-bf37-4d5d-b759-bc6a46589234", "governance_scope_type": "category", "instance_id": "18b49d7a-9519-4539-8db5-ff080623c226", "status": "provisioning", "storage_resource_crn": "crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222", "storage_type": "bmcos_object_storage", "timestamp": "1715056266", "trial_plan": false, "username": "xyz@abc.com"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SalIntegrationPatch model
        sal_integration_patch_model = {}
        sal_integration_patch_model['op'] = 'add'
        sal_integration_patch_model['path'] = 'storage'
        sal_integration_patch_model['value'] = 'new-apikey'

        # Set up parameter values
        body = sal_integration_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_sal_integration(**req_copy)

    def test_update_sal_integration_value_error_with_retries(self):
        # Enable retries and run test_update_sal_integration_value_error.
        _service.enable_retries()
        self.test_update_sal_integration_value_error()

        # Disable retries and run test_update_sal_integration_value_error.
        _service.disable_retries()
        self.test_update_sal_integration_value_error()


class TestCreateSalIntegrationEnrichment:
    """
    Test Class for create_sal_integration_enrichment
    """

    @responses.activate
    def test_create_sal_integration_enrichment_all_params(self):
        """
        create_sal_integration_enrichment()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment')
        responses.add(
            responses.POST,
            url,
            status=204,
        )

        # Construct a dict representation of a EnrichmentObj model
        enrichment_obj_model = {}
        enrichment_obj_model['catalog'] = 'iceberg_data'
        enrichment_obj_model['operation'] = 'create'
        enrichment_obj_model['schema'] = 'testString'
        enrichment_obj_model['tables'] = ['testString']

        # Set up parameter values
        enrichment_prototype = enrichment_obj_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_sal_integration_enrichment(
            enrichment_prototype=enrichment_prototype,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['enrichment_prototype'] == enrichment_obj_model

    def test_create_sal_integration_enrichment_all_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_enrichment_all_params.
        _service.enable_retries()
        self.test_create_sal_integration_enrichment_all_params()

        # Disable retries and run test_create_sal_integration_enrichment_all_params.
        _service.disable_retries()
        self.test_create_sal_integration_enrichment_all_params()

    @responses.activate
    def test_create_sal_integration_enrichment_required_params(self):
        """
        test_create_sal_integration_enrichment_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment')
        responses.add(
            responses.POST,
            url,
            status=204,
        )

        # Construct a dict representation of a EnrichmentObj model
        enrichment_obj_model = {}
        enrichment_obj_model['catalog'] = 'iceberg_data'
        enrichment_obj_model['operation'] = 'create'
        enrichment_obj_model['schema'] = 'testString'
        enrichment_obj_model['tables'] = ['testString']

        # Set up parameter values
        enrichment_prototype = enrichment_obj_model

        # Invoke method
        response = _service.create_sal_integration_enrichment(
            enrichment_prototype=enrichment_prototype,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['enrichment_prototype'] == enrichment_obj_model

    def test_create_sal_integration_enrichment_required_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_enrichment_required_params.
        _service.enable_retries()
        self.test_create_sal_integration_enrichment_required_params()

        # Disable retries and run test_create_sal_integration_enrichment_required_params.
        _service.disable_retries()
        self.test_create_sal_integration_enrichment_required_params()


class TestGetSalIntegrationEnrichmentAssets:
    """
    Test Class for get_sal_integration_enrichment_assets
    """

    @responses.activate
    def test_get_sal_integration_enrichment_assets_all_params(self):
        """
        get_sal_integration_enrichment_assets()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_assets')
        mock_response = '{"enrichment_asset": {"asset_attributes": ["asset_attributes"], "asset_id": "ee0383b9-dcab-4c1a-b03d-bf521837b6ed", "asset_name": "newtable", "resource_key": "0000:0000:0000:0000:0000:FFFF:9EB0:04E2|31134|:/iceberg_data/new_schema/sampletable", "schema_name": "sampleschema"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        project_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_assets(
            project_id=project_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'project_id={}'.format(project_id) in query_string

    def test_get_sal_integration_enrichment_assets_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_assets_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_assets_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_assets_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_assets_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_assets_required_params(self):
        """
        test_get_sal_integration_enrichment_assets_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_assets')
        mock_response = '{"enrichment_asset": {"asset_attributes": ["asset_attributes"], "asset_id": "ee0383b9-dcab-4c1a-b03d-bf521837b6ed", "asset_name": "newtable", "resource_key": "0000:0000:0000:0000:0000:FFFF:9EB0:04E2|31134|:/iceberg_data/new_schema/sampletable", "schema_name": "sampleschema"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_assets()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_assets_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_assets_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_assets_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_assets_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_assets_required_params()


class TestGetSalIntegrationEnrichmentDataAsset:
    """
    Test Class for get_sal_integration_enrichment_data_asset
    """

    @responses.activate
    def test_get_sal_integration_enrichment_data_asset_all_params(self):
        """
        get_sal_integration_enrichment_data_asset()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_data_asset')
        mock_response = '{"asset": "{}"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        project_id = 'testString'
        asset_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_data_asset(
            project_id=project_id,
            asset_id=asset_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'project_id={}'.format(project_id) in query_string
        assert 'asset_id={}'.format(asset_id) in query_string

    def test_get_sal_integration_enrichment_data_asset_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_data_asset_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_data_asset_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_data_asset_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_data_asset_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_data_asset_required_params(self):
        """
        test_get_sal_integration_enrichment_data_asset_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_data_asset')
        mock_response = '{"asset": "{}"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_data_asset()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_data_asset_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_data_asset_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_data_asset_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_data_asset_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_data_asset_required_params()


class TestGetSalIntegrationEnrichmentJobRunLogs:
    """
    Test Class for get_sal_integration_enrichment_job_run_logs
    """

    @responses.activate
    def test_get_sal_integration_enrichment_job_run_logs_all_params(self):
        """
        get_sal_integration_enrichment_job_run_logs()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_job_run_logs')
        mock_response = '{"results": ["results"], "total_count": 12}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        job_id = 'testString'
        job_run_id = 'testString'
        project_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_job_run_logs(
            job_id=job_id,
            job_run_id=job_run_id,
            project_id=project_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'job_id={}'.format(job_id) in query_string
        assert 'job_run_id={}'.format(job_run_id) in query_string
        assert 'project_id={}'.format(project_id) in query_string

    def test_get_sal_integration_enrichment_job_run_logs_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_job_run_logs_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_job_run_logs_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_job_run_logs_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_job_run_logs_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_job_run_logs_required_params(self):
        """
        test_get_sal_integration_enrichment_job_run_logs_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_job_run_logs')
        mock_response = '{"results": ["results"], "total_count": 12}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_job_run_logs()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_job_run_logs_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_job_run_logs_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_job_run_logs_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_job_run_logs_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_job_run_logs_required_params()


class TestGetSalIntegrationEnrichmentJobRuns:
    """
    Test Class for get_sal_integration_enrichment_job_runs
    """

    @responses.activate
    def test_get_sal_integration_enrichment_job_runs_all_params(self):
        """
        get_sal_integration_enrichment_job_runs()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_job_runs')
        mock_response = '{"response": "{}"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        job_id = 'testString'
        project_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_job_runs(
            job_id=job_id,
            project_id=project_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'job_id={}'.format(job_id) in query_string
        assert 'project_id={}'.format(project_id) in query_string

    def test_get_sal_integration_enrichment_job_runs_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_job_runs_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_job_runs_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_job_runs_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_job_runs_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_job_runs_required_params(self):
        """
        test_get_sal_integration_enrichment_job_runs_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_job_runs')
        mock_response = '{"response": "{}"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_job_runs()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_job_runs_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_job_runs_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_job_runs_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_job_runs_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_job_runs_required_params()


class TestGetSalIntegrationEnrichmentJobs:
    """
    Test Class for get_sal_integration_enrichment_jobs
    """

    @responses.activate
    def test_get_sal_integration_enrichment_jobs_all_params(self):
        """
        get_sal_integration_enrichment_jobs()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_jobs')
        mock_response = '{"jobs": {"results": [{"entity": {"job": {"asset_ref": "8688a3b6-a946-499e-a93c-b7d099db80dd", "asset_ref_type": "metadata_enrichment_area", "configuration": {"env_type": "env_type", "env_variables": ["env_variables"]}, "enable_notifications": false, "future_scheduled_runs": ["future_scheduled_runs"], "last_run_initiator": "deprecated field", "last_run_status": "deprecated field", "last_run_status_timestamp": 0, "last_run_time": "deprecated field", "project_name": "SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e", "schedule_creator_id": "schedule_creator_id", "schedule_id": "schedule_id", "schedule_info": {"frequency": "frequency"}, "task_credentials_support": {"account_id": "04e9bc4761254b719ac22759cb69bebd", "task_credentials_enabled": true, "user_id": "IBMid-55000832RK"}}}, "metadata": {"asset_id": "ea73ce44-8aa0-4c75-bd69-6ca7074a1030", "name": "SAL_MDE job", "owner_id": "IBMid-55000832RK", "version": 0}}], "total_rows": 1}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        wkc_project_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_jobs(
            wkc_project_id=wkc_project_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'wkc_project_id={}'.format(wkc_project_id) in query_string

    def test_get_sal_integration_enrichment_jobs_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_jobs_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_jobs_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_jobs_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_jobs_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_jobs_required_params(self):
        """
        test_get_sal_integration_enrichment_jobs_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/enrichment_jobs')
        mock_response = '{"jobs": {"results": [{"entity": {"job": {"asset_ref": "8688a3b6-a946-499e-a93c-b7d099db80dd", "asset_ref_type": "metadata_enrichment_area", "configuration": {"env_type": "env_type", "env_variables": ["env_variables"]}, "enable_notifications": false, "future_scheduled_runs": ["future_scheduled_runs"], "last_run_initiator": "deprecated field", "last_run_status": "deprecated field", "last_run_status_timestamp": 0, "last_run_time": "deprecated field", "project_name": "SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e", "schedule_creator_id": "schedule_creator_id", "schedule_id": "schedule_id", "schedule_info": {"frequency": "frequency"}, "task_credentials_support": {"account_id": "04e9bc4761254b719ac22759cb69bebd", "task_credentials_enabled": true, "user_id": "IBMid-55000832RK"}}}, "metadata": {"asset_id": "ea73ce44-8aa0-4c75-bd69-6ca7074a1030", "name": "SAL_MDE job", "owner_id": "IBMid-55000832RK", "version": 0}}], "total_rows": 1}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_jobs()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_jobs_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_jobs_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_jobs_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_jobs_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_jobs_required_params()


class TestGetSalIntegrationGlossaryTerms:
    """
    Test Class for get_sal_integration_glossary_terms
    """

    @responses.activate
    def test_get_sal_integration_glossary_terms_all_params(self):
        """
        get_sal_integration_glossary_terms()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/glossary_terms')
        mock_response = '{"glossary_term": {"description": "First Name", "name": "Name"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_glossary_terms(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_glossary_terms_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_glossary_terms_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_glossary_terms_all_params()

        # Disable retries and run test_get_sal_integration_glossary_terms_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_glossary_terms_all_params()

    @responses.activate
    def test_get_sal_integration_glossary_terms_required_params(self):
        """
        test_get_sal_integration_glossary_terms_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/glossary_terms')
        mock_response = '{"glossary_term": {"description": "First Name", "name": "Name"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_glossary_terms()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_glossary_terms_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_glossary_terms_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_glossary_terms_required_params()

        # Disable retries and run test_get_sal_integration_glossary_terms_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_glossary_terms_required_params()


class TestGetSalIntegrationMappings:
    """
    Test Class for get_sal_integration_mappings
    """

    @responses.activate
    def test_get_sal_integration_mappings_all_params(self):
        """
        get_sal_integration_mappings()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/mappings')
        mock_response = '{"wkc_catalog_id": "iceberg_data", "wkc_project_id": "create"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_name = 'testString'
        schema_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_mappings(
            catalog_name,
            schema_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_name={}'.format(catalog_name) in query_string
        assert 'schema_name={}'.format(schema_name) in query_string

    def test_get_sal_integration_mappings_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_mappings_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_mappings_all_params()

        # Disable retries and run test_get_sal_integration_mappings_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_mappings_all_params()

    @responses.activate
    def test_get_sal_integration_mappings_required_params(self):
        """
        test_get_sal_integration_mappings_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/mappings')
        mock_response = '{"wkc_catalog_id": "iceberg_data", "wkc_project_id": "create"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_name = 'testString'
        schema_name = 'testString'

        # Invoke method
        response = _service.get_sal_integration_mappings(
            catalog_name,
            schema_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_name={}'.format(catalog_name) in query_string
        assert 'schema_name={}'.format(schema_name) in query_string

    def test_get_sal_integration_mappings_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_mappings_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_mappings_required_params()

        # Disable retries and run test_get_sal_integration_mappings_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_mappings_required_params()

    @responses.activate
    def test_get_sal_integration_mappings_value_error(self):
        """
        test_get_sal_integration_mappings_value_error()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/mappings')
        mock_response = '{"wkc_catalog_id": "iceberg_data", "wkc_project_id": "create"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_name = 'testString'
        schema_name = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_name": catalog_name,
            "schema_name": schema_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_sal_integration_mappings(**req_copy)

    def test_get_sal_integration_mappings_value_error_with_retries(self):
        # Enable retries and run test_get_sal_integration_mappings_value_error.
        _service.enable_retries()
        self.test_get_sal_integration_mappings_value_error()

        # Disable retries and run test_get_sal_integration_mappings_value_error.
        _service.disable_retries()
        self.test_get_sal_integration_mappings_value_error()


class TestGetSalIntegrationEnrichmentGlobalSettings:
    """
    Test Class for get_sal_integration_enrichment_global_settings
    """

    @responses.activate
    def test_get_sal_integration_enrichment_global_settings_all_params(self):
        """
        get_sal_integration_enrichment_global_settings()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_global_settings')
        mock_response = '{"semantic_expansion": {"description_generation": true, "description_generation_configuration": {"assignment_threshold": 0.14, "suggestion_threshold": 0.9}, "name_expansion": true, "name_expansion_configuration": {"assignment_threshold": 0.1, "suggestion_threshold": 0.1}}, "term_assignment": {"class_based_assignments": false, "evaluate_negative_assignments": false, "llm_based_assignments": false, "ml_based_assignments_custom": false, "ml_based_assignments_default": false, "name_matching": false, "term_assignment_threshold": 0.3, "term_suggestion_threshold": 0.4}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_global_settings(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_global_settings_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_global_settings_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_global_settings_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_global_settings_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_global_settings_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_global_settings_required_params(self):
        """
        test_get_sal_integration_enrichment_global_settings_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_global_settings')
        mock_response = '{"semantic_expansion": {"description_generation": true, "description_generation_configuration": {"assignment_threshold": 0.14, "suggestion_threshold": 0.9}, "name_expansion": true, "name_expansion_configuration": {"assignment_threshold": 0.1, "suggestion_threshold": 0.1}}, "term_assignment": {"class_based_assignments": false, "evaluate_negative_assignments": false, "llm_based_assignments": false, "ml_based_assignments_custom": false, "ml_based_assignments_default": false, "name_matching": false, "term_assignment_threshold": 0.3, "term_suggestion_threshold": 0.4}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_global_settings()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_global_settings_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_global_settings_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_global_settings_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_global_settings_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_global_settings_required_params()


class TestCreateSalIntegrationEnrichmentGlobalSettings:
    """
    Test Class for create_sal_integration_enrichment_global_settings
    """

    @responses.activate
    def test_create_sal_integration_enrichment_global_settings_all_params(self):
        """
        create_sal_integration_enrichment_global_settings()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_global_settings')
        mock_response = '{"semantic_expansion": {"description_generation": true, "description_generation_configuration": {"assignment_threshold": 0.14, "suggestion_threshold": 0.9}, "name_expansion": true, "name_expansion_configuration": {"assignment_threshold": 0.1, "suggestion_threshold": 0.1}}, "term_assignment": {"class_based_assignments": false, "evaluate_negative_assignments": false, "llm_based_assignments": false, "ml_based_assignments_custom": false, "ml_based_assignments_default": false, "name_matching": false, "term_assignment_threshold": 0.3, "term_suggestion_threshold": 0.4}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['suggestion_threshold'] = 0.9

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['suggestion_threshold'] = 0.1

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansion model
        sal_integration_enrichment_settings_semantic_expansion_model = {}
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation_configuration'] = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion_configuration'] = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsTermAssignment model
        sal_integration_enrichment_settings_term_assignment_model = {}
        sal_integration_enrichment_settings_term_assignment_model['class_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['evaluate_negative_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['llm_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_custom'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_default'] = False
        sal_integration_enrichment_settings_term_assignment_model['name_matching'] = False
        sal_integration_enrichment_settings_term_assignment_model['term_assignment_threshold'] = 0.3
        sal_integration_enrichment_settings_term_assignment_model['term_suggestion_threshold'] = 0.4

        # Set up parameter values
        semantic_expansion = sal_integration_enrichment_settings_semantic_expansion_model
        term_assignment = sal_integration_enrichment_settings_term_assignment_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_sal_integration_enrichment_global_settings(
            semantic_expansion=semantic_expansion,
            term_assignment=term_assignment,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['semantic_expansion'] == sal_integration_enrichment_settings_semantic_expansion_model
        assert req_body['term_assignment'] == sal_integration_enrichment_settings_term_assignment_model

    def test_create_sal_integration_enrichment_global_settings_all_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_enrichment_global_settings_all_params.
        _service.enable_retries()
        self.test_create_sal_integration_enrichment_global_settings_all_params()

        # Disable retries and run test_create_sal_integration_enrichment_global_settings_all_params.
        _service.disable_retries()
        self.test_create_sal_integration_enrichment_global_settings_all_params()

    @responses.activate
    def test_create_sal_integration_enrichment_global_settings_required_params(self):
        """
        test_create_sal_integration_enrichment_global_settings_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_global_settings')
        mock_response = '{"semantic_expansion": {"description_generation": true, "description_generation_configuration": {"assignment_threshold": 0.14, "suggestion_threshold": 0.9}, "name_expansion": true, "name_expansion_configuration": {"assignment_threshold": 0.1, "suggestion_threshold": 0.1}}, "term_assignment": {"class_based_assignments": false, "evaluate_negative_assignments": false, "llm_based_assignments": false, "ml_based_assignments_custom": false, "ml_based_assignments_default": false, "name_matching": false, "term_assignment_threshold": 0.3, "term_suggestion_threshold": 0.4}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['suggestion_threshold'] = 0.9

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['suggestion_threshold'] = 0.1

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansion model
        sal_integration_enrichment_settings_semantic_expansion_model = {}
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation_configuration'] = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion_configuration'] = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsTermAssignment model
        sal_integration_enrichment_settings_term_assignment_model = {}
        sal_integration_enrichment_settings_term_assignment_model['class_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['evaluate_negative_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['llm_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_custom'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_default'] = False
        sal_integration_enrichment_settings_term_assignment_model['name_matching'] = False
        sal_integration_enrichment_settings_term_assignment_model['term_assignment_threshold'] = 0.3
        sal_integration_enrichment_settings_term_assignment_model['term_suggestion_threshold'] = 0.4

        # Set up parameter values
        semantic_expansion = sal_integration_enrichment_settings_semantic_expansion_model
        term_assignment = sal_integration_enrichment_settings_term_assignment_model

        # Invoke method
        response = _service.create_sal_integration_enrichment_global_settings(
            semantic_expansion=semantic_expansion,
            term_assignment=term_assignment,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['semantic_expansion'] == sal_integration_enrichment_settings_semantic_expansion_model
        assert req_body['term_assignment'] == sal_integration_enrichment_settings_term_assignment_model

    def test_create_sal_integration_enrichment_global_settings_required_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_enrichment_global_settings_required_params.
        _service.enable_retries()
        self.test_create_sal_integration_enrichment_global_settings_required_params()

        # Disable retries and run test_create_sal_integration_enrichment_global_settings_required_params.
        _service.disable_retries()
        self.test_create_sal_integration_enrichment_global_settings_required_params()


class TestGetSalIntegrationEnrichmentSettings:
    """
    Test Class for get_sal_integration_enrichment_settings
    """

    @responses.activate
    def test_get_sal_integration_enrichment_settings_all_params(self):
        """
        get_sal_integration_enrichment_settings()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_settings')
        mock_response = '{"semantic_expansion": {"description_generation": true, "description_generation_configuration": {"assignment_threshold": 0.14, "suggestion_threshold": 0.9}, "name_expansion": true, "name_expansion_configuration": {"assignment_threshold": 0.1, "suggestion_threshold": 0.1}}, "term_assignment": {"class_based_assignments": false, "evaluate_negative_assignments": false, "llm_based_assignments": false, "ml_based_assignments_custom": false, "ml_based_assignments_default": false, "name_matching": false, "term_assignment_threshold": 0.3, "term_suggestion_threshold": 0.4}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        project_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_enrichment_settings(
            project_id=project_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'project_id={}'.format(project_id) in query_string

    def test_get_sal_integration_enrichment_settings_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_settings_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_settings_all_params()

        # Disable retries and run test_get_sal_integration_enrichment_settings_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_settings_all_params()

    @responses.activate
    def test_get_sal_integration_enrichment_settings_required_params(self):
        """
        test_get_sal_integration_enrichment_settings_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_settings')
        mock_response = '{"semantic_expansion": {"description_generation": true, "description_generation_configuration": {"assignment_threshold": 0.14, "suggestion_threshold": 0.9}, "name_expansion": true, "name_expansion_configuration": {"assignment_threshold": 0.1, "suggestion_threshold": 0.1}}, "term_assignment": {"class_based_assignments": false, "evaluate_negative_assignments": false, "llm_based_assignments": false, "ml_based_assignments_custom": false, "ml_based_assignments_default": false, "name_matching": false, "term_assignment_threshold": 0.3, "term_suggestion_threshold": 0.4}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_enrichment_settings()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_enrichment_settings_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_enrichment_settings_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_enrichment_settings_required_params()

        # Disable retries and run test_get_sal_integration_enrichment_settings_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_enrichment_settings_required_params()


class TestCreateSalIntegrationEnrichmentSettings:
    """
    Test Class for create_sal_integration_enrichment_settings
    """

    @responses.activate
    def test_create_sal_integration_enrichment_settings_all_params(self):
        """
        create_sal_integration_enrichment_settings()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_settings')
        responses.add(
            responses.POST,
            url,
            status=204,
        )

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['suggestion_threshold'] = 0.9

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['suggestion_threshold'] = 0.1

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansion model
        sal_integration_enrichment_settings_semantic_expansion_model = {}
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation_configuration'] = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion_configuration'] = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsTermAssignment model
        sal_integration_enrichment_settings_term_assignment_model = {}
        sal_integration_enrichment_settings_term_assignment_model['class_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['evaluate_negative_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['llm_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_custom'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_default'] = False
        sal_integration_enrichment_settings_term_assignment_model['name_matching'] = False
        sal_integration_enrichment_settings_term_assignment_model['term_assignment_threshold'] = 0.3
        sal_integration_enrichment_settings_term_assignment_model['term_suggestion_threshold'] = 0.4

        # Set up parameter values
        semantic_expansion = sal_integration_enrichment_settings_semantic_expansion_model
        term_assignment = sal_integration_enrichment_settings_term_assignment_model
        project_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_sal_integration_enrichment_settings(
            semantic_expansion=semantic_expansion,
            term_assignment=term_assignment,
            project_id=project_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'project_id={}'.format(project_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['semantic_expansion'] == sal_integration_enrichment_settings_semantic_expansion_model
        assert req_body['term_assignment'] == sal_integration_enrichment_settings_term_assignment_model

    def test_create_sal_integration_enrichment_settings_all_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_enrichment_settings_all_params.
        _service.enable_retries()
        self.test_create_sal_integration_enrichment_settings_all_params()

        # Disable retries and run test_create_sal_integration_enrichment_settings_all_params.
        _service.disable_retries()
        self.test_create_sal_integration_enrichment_settings_all_params()

    @responses.activate
    def test_create_sal_integration_enrichment_settings_required_params(self):
        """
        test_create_sal_integration_enrichment_settings_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/metadata_enrichment_settings')
        responses.add(
            responses.POST,
            url,
            status=204,
        )

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['suggestion_threshold'] = 0.9

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = {}
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['suggestion_threshold'] = 0.1

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsSemanticExpansion model
        sal_integration_enrichment_settings_semantic_expansion_model = {}
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation_configuration'] = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion_configuration'] = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model

        # Construct a dict representation of a SalIntegrationEnrichmentSettingsTermAssignment model
        sal_integration_enrichment_settings_term_assignment_model = {}
        sal_integration_enrichment_settings_term_assignment_model['class_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['evaluate_negative_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['llm_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_custom'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_default'] = False
        sal_integration_enrichment_settings_term_assignment_model['name_matching'] = False
        sal_integration_enrichment_settings_term_assignment_model['term_assignment_threshold'] = 0.3
        sal_integration_enrichment_settings_term_assignment_model['term_suggestion_threshold'] = 0.4

        # Set up parameter values
        semantic_expansion = sal_integration_enrichment_settings_semantic_expansion_model
        term_assignment = sal_integration_enrichment_settings_term_assignment_model

        # Invoke method
        response = _service.create_sal_integration_enrichment_settings(
            semantic_expansion=semantic_expansion,
            term_assignment=term_assignment,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['semantic_expansion'] == sal_integration_enrichment_settings_semantic_expansion_model
        assert req_body['term_assignment'] == sal_integration_enrichment_settings_term_assignment_model

    def test_create_sal_integration_enrichment_settings_required_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_enrichment_settings_required_params.
        _service.enable_retries()
        self.test_create_sal_integration_enrichment_settings_required_params()

        # Disable retries and run test_create_sal_integration_enrichment_settings_required_params.
        _service.disable_retries()
        self.test_create_sal_integration_enrichment_settings_required_params()


class TestCreateSalIntegrationUploadGlossary:
    """
    Test Class for create_sal_integration_upload_glossary
    """

    @responses.activate
    def test_create_sal_integration_upload_glossary_all_params(self):
        """
        create_sal_integration_upload_glossary()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/upload_glossary')
        mock_response = '{"process_id": "18b49d7a-9519-4539-8db5-ff080623c226"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        replace_option = 'all'
        glossary_csv = io.BytesIO(b'This is a mock file.').getvalue()
        glossary_csv_content_type = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_sal_integration_upload_glossary(
            replace_option,
            glossary_csv=glossary_csv,
            glossary_csv_content_type=glossary_csv_content_type,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_sal_integration_upload_glossary_all_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_upload_glossary_all_params.
        _service.enable_retries()
        self.test_create_sal_integration_upload_glossary_all_params()

        # Disable retries and run test_create_sal_integration_upload_glossary_all_params.
        _service.disable_retries()
        self.test_create_sal_integration_upload_glossary_all_params()

    @responses.activate
    def test_create_sal_integration_upload_glossary_required_params(self):
        """
        test_create_sal_integration_upload_glossary_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/upload_glossary')
        mock_response = '{"process_id": "18b49d7a-9519-4539-8db5-ff080623c226"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        replace_option = 'all'

        # Invoke method
        response = _service.create_sal_integration_upload_glossary(
            replace_option,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_sal_integration_upload_glossary_required_params_with_retries(self):
        # Enable retries and run test_create_sal_integration_upload_glossary_required_params.
        _service.enable_retries()
        self.test_create_sal_integration_upload_glossary_required_params()

        # Disable retries and run test_create_sal_integration_upload_glossary_required_params.
        _service.disable_retries()
        self.test_create_sal_integration_upload_glossary_required_params()

    @responses.activate
    def test_create_sal_integration_upload_glossary_value_error(self):
        """
        test_create_sal_integration_upload_glossary_value_error()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/upload_glossary')
        mock_response = '{"process_id": "18b49d7a-9519-4539-8db5-ff080623c226"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        replace_option = 'all'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "replace_option": replace_option,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_sal_integration_upload_glossary(**req_copy)

    def test_create_sal_integration_upload_glossary_value_error_with_retries(self):
        # Enable retries and run test_create_sal_integration_upload_glossary_value_error.
        _service.enable_retries()
        self.test_create_sal_integration_upload_glossary_value_error()

        # Disable retries and run test_create_sal_integration_upload_glossary_value_error.
        _service.disable_retries()
        self.test_create_sal_integration_upload_glossary_value_error()


class TestGetSalIntegrationUploadGlossaryStatus:
    """
    Test Class for get_sal_integration_upload_glossary_status
    """

    @responses.activate
    def test_get_sal_integration_upload_glossary_status_all_params(self):
        """
        get_sal_integration_upload_glossary_status()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/upload_glossary_status')
        mock_response = '{"response": "Import status available"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        process_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_sal_integration_upload_glossary_status(
            process_id=process_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'process_id={}'.format(process_id) in query_string

    def test_get_sal_integration_upload_glossary_status_all_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_upload_glossary_status_all_params.
        _service.enable_retries()
        self.test_get_sal_integration_upload_glossary_status_all_params()

        # Disable retries and run test_get_sal_integration_upload_glossary_status_all_params.
        _service.disable_retries()
        self.test_get_sal_integration_upload_glossary_status_all_params()

    @responses.activate
    def test_get_sal_integration_upload_glossary_status_required_params(self):
        """
        test_get_sal_integration_upload_glossary_status_required_params()
        """
        # Set up mock
        url = preprocess_url('/sal_integrations/upload_glossary_status')
        mock_response = '{"response": "Import status available"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_sal_integration_upload_glossary_status()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_sal_integration_upload_glossary_status_required_params_with_retries(self):
        # Enable retries and run test_get_sal_integration_upload_glossary_status_required_params.
        _service.enable_retries()
        self.test_get_sal_integration_upload_glossary_status_required_params()

        # Disable retries and run test_get_sal_integration_upload_glossary_status_required_params.
        _service.disable_retries()
        self.test_get_sal_integration_upload_glossary_status_required_params()


# endregion
##############################################################################
# End of Service: SemanticAutomationLayer
##############################################################################

##############################################################################
# Start of Service: SparkEngines
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListSparkEngines:
    """
    Test Class for list_spark_engines
    """

    @responses.activate
    def test_list_spark_engines_all_params(self):
        """
        list_spark_engines()
        """
        # Set up mock
        url = preprocess_url('/spark_engines')
        mock_response = '{"spark_engines": [{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_spark_engines(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_engines_all_params_with_retries(self):
        # Enable retries and run test_list_spark_engines_all_params.
        _service.enable_retries()
        self.test_list_spark_engines_all_params()

        # Disable retries and run test_list_spark_engines_all_params.
        _service.disable_retries()
        self.test_list_spark_engines_all_params()

    @responses.activate
    def test_list_spark_engines_required_params(self):
        """
        test_list_spark_engines_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines')
        mock_response = '{"spark_engines": [{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_spark_engines()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_engines_required_params_with_retries(self):
        # Enable retries and run test_list_spark_engines_required_params.
        _service.enable_retries()
        self.test_list_spark_engines_required_params()

        # Disable retries and run test_list_spark_engines_required_params.
        _service.disable_retries()
        self.test_list_spark_engines_required_params()


class TestCreateSparkEngine:
    """
    Test Class for create_spark_engine
    """

    @responses.activate
    def test_create_spark_engine_all_params(self):
        """
        create_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a SparkDefaultConfig model
        spark_default_config_model = {}
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        # Construct a dict representation of a SparkScaleConfig model
        spark_scale_config_model = {}
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'small'
        spark_scale_config_model['number_of_nodes'] = 5

        # Construct a dict representation of a SparkEngineDetailsPrototype model
        spark_engine_details_prototype_model = {}
        spark_engine_details_prototype_model['api_key'] = 'apikey'
        spark_engine_details_prototype_model['connection_string'] = '1.2.3.4'
        spark_engine_details_prototype_model['default_config'] = spark_default_config_model
        spark_engine_details_prototype_model['default_version'] = '3.3'
        spark_engine_details_prototype_model['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_prototype_model['engine_home_bucket_name'] = '4fec0f8b-888a-4c16-8f38-250c8499e6ce-customer'
        spark_engine_details_prototype_model['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_prototype_model['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_prototype_model['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_prototype_model['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_prototype_model['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_prototype_model['engine_sub_type'] = 'java/cpp'
        spark_engine_details_prototype_model['instance_id'] = 'spark-id'
        spark_engine_details_prototype_model['managed_by'] = 'fully/self'
        spark_engine_details_prototype_model['scale_config'] = spark_scale_config_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['iceberg-data']
        description = 'testString'
        engine_details = spark_engine_details_prototype_model
        engine_display_name = 'test-native'
        status = 'testString'
        tags = ['testString']
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_spark_engine(
            origin,
            associated_catalogs=associated_catalogs,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            status=status,
            tags=tags,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'native'
        assert req_body['associated_catalogs'] == ['iceberg-data']
        assert req_body['description'] == 'testString'
        assert req_body['engine_details'] == spark_engine_details_prototype_model
        assert req_body['engine_display_name'] == 'test-native'
        assert req_body['status'] == 'testString'
        assert req_body['tags'] == ['testString']

    def test_create_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_create_spark_engine_all_params.
        _service.enable_retries()
        self.test_create_spark_engine_all_params()

        # Disable retries and run test_create_spark_engine_all_params.
        _service.disable_retries()
        self.test_create_spark_engine_all_params()

    @responses.activate
    def test_create_spark_engine_required_params(self):
        """
        test_create_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a SparkDefaultConfig model
        spark_default_config_model = {}
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        # Construct a dict representation of a SparkScaleConfig model
        spark_scale_config_model = {}
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'small'
        spark_scale_config_model['number_of_nodes'] = 5

        # Construct a dict representation of a SparkEngineDetailsPrototype model
        spark_engine_details_prototype_model = {}
        spark_engine_details_prototype_model['api_key'] = 'apikey'
        spark_engine_details_prototype_model['connection_string'] = '1.2.3.4'
        spark_engine_details_prototype_model['default_config'] = spark_default_config_model
        spark_engine_details_prototype_model['default_version'] = '3.3'
        spark_engine_details_prototype_model['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_prototype_model['engine_home_bucket_name'] = '4fec0f8b-888a-4c16-8f38-250c8499e6ce-customer'
        spark_engine_details_prototype_model['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_prototype_model['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_prototype_model['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_prototype_model['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_prototype_model['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_prototype_model['engine_sub_type'] = 'java/cpp'
        spark_engine_details_prototype_model['instance_id'] = 'spark-id'
        spark_engine_details_prototype_model['managed_by'] = 'fully/self'
        spark_engine_details_prototype_model['scale_config'] = spark_scale_config_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['iceberg-data']
        description = 'testString'
        engine_details = spark_engine_details_prototype_model
        engine_display_name = 'test-native'
        status = 'testString'
        tags = ['testString']

        # Invoke method
        response = _service.create_spark_engine(
            origin,
            associated_catalogs=associated_catalogs,
            description=description,
            engine_details=engine_details,
            engine_display_name=engine_display_name,
            status=status,
            tags=tags,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['origin'] == 'native'
        assert req_body['associated_catalogs'] == ['iceberg-data']
        assert req_body['description'] == 'testString'
        assert req_body['engine_details'] == spark_engine_details_prototype_model
        assert req_body['engine_display_name'] == 'test-native'
        assert req_body['status'] == 'testString'
        assert req_body['tags'] == ['testString']

    def test_create_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_create_spark_engine_required_params.
        _service.enable_retries()
        self.test_create_spark_engine_required_params()

        # Disable retries and run test_create_spark_engine_required_params.
        _service.disable_retries()
        self.test_create_spark_engine_required_params()

    @responses.activate
    def test_create_spark_engine_value_error(self):
        """
        test_create_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a SparkDefaultConfig model
        spark_default_config_model = {}
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        # Construct a dict representation of a SparkScaleConfig model
        spark_scale_config_model = {}
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'small'
        spark_scale_config_model['number_of_nodes'] = 5

        # Construct a dict representation of a SparkEngineDetailsPrototype model
        spark_engine_details_prototype_model = {}
        spark_engine_details_prototype_model['api_key'] = 'apikey'
        spark_engine_details_prototype_model['connection_string'] = '1.2.3.4'
        spark_engine_details_prototype_model['default_config'] = spark_default_config_model
        spark_engine_details_prototype_model['default_version'] = '3.3'
        spark_engine_details_prototype_model['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_prototype_model['engine_home_bucket_name'] = '4fec0f8b-888a-4c16-8f38-250c8499e6ce-customer'
        spark_engine_details_prototype_model['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_prototype_model['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_prototype_model['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_prototype_model['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_prototype_model['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_prototype_model['engine_sub_type'] = 'java/cpp'
        spark_engine_details_prototype_model['instance_id'] = 'spark-id'
        spark_engine_details_prototype_model['managed_by'] = 'fully/self'
        spark_engine_details_prototype_model['scale_config'] = spark_scale_config_model

        # Set up parameter values
        origin = 'native'
        associated_catalogs = ['iceberg-data']
        description = 'testString'
        engine_details = spark_engine_details_prototype_model
        engine_display_name = 'test-native'
        status = 'testString'
        tags = ['testString']

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "origin": origin,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_spark_engine(**req_copy)

    def test_create_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_create_spark_engine_value_error.
        _service.enable_retries()
        self.test_create_spark_engine_value_error()

        # Disable retries and run test_create_spark_engine_value_error.
        _service.disable_retries()
        self.test_create_spark_engine_value_error()


class TestGetSparkEngine:
    """
    Test Class for get_spark_engine
    """

    @responses.activate
    def test_get_spark_engine_all_params(self):
        """
        get_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_all_params.
        _service.enable_retries()
        self.test_get_spark_engine_all_params()

        # Disable retries and run test_get_spark_engine_all_params.
        _service.disable_retries()
        self.test_get_spark_engine_all_params()

    @responses.activate
    def test_get_spark_engine_required_params(self):
        """
        test_get_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_required_params.
        _service.enable_retries()
        self.test_get_spark_engine_required_params()

        # Disable retries and run test_get_spark_engine_required_params.
        _service.disable_retries()
        self.test_get_spark_engine_required_params()

    @responses.activate
    def test_get_spark_engine_value_error(self):
        """
        test_get_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_spark_engine(**req_copy)

    def test_get_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_get_spark_engine_value_error.
        _service.enable_retries()
        self.test_get_spark_engine_value_error()

        # Disable retries and run test_get_spark_engine_value_error.
        _service.disable_retries()
        self.test_get_spark_engine_value_error()


class TestDeleteSparkEngine:
    """
    Test Class for delete_spark_engine
    """

    @responses.activate
    def test_delete_spark_engine_all_params(self):
        """
        delete_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_spark_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_all_params.
        _service.enable_retries()
        self.test_delete_spark_engine_all_params()

        # Disable retries and run test_delete_spark_engine_all_params.
        _service.disable_retries()
        self.test_delete_spark_engine_all_params()

    @responses.activate
    def test_delete_spark_engine_required_params(self):
        """
        test_delete_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_spark_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_required_params.
        _service.enable_retries()
        self.test_delete_spark_engine_required_params()

        # Disable retries and run test_delete_spark_engine_required_params.
        _service.disable_retries()
        self.test_delete_spark_engine_required_params()

    @responses.activate
    def test_delete_spark_engine_value_error(self):
        """
        test_delete_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_spark_engine(**req_copy)

    def test_delete_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_delete_spark_engine_value_error.
        _service.enable_retries()
        self.test_delete_spark_engine_value_error()

        # Disable retries and run test_delete_spark_engine_value_error.
        _service.disable_retries()
        self.test_delete_spark_engine_value_error()


class TestUpdateSparkEngine:
    """
    Test Class for update_spark_engine
    """

    @responses.activate
    def test_update_spark_engine_all_params(self):
        """
        update_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SparkEngineResourceLimit model
        spark_engine_resource_limit_model = {}
        spark_engine_resource_limit_model['cores'] = '1'
        spark_engine_resource_limit_model['memory'] = '4G'

        # Construct a dict representation of a UpdateSparkEngineBodyEngineDetails model
        update_spark_engine_body_engine_details_model = {}
        update_spark_engine_body_engine_details_model['default_config'] = {'key1': 'testString'}
        update_spark_engine_body_engine_details_model['default_version'] = '3.4'
        update_spark_engine_body_engine_details_model['engine_home_bucket_name'] = 'test-spark-bucket'
        update_spark_engine_body_engine_details_model['resource_limit_enabled'] = True
        update_spark_engine_body_engine_details_model['resource_limits'] = spark_engine_resource_limit_model

        # Construct a dict representation of a UpdateSparkEngineBody model
        update_spark_engine_body_model = {}
        update_spark_engine_body_model['description'] = 'Updated Description'
        update_spark_engine_body_model['engine_details'] = update_spark_engine_body_engine_details_model
        update_spark_engine_body_model['engine_display_name'] = 'Updated Display Name'
        update_spark_engine_body_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = update_spark_engine_body_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_spark_engine(
            engine_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_update_spark_engine_all_params.
        _service.enable_retries()
        self.test_update_spark_engine_all_params()

        # Disable retries and run test_update_spark_engine_all_params.
        _service.disable_retries()
        self.test_update_spark_engine_all_params()

    @responses.activate
    def test_update_spark_engine_required_params(self):
        """
        test_update_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SparkEngineResourceLimit model
        spark_engine_resource_limit_model = {}
        spark_engine_resource_limit_model['cores'] = '1'
        spark_engine_resource_limit_model['memory'] = '4G'

        # Construct a dict representation of a UpdateSparkEngineBodyEngineDetails model
        update_spark_engine_body_engine_details_model = {}
        update_spark_engine_body_engine_details_model['default_config'] = {'key1': 'testString'}
        update_spark_engine_body_engine_details_model['default_version'] = '3.4'
        update_spark_engine_body_engine_details_model['engine_home_bucket_name'] = 'test-spark-bucket'
        update_spark_engine_body_engine_details_model['resource_limit_enabled'] = True
        update_spark_engine_body_engine_details_model['resource_limits'] = spark_engine_resource_limit_model

        # Construct a dict representation of a UpdateSparkEngineBody model
        update_spark_engine_body_model = {}
        update_spark_engine_body_model['description'] = 'Updated Description'
        update_spark_engine_body_model['engine_details'] = update_spark_engine_body_engine_details_model
        update_spark_engine_body_model['engine_display_name'] = 'Updated Display Name'
        update_spark_engine_body_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = update_spark_engine_body_model

        # Invoke method
        response = _service.update_spark_engine(
            engine_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_update_spark_engine_required_params.
        _service.enable_retries()
        self.test_update_spark_engine_required_params()

        # Disable retries and run test_update_spark_engine_required_params.
        _service.disable_retries()
        self.test_update_spark_engine_required_params()

    @responses.activate
    def test_update_spark_engine_value_error(self):
        """
        test_update_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString')
        mock_response = '{"actions": ["actions"], "associated_catalogs": ["associated_catalogs"], "build_version": "1.0.3.0.0", "created_by": "<username>@<domain>.com", "created_on": 10, "description": "spark engine for running sql queries", "engine_details": {"api_key": "apikey", "connection_string": "https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>", "default_config": {"config1": "config1", "config2": "config2"}, "default_version": "4.8.3", "endpoints": {"applications_api": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>", "history_server_endpoint": "$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server", "spark_access_endpoint": "$HOST/analytics-engine/details/spark-<instance_id>", "spark_jobs_v4_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications", "spark_kernel_endpoint": "$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels", "view_history_server": "view_history_server", "wxd_application_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications", "wxd_engine_endpoint": "$HOST/v1/1698311655308796/engines/spark817", "wxd_history_server_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server", "wxd_history_server_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/history_server/ui"}, "engine_home_bucket_display_name": "test-spark-bucket", "engine_home_bucket_name": "test-spark-bucket", "engine_home_path": "spark/spark1234", "engine_home_volume": "test-spark-volume", "engine_home_volume_id": "1704979825978585", "engine_home_volume_name": "my-volume", "engine_home_volume_storage_class": "nfs-client", "engine_home_volume_storage_size": "5Gi", "instance_id": "spark-id", "engine_sub_type": "java/cpp", "managed_by": "fully/self", "scale_config": {"auto_scale_enabled": true, "current_number_of_nodes": 2, "maximum_number_of_nodes": 5, "minimum_number_of_nodes": 1, "node_type": "medium", "number_of_nodes": 2}}, "engine_display_name": "sampleEngine", "engine_id": "sampleEngine123", "origin": "external", "status": "Registered", "tags": ["tags"], "type": "spark"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SparkEngineResourceLimit model
        spark_engine_resource_limit_model = {}
        spark_engine_resource_limit_model['cores'] = '1'
        spark_engine_resource_limit_model['memory'] = '4G'

        # Construct a dict representation of a UpdateSparkEngineBodyEngineDetails model
        update_spark_engine_body_engine_details_model = {}
        update_spark_engine_body_engine_details_model['default_config'] = {'key1': 'testString'}
        update_spark_engine_body_engine_details_model['default_version'] = '3.4'
        update_spark_engine_body_engine_details_model['engine_home_bucket_name'] = 'test-spark-bucket'
        update_spark_engine_body_engine_details_model['resource_limit_enabled'] = True
        update_spark_engine_body_engine_details_model['resource_limits'] = spark_engine_resource_limit_model

        # Construct a dict representation of a UpdateSparkEngineBody model
        update_spark_engine_body_model = {}
        update_spark_engine_body_model['description'] = 'Updated Description'
        update_spark_engine_body_model['engine_details'] = update_spark_engine_body_engine_details_model
        update_spark_engine_body_model['engine_display_name'] = 'Updated Display Name'
        update_spark_engine_body_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        engine_id = 'testString'
        body = update_spark_engine_body_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_spark_engine(**req_copy)

    def test_update_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_update_spark_engine_value_error.
        _service.enable_retries()
        self.test_update_spark_engine_value_error()

        # Disable retries and run test_update_spark_engine_value_error.
        _service.disable_retries()
        self.test_update_spark_engine_value_error()


class TestListSparkEngineApplications:
    """
    Test Class for list_spark_engine_applications
    """

    @responses.activate
    def test_list_spark_engine_applications_all_params(self):
        """
        list_spark_engine_applications()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        mock_response = '{"applications": [{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'
        state = ['testString']

        # Invoke method
        response = _service.list_spark_engine_applications(
            engine_id,
            auth_instance_id=auth_instance_id,
            state=state,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'state={}'.format(','.join(state)) in query_string

    def test_list_spark_engine_applications_all_params_with_retries(self):
        # Enable retries and run test_list_spark_engine_applications_all_params.
        _service.enable_retries()
        self.test_list_spark_engine_applications_all_params()

        # Disable retries and run test_list_spark_engine_applications_all_params.
        _service.disable_retries()
        self.test_list_spark_engine_applications_all_params()

    @responses.activate
    def test_list_spark_engine_applications_required_params(self):
        """
        test_list_spark_engine_applications_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        mock_response = '{"applications": [{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.list_spark_engine_applications(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_engine_applications_required_params_with_retries(self):
        # Enable retries and run test_list_spark_engine_applications_required_params.
        _service.enable_retries()
        self.test_list_spark_engine_applications_required_params()

        # Disable retries and run test_list_spark_engine_applications_required_params.
        _service.disable_retries()
        self.test_list_spark_engine_applications_required_params()

    @responses.activate
    def test_list_spark_engine_applications_value_error(self):
        """
        test_list_spark_engine_applications_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        mock_response = '{"applications": [{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_spark_engine_applications(**req_copy)

    def test_list_spark_engine_applications_value_error_with_retries(self):
        # Enable retries and run test_list_spark_engine_applications_value_error.
        _service.enable_retries()
        self.test_list_spark_engine_applications_value_error()

        # Disable retries and run test_list_spark_engine_applications_value_error.
        _service.disable_retries()
        self.test_list_spark_engine_applications_value_error()


class TestCreateSparkEngineApplication:
    """
    Test Class for create_spark_engine_application
    """

    @responses.activate
    def test_create_spark_engine_application_all_params(self):
        """
        create_spark_engine_application()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        mock_response = '{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a SparkApplicationConfig model
        spark_application_config_model = {}
        spark_application_config_model['spark_sample_config_properpty'] = 'testString'

        # Construct a dict representation of a SparkApplicationEnv model
        spark_application_env_model = {}
        spark_application_env_model['sample_env_key'] = 'testString'

        # Construct a dict representation of a SparkApplicationDetails model
        spark_application_details_model = {}
        spark_application_details_model['application'] = '/opt/ibm/spark/examples/src/main/python/wordcount.py'
        spark_application_details_model['arguments'] = ['/opt/ibm/spark/examples/src/main/resources/people.txt']
        spark_application_details_model['class'] = 'org.apache.spark.examples.SparkPi'
        spark_application_details_model['conf'] = spark_application_config_model
        spark_application_details_model['env'] = spark_application_env_model
        spark_application_details_model['files'] = 's3://mybucket/myfile.txt'
        spark_application_details_model['jars'] = 'testString'
        spark_application_details_model['name'] = 'SparkApplicaton1'
        spark_application_details_model['packages'] = 'org.apache.spark:example_1.2.3'
        spark_application_details_model['repositories'] = 'https://repo1.maven.org/maven2/'
        spark_application_details_model['spark_version'] = '3.3'

        # Construct a dict representation of a SparkVolumeDetails model
        spark_volume_details_model = {}
        spark_volume_details_model['mount_path'] = '/mount/path'
        spark_volume_details_model['name'] = 'my-volume'
        spark_volume_details_model['read_only'] = True
        spark_volume_details_model['source_sub_path'] = '/source/path'

        # Set up parameter values
        engine_id = 'testString'
        application_details = spark_application_details_model
        job_endpoint = 'testString'
        service_instance_id = 'testString'
        type = 'iae'
        volumes = [spark_volume_details_model]
        auth_instance_id = 'testString'
        state = ['testString']

        # Invoke method
        response = _service.create_spark_engine_application(
            engine_id,
            application_details,
            job_endpoint=job_endpoint,
            service_instance_id=service_instance_id,
            type=type,
            volumes=volumes,
            auth_instance_id=auth_instance_id,
            state=state,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'state={}'.format(','.join(state)) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['application_details'] == spark_application_details_model
        assert req_body['job_endpoint'] == 'testString'
        assert req_body['service_instance_id'] == 'testString'
        assert req_body['type'] == 'iae'
        assert req_body['volumes'] == [spark_volume_details_model]

    def test_create_spark_engine_application_all_params_with_retries(self):
        # Enable retries and run test_create_spark_engine_application_all_params.
        _service.enable_retries()
        self.test_create_spark_engine_application_all_params()

        # Disable retries and run test_create_spark_engine_application_all_params.
        _service.disable_retries()
        self.test_create_spark_engine_application_all_params()

    @responses.activate
    def test_create_spark_engine_application_required_params(self):
        """
        test_create_spark_engine_application_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        mock_response = '{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a SparkApplicationConfig model
        spark_application_config_model = {}
        spark_application_config_model['spark_sample_config_properpty'] = 'testString'

        # Construct a dict representation of a SparkApplicationEnv model
        spark_application_env_model = {}
        spark_application_env_model['sample_env_key'] = 'testString'

        # Construct a dict representation of a SparkApplicationDetails model
        spark_application_details_model = {}
        spark_application_details_model['application'] = '/opt/ibm/spark/examples/src/main/python/wordcount.py'
        spark_application_details_model['arguments'] = ['/opt/ibm/spark/examples/src/main/resources/people.txt']
        spark_application_details_model['class'] = 'org.apache.spark.examples.SparkPi'
        spark_application_details_model['conf'] = spark_application_config_model
        spark_application_details_model['env'] = spark_application_env_model
        spark_application_details_model['files'] = 's3://mybucket/myfile.txt'
        spark_application_details_model['jars'] = 'testString'
        spark_application_details_model['name'] = 'SparkApplicaton1'
        spark_application_details_model['packages'] = 'org.apache.spark:example_1.2.3'
        spark_application_details_model['repositories'] = 'https://repo1.maven.org/maven2/'
        spark_application_details_model['spark_version'] = '3.3'

        # Construct a dict representation of a SparkVolumeDetails model
        spark_volume_details_model = {}
        spark_volume_details_model['mount_path'] = '/mount/path'
        spark_volume_details_model['name'] = 'my-volume'
        spark_volume_details_model['read_only'] = True
        spark_volume_details_model['source_sub_path'] = '/source/path'

        # Set up parameter values
        engine_id = 'testString'
        application_details = spark_application_details_model
        job_endpoint = 'testString'
        service_instance_id = 'testString'
        type = 'iae'
        volumes = [spark_volume_details_model]

        # Invoke method
        response = _service.create_spark_engine_application(
            engine_id,
            application_details,
            job_endpoint=job_endpoint,
            service_instance_id=service_instance_id,
            type=type,
            volumes=volumes,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['application_details'] == spark_application_details_model
        assert req_body['job_endpoint'] == 'testString'
        assert req_body['service_instance_id'] == 'testString'
        assert req_body['type'] == 'iae'
        assert req_body['volumes'] == [spark_volume_details_model]

    def test_create_spark_engine_application_required_params_with_retries(self):
        # Enable retries and run test_create_spark_engine_application_required_params.
        _service.enable_retries()
        self.test_create_spark_engine_application_required_params()

        # Disable retries and run test_create_spark_engine_application_required_params.
        _service.disable_retries()
        self.test_create_spark_engine_application_required_params()

    @responses.activate
    def test_create_spark_engine_application_value_error(self):
        """
        test_create_spark_engine_application_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        mock_response = '{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a SparkApplicationConfig model
        spark_application_config_model = {}
        spark_application_config_model['spark_sample_config_properpty'] = 'testString'

        # Construct a dict representation of a SparkApplicationEnv model
        spark_application_env_model = {}
        spark_application_env_model['sample_env_key'] = 'testString'

        # Construct a dict representation of a SparkApplicationDetails model
        spark_application_details_model = {}
        spark_application_details_model['application'] = '/opt/ibm/spark/examples/src/main/python/wordcount.py'
        spark_application_details_model['arguments'] = ['/opt/ibm/spark/examples/src/main/resources/people.txt']
        spark_application_details_model['class'] = 'org.apache.spark.examples.SparkPi'
        spark_application_details_model['conf'] = spark_application_config_model
        spark_application_details_model['env'] = spark_application_env_model
        spark_application_details_model['files'] = 's3://mybucket/myfile.txt'
        spark_application_details_model['jars'] = 'testString'
        spark_application_details_model['name'] = 'SparkApplicaton1'
        spark_application_details_model['packages'] = 'org.apache.spark:example_1.2.3'
        spark_application_details_model['repositories'] = 'https://repo1.maven.org/maven2/'
        spark_application_details_model['spark_version'] = '3.3'

        # Construct a dict representation of a SparkVolumeDetails model
        spark_volume_details_model = {}
        spark_volume_details_model['mount_path'] = '/mount/path'
        spark_volume_details_model['name'] = 'my-volume'
        spark_volume_details_model['read_only'] = True
        spark_volume_details_model['source_sub_path'] = '/source/path'

        # Set up parameter values
        engine_id = 'testString'
        application_details = spark_application_details_model
        job_endpoint = 'testString'
        service_instance_id = 'testString'
        type = 'iae'
        volumes = [spark_volume_details_model]

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "application_details": application_details,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_spark_engine_application(**req_copy)

    def test_create_spark_engine_application_value_error_with_retries(self):
        # Enable retries and run test_create_spark_engine_application_value_error.
        _service.enable_retries()
        self.test_create_spark_engine_application_value_error()

        # Disable retries and run test_create_spark_engine_application_value_error.
        _service.disable_retries()
        self.test_create_spark_engine_application_value_error()


class TestDeleteSparkEngineApplications:
    """
    Test Class for delete_spark_engine_applications
    """

    @responses.activate
    def test_delete_spark_engine_applications_all_params(self):
        """
        delete_spark_engine_applications()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        application_id = 'testString'
        auth_instance_id = 'testString'
        state = ['testString']

        # Invoke method
        response = _service.delete_spark_engine_applications(
            engine_id,
            application_id,
            auth_instance_id=auth_instance_id,
            state=state,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'application_id={}'.format(application_id) in query_string
        assert 'state={}'.format(','.join(state)) in query_string

    def test_delete_spark_engine_applications_all_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_applications_all_params.
        _service.enable_retries()
        self.test_delete_spark_engine_applications_all_params()

        # Disable retries and run test_delete_spark_engine_applications_all_params.
        _service.disable_retries()
        self.test_delete_spark_engine_applications_all_params()

    @responses.activate
    def test_delete_spark_engine_applications_required_params(self):
        """
        test_delete_spark_engine_applications_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        application_id = 'testString'

        # Invoke method
        response = _service.delete_spark_engine_applications(
            engine_id,
            application_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'application_id={}'.format(application_id) in query_string

    def test_delete_spark_engine_applications_required_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_applications_required_params.
        _service.enable_retries()
        self.test_delete_spark_engine_applications_required_params()

        # Disable retries and run test_delete_spark_engine_applications_required_params.
        _service.disable_retries()
        self.test_delete_spark_engine_applications_required_params()

    @responses.activate
    def test_delete_spark_engine_applications_value_error(self):
        """
        test_delete_spark_engine_applications_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        application_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "application_id": application_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_spark_engine_applications(**req_copy)

    def test_delete_spark_engine_applications_value_error_with_retries(self):
        # Enable retries and run test_delete_spark_engine_applications_value_error.
        _service.enable_retries()
        self.test_delete_spark_engine_applications_value_error()

        # Disable retries and run test_delete_spark_engine_applications_value_error.
        _service.disable_retries()
        self.test_delete_spark_engine_applications_value_error()


class TestGetSparkEngineApplicationStatus:
    """
    Test Class for get_spark_engine_application_status
    """

    @responses.activate
    def test_get_spark_engine_application_status_all_params(self):
        """
        get_spark_engine_application_status()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications/testString')
        mock_response = '{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        application_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine_application_status(
            engine_id,
            application_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_application_status_all_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_application_status_all_params.
        _service.enable_retries()
        self.test_get_spark_engine_application_status_all_params()

        # Disable retries and run test_get_spark_engine_application_status_all_params.
        _service.disable_retries()
        self.test_get_spark_engine_application_status_all_params()

    @responses.activate
    def test_get_spark_engine_application_status_required_params(self):
        """
        test_get_spark_engine_application_status_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications/testString')
        mock_response = '{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        application_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine_application_status(
            engine_id,
            application_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_application_status_required_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_application_status_required_params.
        _service.enable_retries()
        self.test_get_spark_engine_application_status_required_params()

        # Disable retries and run test_get_spark_engine_application_status_required_params.
        _service.disable_retries()
        self.test_get_spark_engine_application_status_required_params()

    @responses.activate
    def test_get_spark_engine_application_status_value_error(self):
        """
        test_get_spark_engine_application_status_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/applications/testString')
        mock_response = '{"application_details": {"application": "s3://mybucket/wordcount.py", "arguments": ["people.txt"], "class": "org.apache.spark.examples.SparkPi", "conf": {"spark_sample_config_properpty": "spark_sample_config_properpty"}, "env": {"sample_env_key": "sample_env_key"}, "files": "s3://mybucket/myfile.txt", "jars": "jars", "name": "SparkApplicaton1", "packages": "org.apache.spark:example_1.2.3", "repositories": "https://repo1.maven.org/maven2/", "spark_version": "3.3"}, "application_id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "auto_termination_time": "2020-12-08T10:00:00.000Z", "creation_time": "Saturday 28 October 2023 07:17:06.856+0000", "deploy_mode": "stand-alone", "end_time": "2020-12-08T10:00:00.000Z", "failed_time": "failed_time", "finish_time": "Saturday 28 October 2023 07:17:38.966+0000", "id": "cd7cbf1f-8893-4c51-aa3d-d92729f05e99", "job_endpoint": "<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications", "return_code": "0", "runtime": {"spark_version": "3.3"}, "service_instance_id": "service_instance_id", "spark_application_id": "app-20231028071726-0000", "spark_application_name": "PythonWordCount", "spark_version": "3.3", "start_time": "Saturday 28 October 2023 07:17:26.649+0000", "state": "FINISHED", "state_details": [{"code": "code", "message": "message", "type": "type"}], "submission_time": "2023-11-01T11:18:49.758Z", "template_id": "spark-3.3-jaas-v2-cp4d-template", "type": "iae", "volumes": [{"mount_path": "/mount/path", "name": "my-volume", "read_only": true, "source_sub_path": "/source/path"}], "wxd_application_ui_endpoint": "$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        application_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "application_id": application_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_spark_engine_application_status(**req_copy)

    def test_get_spark_engine_application_status_value_error_with_retries(self):
        # Enable retries and run test_get_spark_engine_application_status_value_error.
        _service.enable_retries()
        self.test_get_spark_engine_application_status_value_error()

        # Disable retries and run test_get_spark_engine_application_status_value_error.
        _service.disable_retries()
        self.test_get_spark_engine_application_status_value_error()


class TestListSparkEngineCatalogs:
    """
    Test Class for list_spark_engine_catalogs
    """

    @responses.activate
    def test_list_spark_engine_catalogs_all_params(self):
        """
        list_spark_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_spark_engine_catalogs(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_list_spark_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_list_spark_engine_catalogs_all_params()

        # Disable retries and run test_list_spark_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_list_spark_engine_catalogs_all_params()

    @responses.activate
    def test_list_spark_engine_catalogs_required_params(self):
        """
        test_list_spark_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.list_spark_engine_catalogs(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_list_spark_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_list_spark_engine_catalogs_required_params()

        # Disable retries and run test_list_spark_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_list_spark_engine_catalogs_required_params()

    @responses.activate
    def test_list_spark_engine_catalogs_value_error(self):
        """
        test_list_spark_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_spark_engine_catalogs(**req_copy)

    def test_list_spark_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_list_spark_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_list_spark_engine_catalogs_value_error()

        # Disable retries and run test_list_spark_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_list_spark_engine_catalogs_value_error()


class TestCreateSparkEngineCatalogs:
    """
    Test Class for create_spark_engine_catalogs
    """

    @responses.activate
    def test_create_spark_engine_catalogs_all_params(self):
        """
        create_spark_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_spark_engine_catalogs(
            engine_id,
            catalog_names=catalog_names,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['catalog_names'] == 'testString'

    def test_create_spark_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_create_spark_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_create_spark_engine_catalogs_all_params()

        # Disable retries and run test_create_spark_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_create_spark_engine_catalogs_all_params()

    @responses.activate
    def test_create_spark_engine_catalogs_required_params(self):
        """
        test_create_spark_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Invoke method
        response = _service.create_spark_engine_catalogs(
            engine_id,
            catalog_names=catalog_names,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['catalog_names'] == 'testString'

    def test_create_spark_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_create_spark_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_create_spark_engine_catalogs_required_params()

        # Disable retries and run test_create_spark_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_create_spark_engine_catalogs_required_params()

    @responses.activate
    def test_create_spark_engine_catalogs_value_error(self):
        """
        test_create_spark_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_spark_engine_catalogs(**req_copy)

    def test_create_spark_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_create_spark_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_create_spark_engine_catalogs_value_error()

        # Disable retries and run test_create_spark_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_create_spark_engine_catalogs_value_error()


class TestDeleteSparkEngineCatalogs:
    """
    Test Class for delete_spark_engine_catalogs
    """

    @responses.activate
    def test_delete_spark_engine_catalogs_all_params(self):
        """
        delete_spark_engine_catalogs()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_spark_engine_catalogs(
            engine_id,
            catalog_names,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_names={}'.format(catalog_names) in query_string

    def test_delete_spark_engine_catalogs_all_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_catalogs_all_params.
        _service.enable_retries()
        self.test_delete_spark_engine_catalogs_all_params()

        # Disable retries and run test_delete_spark_engine_catalogs_all_params.
        _service.disable_retries()
        self.test_delete_spark_engine_catalogs_all_params()

    @responses.activate
    def test_delete_spark_engine_catalogs_required_params(self):
        """
        test_delete_spark_engine_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Invoke method
        response = _service.delete_spark_engine_catalogs(
            engine_id,
            catalog_names,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_names={}'.format(catalog_names) in query_string

    def test_delete_spark_engine_catalogs_required_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_catalogs_required_params.
        _service.enable_retries()
        self.test_delete_spark_engine_catalogs_required_params()

        # Disable retries and run test_delete_spark_engine_catalogs_required_params.
        _service.disable_retries()
        self.test_delete_spark_engine_catalogs_required_params()

    @responses.activate
    def test_delete_spark_engine_catalogs_value_error(self):
        """
        test_delete_spark_engine_catalogs_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_names = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_names": catalog_names,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_spark_engine_catalogs(**req_copy)

    def test_delete_spark_engine_catalogs_value_error_with_retries(self):
        # Enable retries and run test_delete_spark_engine_catalogs_value_error.
        _service.enable_retries()
        self.test_delete_spark_engine_catalogs_value_error()

        # Disable retries and run test_delete_spark_engine_catalogs_value_error.
        _service.disable_retries()
        self.test_delete_spark_engine_catalogs_value_error()


class TestGetSparkEngineCatalog:
    """
    Test Class for get_spark_engine_catalog
    """

    @responses.activate
    def test_get_spark_engine_catalog_all_params(self):
        """
        get_spark_engine_catalog()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine_catalog(
            engine_id,
            catalog_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_catalog_all_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_catalog_all_params.
        _service.enable_retries()
        self.test_get_spark_engine_catalog_all_params()

        # Disable retries and run test_get_spark_engine_catalog_all_params.
        _service.disable_retries()
        self.test_get_spark_engine_catalog_all_params()

    @responses.activate
    def test_get_spark_engine_catalog_required_params(self):
        """
        test_get_spark_engine_catalog_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine_catalog(
            engine_id,
            catalog_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_catalog_required_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_catalog_required_params.
        _service.enable_retries()
        self.test_get_spark_engine_catalog_required_params()

        # Disable retries and run test_get_spark_engine_catalog_required_params.
        _service.disable_retries()
        self.test_get_spark_engine_catalog_required_params()

    @responses.activate
    def test_get_spark_engine_catalog_value_error(self):
        """
        test_get_spark_engine_catalog_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_spark_engine_catalog(**req_copy)

    def test_get_spark_engine_catalog_value_error_with_retries(self):
        # Enable retries and run test_get_spark_engine_catalog_value_error.
        _service.enable_retries()
        self.test_get_spark_engine_catalog_value_error()

        # Disable retries and run test_get_spark_engine_catalog_value_error.
        _service.disable_retries()
        self.test_get_spark_engine_catalog_value_error()


class TestGetSparkEngineHistoryServer:
    """
    Test Class for get_spark_engine_history_server
    """

    @responses.activate
    def test_get_spark_engine_history_server_all_params(self):
        """
        get_spark_engine_history_server()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        mock_response = '{"auto_termination_time": "2022-02-24T07:37:47Z", "cores": "1", "memory": "4G", "start_time": "2022-02-21T07:37:47Z", "state": "started"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine_history_server(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_history_server_all_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_history_server_all_params.
        _service.enable_retries()
        self.test_get_spark_engine_history_server_all_params()

        # Disable retries and run test_get_spark_engine_history_server_all_params.
        _service.disable_retries()
        self.test_get_spark_engine_history_server_all_params()

    @responses.activate
    def test_get_spark_engine_history_server_required_params(self):
        """
        test_get_spark_engine_history_server_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        mock_response = '{"auto_termination_time": "2022-02-24T07:37:47Z", "cores": "1", "memory": "4G", "start_time": "2022-02-21T07:37:47Z", "state": "started"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.get_spark_engine_history_server(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_spark_engine_history_server_required_params_with_retries(self):
        # Enable retries and run test_get_spark_engine_history_server_required_params.
        _service.enable_retries()
        self.test_get_spark_engine_history_server_required_params()

        # Disable retries and run test_get_spark_engine_history_server_required_params.
        _service.disable_retries()
        self.test_get_spark_engine_history_server_required_params()

    @responses.activate
    def test_get_spark_engine_history_server_value_error(self):
        """
        test_get_spark_engine_history_server_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        mock_response = '{"auto_termination_time": "2022-02-24T07:37:47Z", "cores": "1", "memory": "4G", "start_time": "2022-02-21T07:37:47Z", "state": "started"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_spark_engine_history_server(**req_copy)

    def test_get_spark_engine_history_server_value_error_with_retries(self):
        # Enable retries and run test_get_spark_engine_history_server_value_error.
        _service.enable_retries()
        self.test_get_spark_engine_history_server_value_error()

        # Disable retries and run test_get_spark_engine_history_server_value_error.
        _service.disable_retries()
        self.test_get_spark_engine_history_server_value_error()


class TestStartSparkEngineHistoryServer:
    """
    Test Class for start_spark_engine_history_server
    """

    @responses.activate
    def test_start_spark_engine_history_server_all_params(self):
        """
        start_spark_engine_history_server()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        mock_response = '{"auto_termination_time": "2022-02-24T07:37:47Z", "cores": "1", "memory": "4G", "start_time": "2022-02-21T07:37:47Z", "state": "started"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        cores = '1'
        memory = '4G'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.start_spark_engine_history_server(
            engine_id,
            cores=cores,
            memory=memory,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['cores'] == '1'
        assert req_body['memory'] == '4G'

    def test_start_spark_engine_history_server_all_params_with_retries(self):
        # Enable retries and run test_start_spark_engine_history_server_all_params.
        _service.enable_retries()
        self.test_start_spark_engine_history_server_all_params()

        # Disable retries and run test_start_spark_engine_history_server_all_params.
        _service.disable_retries()
        self.test_start_spark_engine_history_server_all_params()

    @responses.activate
    def test_start_spark_engine_history_server_required_params(self):
        """
        test_start_spark_engine_history_server_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        mock_response = '{"auto_termination_time": "2022-02-24T07:37:47Z", "cores": "1", "memory": "4G", "start_time": "2022-02-21T07:37:47Z", "state": "started"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.start_spark_engine_history_server(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_start_spark_engine_history_server_required_params_with_retries(self):
        # Enable retries and run test_start_spark_engine_history_server_required_params.
        _service.enable_retries()
        self.test_start_spark_engine_history_server_required_params()

        # Disable retries and run test_start_spark_engine_history_server_required_params.
        _service.disable_retries()
        self.test_start_spark_engine_history_server_required_params()

    @responses.activate
    def test_start_spark_engine_history_server_value_error(self):
        """
        test_start_spark_engine_history_server_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        mock_response = '{"auto_termination_time": "2022-02-24T07:37:47Z", "cores": "1", "memory": "4G", "start_time": "2022-02-21T07:37:47Z", "state": "started"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.start_spark_engine_history_server(**req_copy)

    def test_start_spark_engine_history_server_value_error_with_retries(self):
        # Enable retries and run test_start_spark_engine_history_server_value_error.
        _service.enable_retries()
        self.test_start_spark_engine_history_server_value_error()

        # Disable retries and run test_start_spark_engine_history_server_value_error.
        _service.disable_retries()
        self.test_start_spark_engine_history_server_value_error()


class TestDeleteSparkEngineHistoryServer:
    """
    Test Class for delete_spark_engine_history_server
    """

    @responses.activate
    def test_delete_spark_engine_history_server_all_params(self):
        """
        delete_spark_engine_history_server()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_spark_engine_history_server(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_spark_engine_history_server_all_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_history_server_all_params.
        _service.enable_retries()
        self.test_delete_spark_engine_history_server_all_params()

        # Disable retries and run test_delete_spark_engine_history_server_all_params.
        _service.disable_retries()
        self.test_delete_spark_engine_history_server_all_params()

    @responses.activate
    def test_delete_spark_engine_history_server_required_params(self):
        """
        test_delete_spark_engine_history_server_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_spark_engine_history_server(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_spark_engine_history_server_required_params_with_retries(self):
        # Enable retries and run test_delete_spark_engine_history_server_required_params.
        _service.enable_retries()
        self.test_delete_spark_engine_history_server_required_params()

        # Disable retries and run test_delete_spark_engine_history_server_required_params.
        _service.disable_retries()
        self.test_delete_spark_engine_history_server_required_params()

    @responses.activate
    def test_delete_spark_engine_history_server_value_error(self):
        """
        test_delete_spark_engine_history_server_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/history_server')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_spark_engine_history_server(**req_copy)

    def test_delete_spark_engine_history_server_value_error_with_retries(self):
        # Enable retries and run test_delete_spark_engine_history_server_value_error.
        _service.enable_retries()
        self.test_delete_spark_engine_history_server_value_error()

        # Disable retries and run test_delete_spark_engine_history_server_value_error.
        _service.disable_retries()
        self.test_delete_spark_engine_history_server_value_error()


class TestPauseSparkEngine:
    """
    Test Class for pause_spark_engine
    """

    @responses.activate
    def test_pause_spark_engine_all_params(self):
        """
        pause_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        force = True
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.pause_spark_engine(
            engine_id,
            force=force,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['force'] == True

    def test_pause_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_pause_spark_engine_all_params.
        _service.enable_retries()
        self.test_pause_spark_engine_all_params()

        # Disable retries and run test_pause_spark_engine_all_params.
        _service.disable_retries()
        self.test_pause_spark_engine_all_params()

    @responses.activate
    def test_pause_spark_engine_required_params(self):
        """
        test_pause_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.pause_spark_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_pause_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_pause_spark_engine_required_params.
        _service.enable_retries()
        self.test_pause_spark_engine_required_params()

        # Disable retries and run test_pause_spark_engine_required_params.
        _service.disable_retries()
        self.test_pause_spark_engine_required_params()

    @responses.activate
    def test_pause_spark_engine_value_error(self):
        """
        test_pause_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.pause_spark_engine(**req_copy)

    def test_pause_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_pause_spark_engine_value_error.
        _service.enable_retries()
        self.test_pause_spark_engine_value_error()

        # Disable retries and run test_pause_spark_engine_value_error.
        _service.disable_retries()
        self.test_pause_spark_engine_value_error()


class TestResumeSparkEngine:
    """
    Test Class for resume_spark_engine
    """

    @responses.activate
    def test_resume_spark_engine_all_params(self):
        """
        resume_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.resume_spark_engine(
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_resume_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_resume_spark_engine_all_params.
        _service.enable_retries()
        self.test_resume_spark_engine_all_params()

        # Disable retries and run test_resume_spark_engine_all_params.
        _service.disable_retries()
        self.test_resume_spark_engine_all_params()

    @responses.activate
    def test_resume_spark_engine_required_params(self):
        """
        test_resume_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Invoke method
        response = _service.resume_spark_engine(
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_resume_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_resume_spark_engine_required_params.
        _service.enable_retries()
        self.test_resume_spark_engine_required_params()

        # Disable retries and run test_resume_spark_engine_required_params.
        _service.disable_retries()
        self.test_resume_spark_engine_required_params()

    @responses.activate
    def test_resume_spark_engine_value_error(self):
        """
        test_resume_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.resume_spark_engine(**req_copy)

    def test_resume_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_resume_spark_engine_value_error.
        _service.enable_retries()
        self.test_resume_spark_engine_value_error()

        # Disable retries and run test_resume_spark_engine_value_error.
        _service.disable_retries()
        self.test_resume_spark_engine_value_error()


class TestScaleSparkEngine:
    """
    Test Class for scale_spark_engine
    """

    @responses.activate
    def test_scale_spark_engine_all_params(self):
        """
        scale_spark_engine()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Set up parameter values
        engine_id = 'testString'
        number_of_nodes = 2
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.scale_spark_engine(
            engine_id,
            number_of_nodes=number_of_nodes,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['number_of_nodes'] == 2

    def test_scale_spark_engine_all_params_with_retries(self):
        # Enable retries and run test_scale_spark_engine_all_params.
        _service.enable_retries()
        self.test_scale_spark_engine_all_params()

        # Disable retries and run test_scale_spark_engine_all_params.
        _service.disable_retries()
        self.test_scale_spark_engine_all_params()

    @responses.activate
    def test_scale_spark_engine_required_params(self):
        """
        test_scale_spark_engine_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Set up parameter values
        engine_id = 'testString'
        number_of_nodes = 2

        # Invoke method
        response = _service.scale_spark_engine(
            engine_id,
            number_of_nodes=number_of_nodes,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['number_of_nodes'] == 2

    def test_scale_spark_engine_required_params_with_retries(self):
        # Enable retries and run test_scale_spark_engine_required_params.
        _service.enable_retries()
        self.test_scale_spark_engine_required_params()

        # Disable retries and run test_scale_spark_engine_required_params.
        _service.disable_retries()
        self.test_scale_spark_engine_required_params()

    @responses.activate
    def test_scale_spark_engine_value_error(self):
        """
        test_scale_spark_engine_value_error()
        """
        # Set up mock
        url = preprocess_url('/spark_engines/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Set up parameter values
        engine_id = 'testString'
        number_of_nodes = 2

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.scale_spark_engine(**req_copy)

    def test_scale_spark_engine_value_error_with_retries(self):
        # Enable retries and run test_scale_spark_engine_value_error.
        _service.enable_retries()
        self.test_scale_spark_engine_value_error()

        # Disable retries and run test_scale_spark_engine_value_error.
        _service.disable_retries()
        self.test_scale_spark_engine_value_error()


class TestListSparkVersions:
    """
    Test Class for list_spark_versions
    """

    @responses.activate
    def test_list_spark_versions_all_params(self):
        """
        list_spark_versions()
        """
        # Set up mock
        url = preprocess_url('/spark_versions')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "spark_versions": [{"cpp": [{"display_name": "Instance Name", "value": "Instance Name"}], "java": [{"display_name": "Instance Name", "value": "Instance Name"}]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_spark_versions(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_versions_all_params_with_retries(self):
        # Enable retries and run test_list_spark_versions_all_params.
        _service.enable_retries()
        self.test_list_spark_versions_all_params()

        # Disable retries and run test_list_spark_versions_all_params.
        _service.disable_retries()
        self.test_list_spark_versions_all_params()

    @responses.activate
    def test_list_spark_versions_required_params(self):
        """
        test_list_spark_versions_required_params()
        """
        # Set up mock
        url = preprocess_url('/spark_versions')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "spark_versions": [{"cpp": [{"display_name": "Instance Name", "value": "Instance Name"}], "java": [{"display_name": "Instance Name", "value": "Instance Name"}]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_spark_versions()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_spark_versions_required_params_with_retries(self):
        # Enable retries and run test_list_spark_versions_required_params.
        _service.enable_retries()
        self.test_list_spark_versions_required_params()

        # Disable retries and run test_list_spark_versions_required_params.
        _service.disable_retries()
        self.test_list_spark_versions_required_params()


# endregion
##############################################################################
# End of Service: SparkEngines
##############################################################################

##############################################################################
# Start of Service: Catalogs
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListCatalogs:
    """
    Test Class for list_catalogs
    """

    @responses.activate
    def test_list_catalogs_all_params(self):
        """
        list_catalogs()
        """
        # Set up mock
        url = preprocess_url('/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_catalogs(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_catalogs_all_params_with_retries(self):
        # Enable retries and run test_list_catalogs_all_params.
        _service.enable_retries()
        self.test_list_catalogs_all_params()

        # Disable retries and run test_list_catalogs_all_params.
        _service.disable_retries()
        self.test_list_catalogs_all_params()

    @responses.activate
    def test_list_catalogs_required_params(self):
        """
        test_list_catalogs_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs')
        mock_response = '{"catalogs": [{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_catalogs()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_catalogs_required_params_with_retries(self):
        # Enable retries and run test_list_catalogs_required_params.
        _service.enable_retries()
        self.test_list_catalogs_required_params()

        # Disable retries and run test_list_catalogs_required_params.
        _service.disable_retries()
        self.test_list_catalogs_required_params()


class TestGetCatalog:
    """
    Test Class for get_catalog
    """

    @responses.activate
    def test_get_catalog_all_params(self):
        """
        get_catalog()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_catalog(
            catalog_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_catalog_all_params_with_retries(self):
        # Enable retries and run test_get_catalog_all_params.
        _service.enable_retries()
        self.test_get_catalog_all_params()

        # Disable retries and run test_get_catalog_all_params.
        _service.disable_retries()
        self.test_get_catalog_all_params()

    @responses.activate
    def test_get_catalog_required_params(self):
        """
        test_get_catalog_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'

        # Invoke method
        response = _service.get_catalog(
            catalog_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_catalog_required_params_with_retries(self):
        # Enable retries and run test_get_catalog_required_params.
        _service.enable_retries()
        self.test_get_catalog_required_params()

        # Disable retries and run test_get_catalog_required_params.
        _service.disable_retries()
        self.test_get_catalog_required_params()

    @responses.activate
    def test_get_catalog_value_error(self):
        """
        test_get_catalog_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString')
        mock_response = '{"actions": ["actions"], "associated_buckets": ["associated_buckets"], "associated_databases": ["associated_databases"], "associated_engines": ["associated_engines"], "catalog_name": "sampleCatalog", "catalog_type": "iceberg", "created_by": "<username>@<domain>.com", "created_on": "1602839833", "days_left": "30", "description": "Iceberg catalog description", "hostname": "s3a://samplehost.com", "last_sync_at": "1602839833", "managed_by": "ibm", "metastore": "glue", "port": "3232", "rest_uri": "https://samplehost-catalog:4352", "status": "running", "sync_description": "Table registration was successful", "sync_exception": ["sync_exception"], "sync_status": "SUCCESS", "tags": ["tags"], "thrift_uri": "thrift://samplehost-catalog:4354"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_catalog(**req_copy)

    def test_get_catalog_value_error_with_retries(self):
        # Enable retries and run test_get_catalog_value_error.
        _service.enable_retries()
        self.test_get_catalog_value_error()

        # Disable retries and run test_get_catalog_value_error.
        _service.disable_retries()
        self.test_get_catalog_value_error()


class TestListSchemas:
    """
    Test Class for list_schemas
    """

    @responses.activate
    def test_list_schemas_all_params(self):
        """
        list_schemas()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "schemas": ["schemas"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_schemas(
            engine_id,
            catalog_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_schemas_all_params_with_retries(self):
        # Enable retries and run test_list_schemas_all_params.
        _service.enable_retries()
        self.test_list_schemas_all_params()

        # Disable retries and run test_list_schemas_all_params.
        _service.disable_retries()
        self.test_list_schemas_all_params()

    @responses.activate
    def test_list_schemas_required_params(self):
        """
        test_list_schemas_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "schemas": ["schemas"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Invoke method
        response = _service.list_schemas(
            engine_id,
            catalog_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_schemas_required_params_with_retries(self):
        # Enable retries and run test_list_schemas_required_params.
        _service.enable_retries()
        self.test_list_schemas_required_params()

        # Disable retries and run test_list_schemas_required_params.
        _service.disable_retries()
        self.test_list_schemas_required_params()

    @responses.activate
    def test_list_schemas_value_error(self):
        """
        test_list_schemas_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}, "schemas": ["schemas"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_schemas(**req_copy)

    def test_list_schemas_value_error_with_retries(self):
        # Enable retries and run test_list_schemas_value_error.
        _service.enable_retries()
        self.test_list_schemas_value_error()

        # Disable retries and run test_list_schemas_value_error.
        _service.disable_retries()
        self.test_list_schemas_value_error()


class TestCreateSchema:
    """
    Test Class for create_schema
    """

    @responses.activate
    def test_create_schema_all_params(self):
        """
        create_schema()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        custom_path = 'sample-path'
        schema_name = 'SampleSchema1'
        bucket_name = 'sample-bucket'
        hostname = 'db2@hostname.com'
        port = 4553
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_schema(
            engine_id,
            catalog_id,
            custom_path,
            schema_name,
            bucket_name=bucket_name,
            hostname=hostname,
            port=port,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['custom_path'] == 'sample-path'
        assert req_body['schema_name'] == 'SampleSchema1'
        assert req_body['bucket_name'] == 'sample-bucket'
        assert req_body['hostname'] == 'db2@hostname.com'
        assert req_body['port'] == 4553

    def test_create_schema_all_params_with_retries(self):
        # Enable retries and run test_create_schema_all_params.
        _service.enable_retries()
        self.test_create_schema_all_params()

        # Disable retries and run test_create_schema_all_params.
        _service.disable_retries()
        self.test_create_schema_all_params()

    @responses.activate
    def test_create_schema_required_params(self):
        """
        test_create_schema_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        custom_path = 'sample-path'
        schema_name = 'SampleSchema1'
        bucket_name = 'sample-bucket'
        hostname = 'db2@hostname.com'
        port = 4553

        # Invoke method
        response = _service.create_schema(
            engine_id,
            catalog_id,
            custom_path,
            schema_name,
            bucket_name=bucket_name,
            hostname=hostname,
            port=port,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['custom_path'] == 'sample-path'
        assert req_body['schema_name'] == 'SampleSchema1'
        assert req_body['bucket_name'] == 'sample-bucket'
        assert req_body['hostname'] == 'db2@hostname.com'
        assert req_body['port'] == 4553

    def test_create_schema_required_params_with_retries(self):
        # Enable retries and run test_create_schema_required_params.
        _service.enable_retries()
        self.test_create_schema_required_params()

        # Disable retries and run test_create_schema_required_params.
        _service.disable_retries()
        self.test_create_schema_required_params()

    @responses.activate
    def test_create_schema_value_error(self):
        """
        test_create_schema_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        custom_path = 'sample-path'
        schema_name = 'SampleSchema1'
        bucket_name = 'sample-bucket'
        hostname = 'db2@hostname.com'
        port = 4553

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "custom_path": custom_path,
            "schema_name": schema_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_schema(**req_copy)

    def test_create_schema_value_error_with_retries(self):
        # Enable retries and run test_create_schema_value_error.
        _service.enable_retries()
        self.test_create_schema_value_error()

        # Disable retries and run test_create_schema_value_error.
        _service.disable_retries()
        self.test_create_schema_value_error()


class TestDeleteSchema:
    """
    Test Class for delete_schema
    """

    @responses.activate
    def test_delete_schema_all_params(self):
        """
        delete_schema()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_schema(
            engine_id,
            catalog_id,
            schema_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_delete_schema_all_params_with_retries(self):
        # Enable retries and run test_delete_schema_all_params.
        _service.enable_retries()
        self.test_delete_schema_all_params()

        # Disable retries and run test_delete_schema_all_params.
        _service.disable_retries()
        self.test_delete_schema_all_params()

    @responses.activate
    def test_delete_schema_required_params(self):
        """
        test_delete_schema_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'

        # Invoke method
        response = _service.delete_schema(
            engine_id,
            catalog_id,
            schema_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_delete_schema_required_params_with_retries(self):
        # Enable retries and run test_delete_schema_required_params.
        _service.enable_retries()
        self.test_delete_schema_required_params()

        # Disable retries and run test_delete_schema_required_params.
        _service.disable_retries()
        self.test_delete_schema_required_params()

    @responses.activate
    def test_delete_schema_value_error(self):
        """
        test_delete_schema_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_schema(**req_copy)

    def test_delete_schema_value_error_with_retries(self):
        # Enable retries and run test_delete_schema_value_error.
        _service.enable_retries()
        self.test_delete_schema_value_error()

        # Disable retries and run test_delete_schema_value_error.
        _service.disable_retries()
        self.test_delete_schema_value_error()


class TestListTables:
    """
    Test Class for list_tables
    """

    @responses.activate
    def test_list_tables_all_params(self):
        """
        list_tables()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables')
        mock_response = '{"tables": ["tables"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        engine_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_tables(
            catalog_id,
            schema_id,
            engine_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_tables_all_params_with_retries(self):
        # Enable retries and run test_list_tables_all_params.
        _service.enable_retries()
        self.test_list_tables_all_params()

        # Disable retries and run test_list_tables_all_params.
        _service.disable_retries()
        self.test_list_tables_all_params()

    @responses.activate
    def test_list_tables_required_params(self):
        """
        test_list_tables_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables')
        mock_response = '{"tables": ["tables"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        engine_id = 'testString'

        # Invoke method
        response = _service.list_tables(
            catalog_id,
            schema_id,
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_tables_required_params_with_retries(self):
        # Enable retries and run test_list_tables_required_params.
        _service.enable_retries()
        self.test_list_tables_required_params()

        # Disable retries and run test_list_tables_required_params.
        _service.disable_retries()
        self.test_list_tables_required_params()

    @responses.activate
    def test_list_tables_value_error(self):
        """
        test_list_tables_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables')
        mock_response = '{"tables": ["tables"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_tables(**req_copy)

    def test_list_tables_value_error_with_retries(self):
        # Enable retries and run test_list_tables_value_error.
        _service.enable_retries()
        self.test_list_tables_value_error()

        # Disable retries and run test_list_tables_value_error.
        _service.disable_retries()
        self.test_list_tables_value_error()


class TestGetTable:
    """
    Test Class for get_table
    """

    @responses.activate
    def test_get_table_all_params(self):
        """
        get_table()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}], "table_name": "table_name"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'
        type = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_table(
            catalog_id,
            schema_id,
            table_id,
            engine_id,
            type=type,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'type={}'.format(type) in query_string

    def test_get_table_all_params_with_retries(self):
        # Enable retries and run test_get_table_all_params.
        _service.enable_retries()
        self.test_get_table_all_params()

        # Disable retries and run test_get_table_all_params.
        _service.disable_retries()
        self.test_get_table_all_params()

    @responses.activate
    def test_get_table_required_params(self):
        """
        test_get_table_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}], "table_name": "table_name"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'

        # Invoke method
        response = _service.get_table(
            catalog_id,
            schema_id,
            table_id,
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_get_table_required_params_with_retries(self):
        # Enable retries and run test_get_table_required_params.
        _service.enable_retries()
        self.test_get_table_required_params()

        # Disable retries and run test_get_table_required_params.
        _service.disable_retries()
        self.test_get_table_required_params()

    @responses.activate
    def test_get_table_value_error(self):
        """
        test_get_table_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}], "table_name": "table_name"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_table(**req_copy)

    def test_get_table_value_error_with_retries(self):
        # Enable retries and run test_get_table_value_error.
        _service.enable_retries()
        self.test_get_table_value_error()

        # Disable retries and run test_get_table_value_error.
        _service.disable_retries()
        self.test_get_table_value_error()


class TestDeleteTable:
    """
    Test Class for delete_table
    """

    @responses.activate
    def test_delete_table_all_params(self):
        """
        delete_table()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'
        type = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_table(
            catalog_id,
            schema_id,
            table_id,
            engine_id,
            type=type,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'type={}'.format(type) in query_string

    def test_delete_table_all_params_with_retries(self):
        # Enable retries and run test_delete_table_all_params.
        _service.enable_retries()
        self.test_delete_table_all_params()

        # Disable retries and run test_delete_table_all_params.
        _service.disable_retries()
        self.test_delete_table_all_params()

    @responses.activate
    def test_delete_table_required_params(self):
        """
        test_delete_table_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'

        # Invoke method
        response = _service.delete_table(
            catalog_id,
            schema_id,
            table_id,
            engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_delete_table_required_params_with_retries(self):
        # Enable retries and run test_delete_table_required_params.
        _service.enable_retries()
        self.test_delete_table_required_params()

        # Disable retries and run test_delete_table_required_params.
        _service.disable_retries()
        self.test_delete_table_required_params()

    @responses.activate
    def test_delete_table_value_error(self):
        """
        test_delete_table_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
            "engine_id": engine_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_table(**req_copy)

    def test_delete_table_value_error_with_retries(self):
        # Enable retries and run test_delete_table_value_error.
        _service.enable_retries()
        self.test_delete_table_value_error()

        # Disable retries and run test_delete_table_value_error.
        _service.disable_retries()
        self.test_delete_table_value_error()


class TestUpdateTable:
    """
    Test Class for update_table
    """

    @responses.activate
    def test_update_table_all_params(self):
        """
        update_table()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}], "table_name": "table_name"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a TablePatch model
        table_patch_model = {}
        table_patch_model['table_name'] = 'updated_table_name'

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'
        body = table_patch_model
        type = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_table(
            catalog_id,
            schema_id,
            table_id,
            engine_id,
            body,
            type=type,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        assert 'type={}'.format(type) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_table_all_params_with_retries(self):
        # Enable retries and run test_update_table_all_params.
        _service.enable_retries()
        self.test_update_table_all_params()

        # Disable retries and run test_update_table_all_params.
        _service.disable_retries()
        self.test_update_table_all_params()

    @responses.activate
    def test_update_table_required_params(self):
        """
        test_update_table_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}], "table_name": "table_name"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a TablePatch model
        table_patch_model = {}
        table_patch_model['table_name'] = 'updated_table_name'

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'
        body = table_patch_model

        # Invoke method
        response = _service.update_table(
            catalog_id,
            schema_id,
            table_id,
            engine_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_table_required_params_with_retries(self):
        # Enable retries and run test_update_table_required_params.
        _service.enable_retries()
        self.test_update_table_required_params()

        # Disable retries and run test_update_table_required_params.
        _service.disable_retries()
        self.test_update_table_required_params()

    @responses.activate
    def test_update_table_value_error(self):
        """
        test_update_table_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}], "table_name": "table_name"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a TablePatch model
        table_patch_model = {}
        table_patch_model['table_name'] = 'updated_table_name'

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        engine_id = 'testString'
        body = table_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
            "engine_id": engine_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_table(**req_copy)

    def test_update_table_value_error_with_retries(self):
        # Enable retries and run test_update_table_value_error.
        _service.enable_retries()
        self.test_update_table_value_error()

        # Disable retries and run test_update_table_value_error.
        _service.disable_retries()
        self.test_update_table_value_error()


class TestListColumns:
    """
    Test Class for list_columns
    """

    @responses.activate
    def test_list_columns_all_params(self):
        """
        list_columns()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_columns(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_columns_all_params_with_retries(self):
        # Enable retries and run test_list_columns_all_params.
        _service.enable_retries()
        self.test_list_columns_all_params()

        # Disable retries and run test_list_columns_all_params.
        _service.disable_retries()
        self.test_list_columns_all_params()

    @responses.activate
    def test_list_columns_required_params(self):
        """
        test_list_columns_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'

        # Invoke method
        response = _service.list_columns(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_columns_required_params_with_retries(self):
        # Enable retries and run test_list_columns_required_params.
        _service.enable_retries()
        self.test_list_columns_required_params()

        # Disable retries and run test_list_columns_required_params.
        _service.disable_retries()
        self.test_list_columns_required_params()

    @responses.activate
    def test_list_columns_value_error(self):
        """
        test_list_columns_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_columns(**req_copy)

    def test_list_columns_value_error_with_retries(self):
        # Enable retries and run test_list_columns_value_error.
        _service.enable_retries()
        self.test_list_columns_value_error()

        # Disable retries and run test_list_columns_value_error.
        _service.disable_retries()
        self.test_list_columns_value_error()


class TestCreateColumns:
    """
    Test Class for create_columns
    """

    @responses.activate
    def test_create_columns_all_params(self):
        """
        create_columns()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a Column model
        column_model = {}
        column_model['column_name'] = 'expenses'
        column_model['comment'] = 'expenses column'
        column_model['extra'] = 'varchar'
        column_model['length'] = '30'
        column_model['precision'] = '10'
        column_model['scale'] = '2'
        column_model['type'] = 'varchar'

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        columns = [column_model]
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_columns(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            columns=columns,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['columns'] == [column_model]

    def test_create_columns_all_params_with_retries(self):
        # Enable retries and run test_create_columns_all_params.
        _service.enable_retries()
        self.test_create_columns_all_params()

        # Disable retries and run test_create_columns_all_params.
        _service.disable_retries()
        self.test_create_columns_all_params()

    @responses.activate
    def test_create_columns_required_params(self):
        """
        test_create_columns_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a Column model
        column_model = {}
        column_model['column_name'] = 'expenses'
        column_model['comment'] = 'expenses column'
        column_model['extra'] = 'varchar'
        column_model['length'] = '30'
        column_model['precision'] = '10'
        column_model['scale'] = '2'
        column_model['type'] = 'varchar'

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        columns = [column_model]

        # Invoke method
        response = _service.create_columns(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            columns=columns,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['columns'] == [column_model]

    def test_create_columns_required_params_with_retries(self):
        # Enable retries and run test_create_columns_required_params.
        _service.enable_retries()
        self.test_create_columns_required_params()

        # Disable retries and run test_create_columns_required_params.
        _service.disable_retries()
        self.test_create_columns_required_params()

    @responses.activate
    def test_create_columns_value_error(self):
        """
        test_create_columns_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns')
        mock_response = '{"columns": [{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}]}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a Column model
        column_model = {}
        column_model['column_name'] = 'expenses'
        column_model['comment'] = 'expenses column'
        column_model['extra'] = 'varchar'
        column_model['length'] = '30'
        column_model['precision'] = '10'
        column_model['scale'] = '2'
        column_model['type'] = 'varchar'

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        columns = [column_model]

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_columns(**req_copy)

    def test_create_columns_value_error_with_retries(self):
        # Enable retries and run test_create_columns_value_error.
        _service.enable_retries()
        self.test_create_columns_value_error()

        # Disable retries and run test_create_columns_value_error.
        _service.disable_retries()
        self.test_create_columns_value_error()


class TestDeleteColumn:
    """
    Test Class for delete_column
    """

    @responses.activate
    def test_delete_column_all_params(self):
        """
        delete_column()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        column_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_column(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            column_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_delete_column_all_params_with_retries(self):
        # Enable retries and run test_delete_column_all_params.
        _service.enable_retries()
        self.test_delete_column_all_params()

        # Disable retries and run test_delete_column_all_params.
        _service.disable_retries()
        self.test_delete_column_all_params()

    @responses.activate
    def test_delete_column_required_params(self):
        """
        test_delete_column_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        column_id = 'testString'

        # Invoke method
        response = _service.delete_column(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            column_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_delete_column_required_params_with_retries(self):
        # Enable retries and run test_delete_column_required_params.
        _service.enable_retries()
        self.test_delete_column_required_params()

        # Disable retries and run test_delete_column_required_params.
        _service.disable_retries()
        self.test_delete_column_required_params()

    @responses.activate
    def test_delete_column_value_error(self):
        """
        test_delete_column_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        column_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
            "column_id": column_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_column(**req_copy)

    def test_delete_column_value_error_with_retries(self):
        # Enable retries and run test_delete_column_value_error.
        _service.enable_retries()
        self.test_delete_column_value_error()

        # Disable retries and run test_delete_column_value_error.
        _service.disable_retries()
        self.test_delete_column_value_error()


class TestUpdateColumn:
    """
    Test Class for update_column
    """

    @responses.activate
    def test_update_column_all_params(self):
        """
        update_column()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns/testString')
        mock_response = '{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a ColumnPatch model
        column_patch_model = {}
        column_patch_model['column_name'] = 'expenses'

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        column_id = 'testString'
        body = column_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_column(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            column_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_column_all_params_with_retries(self):
        # Enable retries and run test_update_column_all_params.
        _service.enable_retries()
        self.test_update_column_all_params()

        # Disable retries and run test_update_column_all_params.
        _service.disable_retries()
        self.test_update_column_all_params()

    @responses.activate
    def test_update_column_required_params(self):
        """
        test_update_column_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns/testString')
        mock_response = '{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a ColumnPatch model
        column_patch_model = {}
        column_patch_model['column_name'] = 'expenses'

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        column_id = 'testString'
        body = column_patch_model

        # Invoke method
        response = _service.update_column(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            column_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_column_required_params_with_retries(self):
        # Enable retries and run test_update_column_required_params.
        _service.enable_retries()
        self.test_update_column_required_params()

        # Disable retries and run test_update_column_required_params.
        _service.disable_retries()
        self.test_update_column_required_params()

    @responses.activate
    def test_update_column_value_error(self):
        """
        test_update_column_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/columns/testString')
        mock_response = '{"column_name": "expenses", "comment": "expenses column", "extra": "varchar", "length": "30", "precision": "10", "scale": "2", "type": "varchar"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a ColumnPatch model
        column_patch_model = {}
        column_patch_model['column_name'] = 'expenses'

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        column_id = 'testString'
        body = column_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
            "column_id": column_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_column(**req_copy)

    def test_update_column_value_error_with_retries(self):
        # Enable retries and run test_update_column_value_error.
        _service.enable_retries()
        self.test_update_column_value_error()

        # Disable retries and run test_update_column_value_error.
        _service.disable_retries()
        self.test_update_column_value_error()


class TestListTableSnapshots:
    """
    Test Class for list_table_snapshots
    """

    @responses.activate
    def test_list_table_snapshots_all_params(self):
        """
        list_table_snapshots()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/snapshots')
        mock_response = '{"snapshots": [{"added_data_files": "1", "added_files_size": "17425", "added_records": "3277", "changed_partition_count": "1", "committed_at": "1609379392", "operation": "alter", "snapshot_id": "2332342122211222", "total_data_files": "2", "total_delete_files": "0", "total_equality_deletes": "0", "total_position_deletes": "0", "total_records": "5000"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_table_snapshots(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_table_snapshots_all_params_with_retries(self):
        # Enable retries and run test_list_table_snapshots_all_params.
        _service.enable_retries()
        self.test_list_table_snapshots_all_params()

        # Disable retries and run test_list_table_snapshots_all_params.
        _service.disable_retries()
        self.test_list_table_snapshots_all_params()

    @responses.activate
    def test_list_table_snapshots_required_params(self):
        """
        test_list_table_snapshots_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/snapshots')
        mock_response = '{"snapshots": [{"added_data_files": "1", "added_files_size": "17425", "added_records": "3277", "changed_partition_count": "1", "committed_at": "1609379392", "operation": "alter", "snapshot_id": "2332342122211222", "total_data_files": "2", "total_delete_files": "0", "total_equality_deletes": "0", "total_position_deletes": "0", "total_records": "5000"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'

        # Invoke method
        response = _service.list_table_snapshots(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string

    def test_list_table_snapshots_required_params_with_retries(self):
        # Enable retries and run test_list_table_snapshots_required_params.
        _service.enable_retries()
        self.test_list_table_snapshots_required_params()

        # Disable retries and run test_list_table_snapshots_required_params.
        _service.disable_retries()
        self.test_list_table_snapshots_required_params()

    @responses.activate
    def test_list_table_snapshots_value_error(self):
        """
        test_list_table_snapshots_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/snapshots')
        mock_response = '{"snapshots": [{"added_data_files": "1", "added_files_size": "17425", "added_records": "3277", "changed_partition_count": "1", "committed_at": "1609379392", "operation": "alter", "snapshot_id": "2332342122211222", "total_data_files": "2", "total_delete_files": "0", "total_equality_deletes": "0", "total_position_deletes": "0", "total_records": "5000"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_table_snapshots(**req_copy)

    def test_list_table_snapshots_value_error_with_retries(self):
        # Enable retries and run test_list_table_snapshots_value_error.
        _service.enable_retries()
        self.test_list_table_snapshots_value_error()

        # Disable retries and run test_list_table_snapshots_value_error.
        _service.disable_retries()
        self.test_list_table_snapshots_value_error()


class TestRollbackTable:
    """
    Test Class for rollback_table
    """

    @responses.activate
    def test_rollback_table_all_params(self):
        """
        rollback_table()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/rollback')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        snapshot_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.rollback_table(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            snapshot_id=snapshot_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['snapshot_id'] == 'testString'

    def test_rollback_table_all_params_with_retries(self):
        # Enable retries and run test_rollback_table_all_params.
        _service.enable_retries()
        self.test_rollback_table_all_params()

        # Disable retries and run test_rollback_table_all_params.
        _service.disable_retries()
        self.test_rollback_table_all_params()

    @responses.activate
    def test_rollback_table_required_params(self):
        """
        test_rollback_table_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/rollback')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        snapshot_id = 'testString'

        # Invoke method
        response = _service.rollback_table(
            engine_id,
            catalog_id,
            schema_id,
            table_id,
            snapshot_id=snapshot_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'engine_id={}'.format(engine_id) in query_string
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['snapshot_id'] == 'testString'

    def test_rollback_table_required_params_with_retries(self):
        # Enable retries and run test_rollback_table_required_params.
        _service.enable_retries()
        self.test_rollback_table_required_params()

        # Disable retries and run test_rollback_table_required_params.
        _service.disable_retries()
        self.test_rollback_table_required_params()

    @responses.activate
    def test_rollback_table_value_error(self):
        """
        test_rollback_table_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/rollback')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        engine_id = 'testString'
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        snapshot_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "engine_id": engine_id,
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.rollback_table(**req_copy)

    def test_rollback_table_value_error_with_retries(self):
        # Enable retries and run test_rollback_table_value_error.
        _service.enable_retries()
        self.test_rollback_table_value_error()

        # Disable retries and run test_rollback_table_value_error.
        _service.disable_retries()
        self.test_rollback_table_value_error()


class TestUpdateSyncCatalog:
    """
    Test Class for update_sync_catalog
    """

    @responses.activate
    def test_update_sync_catalog_all_params(self):
        """
        update_sync_catalog()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/sync')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SyncCatalogs model
        sync_catalogs_model = {}
        sync_catalogs_model['auto_add_new_tables'] = True
        sync_catalogs_model['sync_iceberg_md'] = True

        # Set up parameter values
        catalog_id = 'testString'
        body = sync_catalogs_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_sync_catalog(
            catalog_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_sync_catalog_all_params_with_retries(self):
        # Enable retries and run test_update_sync_catalog_all_params.
        _service.enable_retries()
        self.test_update_sync_catalog_all_params()

        # Disable retries and run test_update_sync_catalog_all_params.
        _service.disable_retries()
        self.test_update_sync_catalog_all_params()

    @responses.activate
    def test_update_sync_catalog_required_params(self):
        """
        test_update_sync_catalog_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/sync')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SyncCatalogs model
        sync_catalogs_model = {}
        sync_catalogs_model['auto_add_new_tables'] = True
        sync_catalogs_model['sync_iceberg_md'] = True

        # Set up parameter values
        catalog_id = 'testString'
        body = sync_catalogs_model

        # Invoke method
        response = _service.update_sync_catalog(
            catalog_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_sync_catalog_required_params_with_retries(self):
        # Enable retries and run test_update_sync_catalog_required_params.
        _service.enable_retries()
        self.test_update_sync_catalog_required_params()

        # Disable retries and run test_update_sync_catalog_required_params.
        _service.disable_retries()
        self.test_update_sync_catalog_required_params()

    @responses.activate
    def test_update_sync_catalog_value_error(self):
        """
        test_update_sync_catalog_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/sync')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a SyncCatalogs model
        sync_catalogs_model = {}
        sync_catalogs_model['auto_add_new_tables'] = True
        sync_catalogs_model['sync_iceberg_md'] = True

        # Set up parameter values
        catalog_id = 'testString'
        body = sync_catalogs_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_sync_catalog(**req_copy)

    def test_update_sync_catalog_value_error_with_retries(self):
        # Enable retries and run test_update_sync_catalog_value_error.
        _service.enable_retries()
        self.test_update_sync_catalog_value_error()

        # Disable retries and run test_update_sync_catalog_value_error.
        _service.disable_retries()
        self.test_update_sync_catalog_value_error()


# endregion
##############################################################################
# End of Service: Catalogs
##############################################################################

##############################################################################
# Start of Service: Services
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListMilvusServices:
    """
    Test Class for list_milvus_services
    """

    @responses.activate
    def test_list_milvus_services_all_params(self):
        """
        list_milvus_services()
        """
        # Set up mock
        url = preprocess_url('/milvus_services')
        mock_response = '{"milvus_services": [{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_milvus_services(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_milvus_services_all_params_with_retries(self):
        # Enable retries and run test_list_milvus_services_all_params.
        _service.enable_retries()
        self.test_list_milvus_services_all_params()

        # Disable retries and run test_list_milvus_services_all_params.
        _service.disable_retries()
        self.test_list_milvus_services_all_params()

    @responses.activate
    def test_list_milvus_services_required_params(self):
        """
        test_list_milvus_services_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services')
        mock_response = '{"milvus_services": [{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_milvus_services()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_milvus_services_required_params_with_retries(self):
        # Enable retries and run test_list_milvus_services_required_params.
        _service.enable_retries()
        self.test_list_milvus_services_required_params()

        # Disable retries and run test_list_milvus_services_required_params.
        _service.disable_retries()
        self.test_list_milvus_services_required_params()


class TestCreateMilvusService:
    """
    Test Class for create_milvus_service
    """

    @responses.activate
    def test_create_milvus_service_all_params(self):
        """
        create_milvus_service()
        """
        # Set up mock
        url = preprocess_url('/milvus_services')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_name = 'Sample bucket name'
        origin = 'native'
        root_path = 'Sample path'
        service_display_name = 'sampleService'
        bucket_type = 'Sample bucket type'
        description = 'milvus service for running sql queries'
        index_type = 'FLAT'
        iw_cpu = 1
        iw_memory = 1
        iw_replicas = 1
        managed_by = 'customer'
        qw_cpu = 1
        qw_memory = 1
        qw_replicas = 1
        tags = ['tag1', 'tag2']
        tshirt_size = 'small'
        vector_dimension = 384
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_milvus_service(
            bucket_name,
            origin,
            root_path,
            service_display_name,
            bucket_type=bucket_type,
            description=description,
            index_type=index_type,
            iw_cpu=iw_cpu,
            iw_memory=iw_memory,
            iw_replicas=iw_replicas,
            managed_by=managed_by,
            qw_cpu=qw_cpu,
            qw_memory=qw_memory,
            qw_replicas=qw_replicas,
            tags=tags,
            tshirt_size=tshirt_size,
            vector_dimension=vector_dimension,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['bucket_name'] == 'Sample bucket name'
        assert req_body['origin'] == 'native'
        assert req_body['root_path'] == 'Sample path'
        assert req_body['service_display_name'] == 'sampleService'
        assert req_body['bucket_type'] == 'Sample bucket type'
        assert req_body['description'] == 'milvus service for running sql queries'
        assert req_body['index_type'] == 'FLAT'
        assert req_body['iw_cpu'] == 1
        assert req_body['iw_memory'] == 1
        assert req_body['iw_replicas'] == 1
        assert req_body['managed_by'] == 'customer'
        assert req_body['qw_cpu'] == 1
        assert req_body['qw_memory'] == 1
        assert req_body['qw_replicas'] == 1
        assert req_body['tags'] == ['tag1', 'tag2']
        assert req_body['tshirt_size'] == 'small'
        assert req_body['vector_dimension'] == 384

    def test_create_milvus_service_all_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_all_params.
        _service.enable_retries()
        self.test_create_milvus_service_all_params()

        # Disable retries and run test_create_milvus_service_all_params.
        _service.disable_retries()
        self.test_create_milvus_service_all_params()

    @responses.activate
    def test_create_milvus_service_required_params(self):
        """
        test_create_milvus_service_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_name = 'Sample bucket name'
        origin = 'native'
        root_path = 'Sample path'
        service_display_name = 'sampleService'
        bucket_type = 'Sample bucket type'
        description = 'milvus service for running sql queries'
        index_type = 'FLAT'
        iw_cpu = 1
        iw_memory = 1
        iw_replicas = 1
        managed_by = 'customer'
        qw_cpu = 1
        qw_memory = 1
        qw_replicas = 1
        tags = ['tag1', 'tag2']
        tshirt_size = 'small'
        vector_dimension = 384

        # Invoke method
        response = _service.create_milvus_service(
            bucket_name,
            origin,
            root_path,
            service_display_name,
            bucket_type=bucket_type,
            description=description,
            index_type=index_type,
            iw_cpu=iw_cpu,
            iw_memory=iw_memory,
            iw_replicas=iw_replicas,
            managed_by=managed_by,
            qw_cpu=qw_cpu,
            qw_memory=qw_memory,
            qw_replicas=qw_replicas,
            tags=tags,
            tshirt_size=tshirt_size,
            vector_dimension=vector_dimension,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['bucket_name'] == 'Sample bucket name'
        assert req_body['origin'] == 'native'
        assert req_body['root_path'] == 'Sample path'
        assert req_body['service_display_name'] == 'sampleService'
        assert req_body['bucket_type'] == 'Sample bucket type'
        assert req_body['description'] == 'milvus service for running sql queries'
        assert req_body['index_type'] == 'FLAT'
        assert req_body['iw_cpu'] == 1
        assert req_body['iw_memory'] == 1
        assert req_body['iw_replicas'] == 1
        assert req_body['managed_by'] == 'customer'
        assert req_body['qw_cpu'] == 1
        assert req_body['qw_memory'] == 1
        assert req_body['qw_replicas'] == 1
        assert req_body['tags'] == ['tag1', 'tag2']
        assert req_body['tshirt_size'] == 'small'
        assert req_body['vector_dimension'] == 384

    def test_create_milvus_service_required_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_required_params.
        _service.enable_retries()
        self.test_create_milvus_service_required_params()

        # Disable retries and run test_create_milvus_service_required_params.
        _service.disable_retries()
        self.test_create_milvus_service_required_params()

    @responses.activate
    def test_create_milvus_service_value_error(self):
        """
        test_create_milvus_service_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        bucket_name = 'Sample bucket name'
        origin = 'native'
        root_path = 'Sample path'
        service_display_name = 'sampleService'
        bucket_type = 'Sample bucket type'
        description = 'milvus service for running sql queries'
        index_type = 'FLAT'
        iw_cpu = 1
        iw_memory = 1
        iw_replicas = 1
        managed_by = 'customer'
        qw_cpu = 1
        qw_memory = 1
        qw_replicas = 1
        tags = ['tag1', 'tag2']
        tshirt_size = 'small'
        vector_dimension = 384

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "bucket_name": bucket_name,
            "origin": origin,
            "root_path": root_path,
            "service_display_name": service_display_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_milvus_service(**req_copy)

    def test_create_milvus_service_value_error_with_retries(self):
        # Enable retries and run test_create_milvus_service_value_error.
        _service.enable_retries()
        self.test_create_milvus_service_value_error()

        # Disable retries and run test_create_milvus_service_value_error.
        _service.disable_retries()
        self.test_create_milvus_service_value_error()


class TestGetMilvusService:
    """
    Test Class for get_milvus_service
    """

    @responses.activate
    def test_get_milvus_service_all_params(self):
        """
        get_milvus_service()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_milvus_service(
            service_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_milvus_service_all_params_with_retries(self):
        # Enable retries and run test_get_milvus_service_all_params.
        _service.enable_retries()
        self.test_get_milvus_service_all_params()

        # Disable retries and run test_get_milvus_service_all_params.
        _service.disable_retries()
        self.test_get_milvus_service_all_params()

    @responses.activate
    def test_get_milvus_service_required_params(self):
        """
        test_get_milvus_service_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'

        # Invoke method
        response = _service.get_milvus_service(
            service_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_milvus_service_required_params_with_retries(self):
        # Enable retries and run test_get_milvus_service_required_params.
        _service.enable_retries()
        self.test_get_milvus_service_required_params()

        # Disable retries and run test_get_milvus_service_required_params.
        _service.disable_retries()
        self.test_get_milvus_service_required_params()

    @responses.activate
    def test_get_milvus_service_value_error(self):
        """
        test_get_milvus_service_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_milvus_service(**req_copy)

    def test_get_milvus_service_value_error_with_retries(self):
        # Enable retries and run test_get_milvus_service_value_error.
        _service.enable_retries()
        self.test_get_milvus_service_value_error()

        # Disable retries and run test_get_milvus_service_value_error.
        _service.disable_retries()
        self.test_get_milvus_service_value_error()


class TestDeleteMilvusService:
    """
    Test Class for delete_milvus_service
    """

    @responses.activate
    def test_delete_milvus_service_all_params(self):
        """
        delete_milvus_service()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        service_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_milvus_service(
            service_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_milvus_service_all_params_with_retries(self):
        # Enable retries and run test_delete_milvus_service_all_params.
        _service.enable_retries()
        self.test_delete_milvus_service_all_params()

        # Disable retries and run test_delete_milvus_service_all_params.
        _service.disable_retries()
        self.test_delete_milvus_service_all_params()

    @responses.activate
    def test_delete_milvus_service_required_params(self):
        """
        test_delete_milvus_service_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        service_id = 'testString'

        # Invoke method
        response = _service.delete_milvus_service(
            service_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_milvus_service_required_params_with_retries(self):
        # Enable retries and run test_delete_milvus_service_required_params.
        _service.enable_retries()
        self.test_delete_milvus_service_required_params()

        # Disable retries and run test_delete_milvus_service_required_params.
        _service.disable_retries()
        self.test_delete_milvus_service_required_params()

    @responses.activate
    def test_delete_milvus_service_value_error(self):
        """
        test_delete_milvus_service_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        service_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_milvus_service(**req_copy)

    def test_delete_milvus_service_value_error_with_retries(self):
        # Enable retries and run test_delete_milvus_service_value_error.
        _service.enable_retries()
        self.test_delete_milvus_service_value_error()

        # Disable retries and run test_delete_milvus_service_value_error.
        _service.disable_retries()
        self.test_delete_milvus_service_value_error()


class TestUpdateMilvusService:
    """
    Test Class for update_milvus_service
    """

    @responses.activate
    def test_update_milvus_service_all_params(self):
        """
        update_milvus_service()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a MilvusServicePatch model
        milvus_service_patch_model = {}
        milvus_service_patch_model['description'] = 'updated description for milvus service'
        milvus_service_patch_model['service_display_name'] = 'sampleService'
        milvus_service_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        service_id = 'testString'
        body = milvus_service_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_milvus_service(
            service_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_milvus_service_all_params_with_retries(self):
        # Enable retries and run test_update_milvus_service_all_params.
        _service.enable_retries()
        self.test_update_milvus_service_all_params()

        # Disable retries and run test_update_milvus_service_all_params.
        _service.disable_retries()
        self.test_update_milvus_service_all_params()

    @responses.activate
    def test_update_milvus_service_required_params(self):
        """
        test_update_milvus_service_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a MilvusServicePatch model
        milvus_service_patch_model = {}
        milvus_service_patch_model['description'] = 'updated description for milvus service'
        milvus_service_patch_model['service_display_name'] = 'sampleService'
        milvus_service_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        service_id = 'testString'
        body = milvus_service_patch_model

        # Invoke method
        response = _service.update_milvus_service(
            service_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_milvus_service_required_params_with_retries(self):
        # Enable retries and run test_update_milvus_service_required_params.
        _service.enable_retries()
        self.test_update_milvus_service_required_params()

        # Disable retries and run test_update_milvus_service_required_params.
        _service.disable_retries()
        self.test_update_milvus_service_required_params()

    @responses.activate
    def test_update_milvus_service_value_error(self):
        """
        test_update_milvus_service_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a MilvusServicePatch model
        milvus_service_patch_model = {}
        milvus_service_patch_model['description'] = 'updated description for milvus service'
        milvus_service_patch_model['service_display_name'] = 'sampleService'
        milvus_service_patch_model['tags'] = ['tag1', 'tag2']

        # Set up parameter values
        service_id = 'testString'
        body = milvus_service_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_milvus_service(**req_copy)

    def test_update_milvus_service_value_error_with_retries(self):
        # Enable retries and run test_update_milvus_service_value_error.
        _service.enable_retries()
        self.test_update_milvus_service_value_error()

        # Disable retries and run test_update_milvus_service_value_error.
        _service.disable_retries()
        self.test_update_milvus_service_value_error()


class TestUpdateMilvusServiceBucket:
    """
    Test Class for update_milvus_service_bucket
    """

    @responses.activate
    def test_update_milvus_service_bucket_all_params(self):
        """
        update_milvus_service_bucket()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/bucket')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a MilvusServiceBucketPatch model
        milvus_service_bucket_patch_model = {}
        milvus_service_bucket_patch_model['bucket_name'] = 'Sample bucket name'
        milvus_service_bucket_patch_model['managed_by'] = 'customer'
        milvus_service_bucket_patch_model['root_path'] = 'Sample path'
        milvus_service_bucket_patch_model['tshirt_size'] = 'small'

        # Set up parameter values
        service_id = 'testString'
        body = milvus_service_bucket_patch_model
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.update_milvus_service_bucket(
            service_id,
            body,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_milvus_service_bucket_all_params_with_retries(self):
        # Enable retries and run test_update_milvus_service_bucket_all_params.
        _service.enable_retries()
        self.test_update_milvus_service_bucket_all_params()

        # Disable retries and run test_update_milvus_service_bucket_all_params.
        _service.disable_retries()
        self.test_update_milvus_service_bucket_all_params()

    @responses.activate
    def test_update_milvus_service_bucket_required_params(self):
        """
        test_update_milvus_service_bucket_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/bucket')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a MilvusServiceBucketPatch model
        milvus_service_bucket_patch_model = {}
        milvus_service_bucket_patch_model['bucket_name'] = 'Sample bucket name'
        milvus_service_bucket_patch_model['managed_by'] = 'customer'
        milvus_service_bucket_patch_model['root_path'] = 'Sample path'
        milvus_service_bucket_patch_model['tshirt_size'] = 'small'

        # Set up parameter values
        service_id = 'testString'
        body = milvus_service_bucket_patch_model

        # Invoke method
        response = _service.update_milvus_service_bucket(
            service_id,
            body,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body == body

    def test_update_milvus_service_bucket_required_params_with_retries(self):
        # Enable retries and run test_update_milvus_service_bucket_required_params.
        _service.enable_retries()
        self.test_update_milvus_service_bucket_required_params()

        # Disable retries and run test_update_milvus_service_bucket_required_params.
        _service.disable_retries()
        self.test_update_milvus_service_bucket_required_params()

    @responses.activate
    def test_update_milvus_service_bucket_value_error(self):
        """
        test_update_milvus_service_bucket_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/bucket')
        mock_response = '{"access_key": "Sample bucket access key", "actions": ["actions"], "bucket_name": "Sample bucket name", "bucket_type": "Sample bucket type", "created_by": "<username>@<domain>.com", "created_on": 1, "description": "milvus service for running sql queries", "endpoint": "Sample bucket type", "grpc_host": "example.grpc.host", "grpc_port": 1, "host_name": "sampleMilvus", "https_host": "example.https.host", "https_port": 1, "origin": "native", "root_path": "Sample path", "secret_key": "Sample bucket secret access key", "service_display_name": "sampleService", "service_id": "sampleService123", "status": "running", "status_code": 11, "tags": ["tags"], "tshirt_size": "small", "type": "milvus"}'
        responses.add(
            responses.PATCH,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Construct a dict representation of a MilvusServiceBucketPatch model
        milvus_service_bucket_patch_model = {}
        milvus_service_bucket_patch_model['bucket_name'] = 'Sample bucket name'
        milvus_service_bucket_patch_model['managed_by'] = 'customer'
        milvus_service_bucket_patch_model['root_path'] = 'Sample path'
        milvus_service_bucket_patch_model['tshirt_size'] = 'small'

        # Set up parameter values
        service_id = 'testString'
        body = milvus_service_bucket_patch_model

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
            "body": body,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.update_milvus_service_bucket(**req_copy)

    def test_update_milvus_service_bucket_value_error_with_retries(self):
        # Enable retries and run test_update_milvus_service_bucket_value_error.
        _service.enable_retries()
        self.test_update_milvus_service_bucket_value_error()

        # Disable retries and run test_update_milvus_service_bucket_value_error.
        _service.disable_retries()
        self.test_update_milvus_service_bucket_value_error()


class TestListMilvusServiceDatabases:
    """
    Test Class for list_milvus_service_databases
    """

    @responses.activate
    def test_list_milvus_service_databases_all_params(self):
        """
        list_milvus_service_databases()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/databases')
        mock_response = '{"milvus_databases": ["[\\"default\\",\\"new\\"]"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_milvus_service_databases(
            service_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_milvus_service_databases_all_params_with_retries(self):
        # Enable retries and run test_list_milvus_service_databases_all_params.
        _service.enable_retries()
        self.test_list_milvus_service_databases_all_params()

        # Disable retries and run test_list_milvus_service_databases_all_params.
        _service.disable_retries()
        self.test_list_milvus_service_databases_all_params()

    @responses.activate
    def test_list_milvus_service_databases_required_params(self):
        """
        test_list_milvus_service_databases_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/databases')
        mock_response = '{"milvus_databases": ["[\\"default\\",\\"new\\"]"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'

        # Invoke method
        response = _service.list_milvus_service_databases(
            service_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_milvus_service_databases_required_params_with_retries(self):
        # Enable retries and run test_list_milvus_service_databases_required_params.
        _service.enable_retries()
        self.test_list_milvus_service_databases_required_params()

        # Disable retries and run test_list_milvus_service_databases_required_params.
        _service.disable_retries()
        self.test_list_milvus_service_databases_required_params()

    @responses.activate
    def test_list_milvus_service_databases_value_error(self):
        """
        test_list_milvus_service_databases_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/databases')
        mock_response = '{"milvus_databases": ["[\\"default\\",\\"new\\"]"]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_milvus_service_databases(**req_copy)

    def test_list_milvus_service_databases_value_error_with_retries(self):
        # Enable retries and run test_list_milvus_service_databases_value_error.
        _service.enable_retries()
        self.test_list_milvus_service_databases_value_error()

        # Disable retries and run test_list_milvus_service_databases_value_error.
        _service.disable_retries()
        self.test_list_milvus_service_databases_value_error()


class TestListMilvusDatabaseCollections:
    """
    Test Class for list_milvus_database_collections
    """

    @responses.activate
    def test_list_milvus_database_collections_all_params(self):
        """
        list_milvus_database_collections()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/databases/testString/collections')
        mock_response = '{"collections": [{"collection_id": 1, "collection_name": "col1", "physical_channels": ["physical_channels"], "virtual_channels": ["virtual_channels"]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'
        database_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_milvus_database_collections(
            service_id,
            database_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_milvus_database_collections_all_params_with_retries(self):
        # Enable retries and run test_list_milvus_database_collections_all_params.
        _service.enable_retries()
        self.test_list_milvus_database_collections_all_params()

        # Disable retries and run test_list_milvus_database_collections_all_params.
        _service.disable_retries()
        self.test_list_milvus_database_collections_all_params()

    @responses.activate
    def test_list_milvus_database_collections_required_params(self):
        """
        test_list_milvus_database_collections_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/databases/testString/collections')
        mock_response = '{"collections": [{"collection_id": 1, "collection_name": "col1", "physical_channels": ["physical_channels"], "virtual_channels": ["virtual_channels"]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'
        database_id = 'testString'

        # Invoke method
        response = _service.list_milvus_database_collections(
            service_id,
            database_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_milvus_database_collections_required_params_with_retries(self):
        # Enable retries and run test_list_milvus_database_collections_required_params.
        _service.enable_retries()
        self.test_list_milvus_database_collections_required_params()

        # Disable retries and run test_list_milvus_database_collections_required_params.
        _service.disable_retries()
        self.test_list_milvus_database_collections_required_params()

    @responses.activate
    def test_list_milvus_database_collections_value_error(self):
        """
        test_list_milvus_database_collections_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/databases/testString/collections')
        mock_response = '{"collections": [{"collection_id": 1, "collection_name": "col1", "physical_channels": ["physical_channels"], "virtual_channels": ["virtual_channels"]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        service_id = 'testString'
        database_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
            "database_id": database_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_milvus_database_collections(**req_copy)

    def test_list_milvus_database_collections_value_error_with_retries(self):
        # Enable retries and run test_list_milvus_database_collections_value_error.
        _service.enable_retries()
        self.test_list_milvus_database_collections_value_error()

        # Disable retries and run test_list_milvus_database_collections_value_error.
        _service.disable_retries()
        self.test_list_milvus_database_collections_value_error()


class TestCreateMilvusServicePause:
    """
    Test Class for create_milvus_service_pause
    """

    @responses.activate
    def test_create_milvus_service_pause_all_params(self):
        """
        create_milvus_service_pause()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_milvus_service_pause(
            service_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_milvus_service_pause_all_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_pause_all_params.
        _service.enable_retries()
        self.test_create_milvus_service_pause_all_params()

        # Disable retries and run test_create_milvus_service_pause_all_params.
        _service.disable_retries()
        self.test_create_milvus_service_pause_all_params()

    @responses.activate
    def test_create_milvus_service_pause_required_params(self):
        """
        test_create_milvus_service_pause_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'

        # Invoke method
        response = _service.create_milvus_service_pause(
            service_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_milvus_service_pause_required_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_pause_required_params.
        _service.enable_retries()
        self.test_create_milvus_service_pause_required_params()

        # Disable retries and run test_create_milvus_service_pause_required_params.
        _service.disable_retries()
        self.test_create_milvus_service_pause_required_params()

    @responses.activate
    def test_create_milvus_service_pause_value_error(self):
        """
        test_create_milvus_service_pause_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/pause')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_milvus_service_pause(**req_copy)

    def test_create_milvus_service_pause_value_error_with_retries(self):
        # Enable retries and run test_create_milvus_service_pause_value_error.
        _service.enable_retries()
        self.test_create_milvus_service_pause_value_error()

        # Disable retries and run test_create_milvus_service_pause_value_error.
        _service.disable_retries()
        self.test_create_milvus_service_pause_value_error()


class TestCreateMilvusServiceResume:
    """
    Test Class for create_milvus_service_resume
    """

    @responses.activate
    def test_create_milvus_service_resume_all_params(self):
        """
        create_milvus_service_resume()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_milvus_service_resume(
            service_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_milvus_service_resume_all_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_resume_all_params.
        _service.enable_retries()
        self.test_create_milvus_service_resume_all_params()

        # Disable retries and run test_create_milvus_service_resume_all_params.
        _service.disable_retries()
        self.test_create_milvus_service_resume_all_params()

    @responses.activate
    def test_create_milvus_service_resume_required_params(self):
        """
        test_create_milvus_service_resume_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'

        # Invoke method
        response = _service.create_milvus_service_resume(
            service_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201

    def test_create_milvus_service_resume_required_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_resume_required_params.
        _service.enable_retries()
        self.test_create_milvus_service_resume_required_params()

        # Disable retries and run test_create_milvus_service_resume_required_params.
        _service.disable_retries()
        self.test_create_milvus_service_resume_required_params()

    @responses.activate
    def test_create_milvus_service_resume_value_error(self):
        """
        test_create_milvus_service_resume_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/resume')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_milvus_service_resume(**req_copy)

    def test_create_milvus_service_resume_value_error_with_retries(self):
        # Enable retries and run test_create_milvus_service_resume_value_error.
        _service.enable_retries()
        self.test_create_milvus_service_resume_value_error()

        # Disable retries and run test_create_milvus_service_resume_value_error.
        _service.disable_retries()
        self.test_create_milvus_service_resume_value_error()


class TestCreateMilvusServiceScale:
    """
    Test Class for create_milvus_service_scale
    """

    @responses.activate
    def test_create_milvus_service_scale_all_params(self):
        """
        create_milvus_service_scale()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'
        tshirt_size = 'testString'
        index_type = 'FLAT'
        iw_cpu = 1
        iw_memory = 1
        iw_replicas = 1
        milvus_name = 'milvus123'
        qw_cpu = 1
        qw_memory = 1
        qw_replicas = 1
        vector_dimension = 384
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.create_milvus_service_scale(
            service_id,
            tshirt_size,
            index_type=index_type,
            iw_cpu=iw_cpu,
            iw_memory=iw_memory,
            iw_replicas=iw_replicas,
            milvus_name=milvus_name,
            qw_cpu=qw_cpu,
            qw_memory=qw_memory,
            qw_replicas=qw_replicas,
            vector_dimension=vector_dimension,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['tshirt_size'] == 'testString'
        assert req_body['index_type'] == 'FLAT'
        assert req_body['iw_cpu'] == 1
        assert req_body['iw_memory'] == 1
        assert req_body['iw_replicas'] == 1
        assert req_body['milvus_name'] == 'milvus123'
        assert req_body['qw_cpu'] == 1
        assert req_body['qw_memory'] == 1
        assert req_body['qw_replicas'] == 1
        assert req_body['vector_dimension'] == 384

    def test_create_milvus_service_scale_all_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_scale_all_params.
        _service.enable_retries()
        self.test_create_milvus_service_scale_all_params()

        # Disable retries and run test_create_milvus_service_scale_all_params.
        _service.disable_retries()
        self.test_create_milvus_service_scale_all_params()

    @responses.activate
    def test_create_milvus_service_scale_required_params(self):
        """
        test_create_milvus_service_scale_required_params()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'
        tshirt_size = 'testString'
        index_type = 'FLAT'
        iw_cpu = 1
        iw_memory = 1
        iw_replicas = 1
        milvus_name = 'milvus123'
        qw_cpu = 1
        qw_memory = 1
        qw_replicas = 1
        vector_dimension = 384

        # Invoke method
        response = _service.create_milvus_service_scale(
            service_id,
            tshirt_size,
            index_type=index_type,
            iw_cpu=iw_cpu,
            iw_memory=iw_memory,
            iw_replicas=iw_replicas,
            milvus_name=milvus_name,
            qw_cpu=qw_cpu,
            qw_memory=qw_memory,
            qw_replicas=qw_replicas,
            vector_dimension=vector_dimension,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['tshirt_size'] == 'testString'
        assert req_body['index_type'] == 'FLAT'
        assert req_body['iw_cpu'] == 1
        assert req_body['iw_memory'] == 1
        assert req_body['iw_replicas'] == 1
        assert req_body['milvus_name'] == 'milvus123'
        assert req_body['qw_cpu'] == 1
        assert req_body['qw_memory'] == 1
        assert req_body['qw_replicas'] == 1
        assert req_body['vector_dimension'] == 384

    def test_create_milvus_service_scale_required_params_with_retries(self):
        # Enable retries and run test_create_milvus_service_scale_required_params.
        _service.enable_retries()
        self.test_create_milvus_service_scale_required_params()

        # Disable retries and run test_create_milvus_service_scale_required_params.
        _service.disable_retries()
        self.test_create_milvus_service_scale_required_params()

    @responses.activate
    def test_create_milvus_service_scale_value_error(self):
        """
        test_create_milvus_service_scale_value_error()
        """
        # Set up mock
        url = preprocess_url('/milvus_services/testString/scale')
        mock_response = '{"message": "message", "message_code": "message_code"}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        service_id = 'testString'
        tshirt_size = 'testString'
        index_type = 'FLAT'
        iw_cpu = 1
        iw_memory = 1
        iw_replicas = 1
        milvus_name = 'milvus123'
        qw_cpu = 1
        qw_memory = 1
        qw_replicas = 1
        vector_dimension = 384

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "service_id": service_id,
            "tshirt_size": tshirt_size,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_milvus_service_scale(**req_copy)

    def test_create_milvus_service_scale_value_error_with_retries(self):
        # Enable retries and run test_create_milvus_service_scale_value_error.
        _service.enable_retries()
        self.test_create_milvus_service_scale_value_error()

        # Disable retries and run test_create_milvus_service_scale_value_error.
        _service.disable_retries()
        self.test_create_milvus_service_scale_value_error()


# endregion
##############################################################################
# End of Service: Services
##############################################################################

##############################################################################
# Start of Service: Ingestion
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestListIngestionJobs:
    """
    Test Class for list_ingestion_jobs
    """

    @responses.activate
    def test_list_ingestion_jobs_all_params(self):
        """
        list_ingestion_jobs()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs')
        mock_response = '{"ingestion_jobs": [{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}], "first": {"href": "http://api.example.com/collection?start=eyJvZmZzZXQiOjAsImRvbmUiOnRydWV9"}, "next": {"href": "http://api.example.com/collection?start=eyJvZmZzZXQiOjAsImRvbmUiOnRydWV9"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'
        start = '1'
        jobs_per_page = 1

        # Invoke method
        response = _service.list_ingestion_jobs(
            auth_instance_id,
            start=start,
            jobs_per_page=jobs_per_page,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'start={}'.format(start) in query_string
        assert 'jobs_per_page={}'.format(jobs_per_page) in query_string

    def test_list_ingestion_jobs_all_params_with_retries(self):
        # Enable retries and run test_list_ingestion_jobs_all_params.
        _service.enable_retries()
        self.test_list_ingestion_jobs_all_params()

        # Disable retries and run test_list_ingestion_jobs_all_params.
        _service.disable_retries()
        self.test_list_ingestion_jobs_all_params()

    @responses.activate
    def test_list_ingestion_jobs_required_params(self):
        """
        test_list_ingestion_jobs_required_params()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs')
        mock_response = '{"ingestion_jobs": [{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}], "first": {"href": "http://api.example.com/collection?start=eyJvZmZzZXQiOjAsImRvbmUiOnRydWV9"}, "next": {"href": "http://api.example.com/collection?start=eyJvZmZzZXQiOjAsImRvbmUiOnRydWV9"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_ingestion_jobs(
            auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_ingestion_jobs_required_params_with_retries(self):
        # Enable retries and run test_list_ingestion_jobs_required_params.
        _service.enable_retries()
        self.test_list_ingestion_jobs_required_params()

        # Disable retries and run test_list_ingestion_jobs_required_params.
        _service.disable_retries()
        self.test_list_ingestion_jobs_required_params()

    @responses.activate
    def test_list_ingestion_jobs_value_error(self):
        """
        test_list_ingestion_jobs_value_error()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs')
        mock_response = '{"ingestion_jobs": [{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}], "first": {"href": "http://api.example.com/collection?start=eyJvZmZzZXQiOjAsImRvbmUiOnRydWV9"}, "next": {"href": "http://api.example.com/collection?start=eyJvZmZzZXQiOjAsImRvbmUiOnRydWV9"}}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "auth_instance_id": auth_instance_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.list_ingestion_jobs(**req_copy)

    def test_list_ingestion_jobs_value_error_with_retries(self):
        # Enable retries and run test_list_ingestion_jobs_value_error.
        _service.enable_retries()
        self.test_list_ingestion_jobs_value_error()

        # Disable retries and run test_list_ingestion_jobs_value_error.
        _service.disable_retries()
        self.test_list_ingestion_jobs_value_error()

    @responses.activate
    def test_list_ingestion_jobs_with_pager_get_next(self):
        """
        test_list_ingestion_jobs_with_pager_get_next()
        """
        # Set up a two-page mock response
        url = preprocess_url('/ingestion_jobs')
        mock_response1 = '{"next":{"href":"https://myhost.com/somePath?start=1"},"total_count":2,"limit":1,"ingestion_jobs":[{"create_if_not_exist":false,"csv_property":{"encoding":"utf-8","escape_character":"|","field_delimiter":",","header":true,"line_delimiter":"\n"},"details":"Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory","end_timestamp":"1685088775","engine_id":"spark123","engine_name":"sparkdemo","execute_config":{"driver_cores":1,"driver_memory":"2G","executor_cores":1,"executor_memory":"2G","num_executors":1},"instance_id":"1684432229673971","job_id":"ingestion-1699459946935","partition_by":"col1, col2","schema":"{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}","source_data_files":"s3://demobucket/data/yellow_tripdata_2022-01.parquet","source_file_type":"csv","start_timestamp":"1685084455","status":"running","target_table":"demodb.test.targettable","username":"ibmlhadmin","validate_csv_header":false}]}'
        mock_response2 = '{"total_count":2,"limit":1,"ingestion_jobs":[{"create_if_not_exist":false,"csv_property":{"encoding":"utf-8","escape_character":"|","field_delimiter":",","header":true,"line_delimiter":"\n"},"details":"Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory","end_timestamp":"1685088775","engine_id":"spark123","engine_name":"sparkdemo","execute_config":{"driver_cores":1,"driver_memory":"2G","executor_cores":1,"executor_memory":"2G","num_executors":1},"instance_id":"1684432229673971","job_id":"ingestion-1699459946935","partition_by":"col1, col2","schema":"{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}","source_data_files":"s3://demobucket/data/yellow_tripdata_2022-01.parquet","source_file_type":"csv","start_timestamp":"1685084455","status":"running","target_table":"demodb.test.targettable","username":"ibmlhadmin","validate_csv_header":false}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response1,
            content_type='application/json',
            status=200,
        )
        responses.add(
            responses.GET,
            url,
            body=mock_response2,
            content_type='application/json',
            status=200,
        )

        # Exercise the pager class for this operation
        all_results = []
        pager = IngestionJobsPager(
            client=_service,
            auth_instance_id='testString',
            jobs_per_page=1,
        )
        while pager.has_next():
            next_page = pager.get_next()
            assert next_page is not None
            all_results.extend(next_page)
        assert len(all_results) == 2

    @responses.activate
    def test_list_ingestion_jobs_with_pager_get_all(self):
        """
        test_list_ingestion_jobs_with_pager_get_all()
        """
        # Set up a two-page mock response
        url = preprocess_url('/ingestion_jobs')
        mock_response1 = '{"next":{"href":"https://myhost.com/somePath?start=1"},"total_count":2,"limit":1,"ingestion_jobs":[{"create_if_not_exist":false,"csv_property":{"encoding":"utf-8","escape_character":"|","field_delimiter":",","header":true,"line_delimiter":"\n"},"details":"Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory","end_timestamp":"1685088775","engine_id":"spark123","engine_name":"sparkdemo","execute_config":{"driver_cores":1,"driver_memory":"2G","executor_cores":1,"executor_memory":"2G","num_executors":1},"instance_id":"1684432229673971","job_id":"ingestion-1699459946935","partition_by":"col1, col2","schema":"{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}","source_data_files":"s3://demobucket/data/yellow_tripdata_2022-01.parquet","source_file_type":"csv","start_timestamp":"1685084455","status":"running","target_table":"demodb.test.targettable","username":"ibmlhadmin","validate_csv_header":false}]}'
        mock_response2 = '{"total_count":2,"limit":1,"ingestion_jobs":[{"create_if_not_exist":false,"csv_property":{"encoding":"utf-8","escape_character":"|","field_delimiter":",","header":true,"line_delimiter":"\n"},"details":"Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory","end_timestamp":"1685088775","engine_id":"spark123","engine_name":"sparkdemo","execute_config":{"driver_cores":1,"driver_memory":"2G","executor_cores":1,"executor_memory":"2G","num_executors":1},"instance_id":"1684432229673971","job_id":"ingestion-1699459946935","partition_by":"col1, col2","schema":"{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}","source_data_files":"s3://demobucket/data/yellow_tripdata_2022-01.parquet","source_file_type":"csv","start_timestamp":"1685084455","status":"running","target_table":"demodb.test.targettable","username":"ibmlhadmin","validate_csv_header":false}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response1,
            content_type='application/json',
            status=200,
        )
        responses.add(
            responses.GET,
            url,
            body=mock_response2,
            content_type='application/json',
            status=200,
        )

        # Exercise the pager class for this operation
        pager = IngestionJobsPager(
            client=_service,
            auth_instance_id='testString',
            jobs_per_page=1,
        )
        all_results = pager.get_all()
        assert all_results is not None
        assert len(all_results) == 2


class TestCreateIngestionJobs:
    """
    Test Class for create_ingestion_jobs
    """

    @responses.activate
    def test_create_ingestion_jobs_all_params(self):
        """
        create_ingestion_jobs()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a IngestionJobPrototypeCsvProperty model
        ingestion_job_prototype_csv_property_model = {}
        ingestion_job_prototype_csv_property_model['encoding'] = 'utf-8'
        ingestion_job_prototype_csv_property_model['escape_character'] = '\\\\'
        ingestion_job_prototype_csv_property_model['field_delimiter'] = ','
        ingestion_job_prototype_csv_property_model['header'] = True
        ingestion_job_prototype_csv_property_model['line_delimiter'] = '\\n'

        # Construct a dict representation of a IngestionJobPrototypeExecuteConfig model
        ingestion_job_prototype_execute_config_model = {}
        ingestion_job_prototype_execute_config_model['driver_cores'] = 1
        ingestion_job_prototype_execute_config_model['driver_memory'] = '2G'
        ingestion_job_prototype_execute_config_model['executor_cores'] = 1
        ingestion_job_prototype_execute_config_model['executor_memory'] = '2G'
        ingestion_job_prototype_execute_config_model['num_executors'] = 1

        # Set up parameter values
        auth_instance_id = 'testString'
        job_id = 'ingestion-1699459946935'
        source_data_files = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        target_table = 'demodb.test.targettable'
        username = 'user1'
        create_if_not_exist = False
        csv_property = ingestion_job_prototype_csv_property_model
        engine_id = 'spark123'
        execute_config = ingestion_job_prototype_execute_config_model
        partition_by = 'col1, col2'
        schema = '{"type":"struct","schema-id":0,"fields":[{"id":1,"name":"ID","required":true,"type":"int"},{"id":2,"name":"Name","required":true,"type":"string"}]}'
        source_file_type = 'csv'
        validate_csv_header = False

        # Invoke method
        response = _service.create_ingestion_jobs(
            auth_instance_id,
            job_id,
            source_data_files,
            target_table,
            username,
            create_if_not_exist=create_if_not_exist,
            csv_property=csv_property,
            engine_id=engine_id,
            execute_config=execute_config,
            partition_by=partition_by,
            schema=schema,
            source_file_type=source_file_type,
            validate_csv_header=validate_csv_header,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['job_id'] == 'ingestion-1699459946935'
        assert req_body['source_data_files'] == 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        assert req_body['target_table'] == 'demodb.test.targettable'
        assert req_body['username'] == 'user1'
        assert req_body['create_if_not_exist'] == False
        assert req_body['csv_property'] == ingestion_job_prototype_csv_property_model
        assert req_body['engine_id'] == 'spark123'
        assert req_body['execute_config'] == ingestion_job_prototype_execute_config_model
        assert req_body['partition_by'] == 'col1, col2'
        assert req_body['schema'] == '{"type":"struct","schema-id":0,"fields":[{"id":1,"name":"ID","required":true,"type":"int"},{"id":2,"name":"Name","required":true,"type":"string"}]}'
        assert req_body['source_file_type'] == 'csv'
        assert req_body['validate_csv_header'] == False

    def test_create_ingestion_jobs_all_params_with_retries(self):
        # Enable retries and run test_create_ingestion_jobs_all_params.
        _service.enable_retries()
        self.test_create_ingestion_jobs_all_params()

        # Disable retries and run test_create_ingestion_jobs_all_params.
        _service.disable_retries()
        self.test_create_ingestion_jobs_all_params()

    @responses.activate
    def test_create_ingestion_jobs_value_error(self):
        """
        test_create_ingestion_jobs_value_error()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Construct a dict representation of a IngestionJobPrototypeCsvProperty model
        ingestion_job_prototype_csv_property_model = {}
        ingestion_job_prototype_csv_property_model['encoding'] = 'utf-8'
        ingestion_job_prototype_csv_property_model['escape_character'] = '\\\\'
        ingestion_job_prototype_csv_property_model['field_delimiter'] = ','
        ingestion_job_prototype_csv_property_model['header'] = True
        ingestion_job_prototype_csv_property_model['line_delimiter'] = '\\n'

        # Construct a dict representation of a IngestionJobPrototypeExecuteConfig model
        ingestion_job_prototype_execute_config_model = {}
        ingestion_job_prototype_execute_config_model['driver_cores'] = 1
        ingestion_job_prototype_execute_config_model['driver_memory'] = '2G'
        ingestion_job_prototype_execute_config_model['executor_cores'] = 1
        ingestion_job_prototype_execute_config_model['executor_memory'] = '2G'
        ingestion_job_prototype_execute_config_model['num_executors'] = 1

        # Set up parameter values
        auth_instance_id = 'testString'
        job_id = 'ingestion-1699459946935'
        source_data_files = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        target_table = 'demodb.test.targettable'
        username = 'user1'
        create_if_not_exist = False
        csv_property = ingestion_job_prototype_csv_property_model
        engine_id = 'spark123'
        execute_config = ingestion_job_prototype_execute_config_model
        partition_by = 'col1, col2'
        schema = '{"type":"struct","schema-id":0,"fields":[{"id":1,"name":"ID","required":true,"type":"int"},{"id":2,"name":"Name","required":true,"type":"string"}]}'
        source_file_type = 'csv'
        validate_csv_header = False

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "auth_instance_id": auth_instance_id,
            "job_id": job_id,
            "source_data_files": source_data_files,
            "target_table": target_table,
            "username": username,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_ingestion_jobs(**req_copy)

    def test_create_ingestion_jobs_value_error_with_retries(self):
        # Enable retries and run test_create_ingestion_jobs_value_error.
        _service.enable_retries()
        self.test_create_ingestion_jobs_value_error()

        # Disable retries and run test_create_ingestion_jobs_value_error.
        _service.disable_retries()
        self.test_create_ingestion_jobs_value_error()


class TestCreateIngestionJobsLocalFiles:
    """
    Test Class for create_ingestion_jobs_local_files
    """

    @responses.activate
    def test_create_ingestion_jobs_local_files_all_params(self):
        """
        create_ingestion_jobs_local_files()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs_local_files')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Set up parameter values
        auth_instance_id = 'testString'
        source_data_file = io.BytesIO(b'This is a mock file.').getvalue()
        target_table = 'testString'
        job_id = 'testString'
        username = 'testString'
        source_data_file_content_type = 'testString'
        source_file_type = 'csv'
        csv_property = 'testString'
        create_if_not_exist = False
        validate_csv_header = False
        execute_config = 'testString'
        engine_id = 'testString'

        # Invoke method
        response = _service.create_ingestion_jobs_local_files(
            auth_instance_id,
            source_data_file,
            target_table,
            job_id,
            username,
            source_data_file_content_type=source_data_file_content_type,
            source_file_type=source_file_type,
            csv_property=csv_property,
            create_if_not_exist=create_if_not_exist,
            validate_csv_header=validate_csv_header,
            execute_config=execute_config,
            engine_id=engine_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202

    def test_create_ingestion_jobs_local_files_all_params_with_retries(self):
        # Enable retries and run test_create_ingestion_jobs_local_files_all_params.
        _service.enable_retries()
        self.test_create_ingestion_jobs_local_files_all_params()

        # Disable retries and run test_create_ingestion_jobs_local_files_all_params.
        _service.disable_retries()
        self.test_create_ingestion_jobs_local_files_all_params()

    @responses.activate
    def test_create_ingestion_jobs_local_files_required_params(self):
        """
        test_create_ingestion_jobs_local_files_required_params()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs_local_files')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Set up parameter values
        auth_instance_id = 'testString'
        source_data_file = io.BytesIO(b'This is a mock file.').getvalue()
        target_table = 'testString'
        job_id = 'testString'
        username = 'testString'

        # Invoke method
        response = _service.create_ingestion_jobs_local_files(
            auth_instance_id,
            source_data_file,
            target_table,
            job_id,
            username,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 202

    def test_create_ingestion_jobs_local_files_required_params_with_retries(self):
        # Enable retries and run test_create_ingestion_jobs_local_files_required_params.
        _service.enable_retries()
        self.test_create_ingestion_jobs_local_files_required_params()

        # Disable retries and run test_create_ingestion_jobs_local_files_required_params.
        _service.disable_retries()
        self.test_create_ingestion_jobs_local_files_required_params()

    @responses.activate
    def test_create_ingestion_jobs_local_files_value_error(self):
        """
        test_create_ingestion_jobs_local_files_value_error()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs_local_files')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=202,
        )

        # Set up parameter values
        auth_instance_id = 'testString'
        source_data_file = io.BytesIO(b'This is a mock file.').getvalue()
        target_table = 'testString'
        job_id = 'testString'
        username = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "auth_instance_id": auth_instance_id,
            "source_data_file": source_data_file,
            "target_table": target_table,
            "job_id": job_id,
            "username": username,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_ingestion_jobs_local_files(**req_copy)

    def test_create_ingestion_jobs_local_files_value_error_with_retries(self):
        # Enable retries and run test_create_ingestion_jobs_local_files_value_error.
        _service.enable_retries()
        self.test_create_ingestion_jobs_local_files_value_error()

        # Disable retries and run test_create_ingestion_jobs_local_files_value_error.
        _service.disable_retries()
        self.test_create_ingestion_jobs_local_files_value_error()


class TestGetIngestionJob:
    """
    Test Class for get_ingestion_job
    """

    @responses.activate
    def test_get_ingestion_job_all_params(self):
        """
        get_ingestion_job()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs/testString')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        job_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_ingestion_job(
            job_id,
            auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_ingestion_job_all_params_with_retries(self):
        # Enable retries and run test_get_ingestion_job_all_params.
        _service.enable_retries()
        self.test_get_ingestion_job_all_params()

        # Disable retries and run test_get_ingestion_job_all_params.
        _service.disable_retries()
        self.test_get_ingestion_job_all_params()

    @responses.activate
    def test_get_ingestion_job_value_error(self):
        """
        test_get_ingestion_job_value_error()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs/testString')
        mock_response = '{"create_if_not_exist": false, "csv_property": {"encoding": "utf-8", "escape_character": "|", "field_delimiter": ",", "header": true, "line_delimiter": "\n"}, "details": "Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory", "end_timestamp": "1685088775", "engine_id": "spark123", "engine_name": "sparkdemo", "execute_config": {"driver_cores": 1, "driver_memory": "2G", "executor_cores": 1, "executor_memory": "2G", "num_executors": 1}, "instance_id": "1684432229673971", "job_id": "ingestion-1699459946935", "partition_by": "col1, col2", "schema": "{\\"type\\":\\"struct\\",\\"schema-id\\":0,\\"fields\\":[{\\"id\\":1,\\"name\\":\\"ID\\",\\"required\\":true,\\"type\\":\\"int\\"},{\\"id\\":2,\\"name\\":\\"Name\\",\\"required\\":true,\\"type\\":\\"string\\"}]}", "source_data_files": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "source_file_type": "csv", "start_timestamp": "1685084455", "status": "running", "target_table": "demodb.test.targettable", "username": "ibmlhadmin", "validate_csv_header": false}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        job_id = 'testString'
        auth_instance_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "job_id": job_id,
            "auth_instance_id": auth_instance_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_ingestion_job(**req_copy)

    def test_get_ingestion_job_value_error_with_retries(self):
        # Enable retries and run test_get_ingestion_job_value_error.
        _service.enable_retries()
        self.test_get_ingestion_job_value_error()

        # Disable retries and run test_get_ingestion_job_value_error.
        _service.disable_retries()
        self.test_get_ingestion_job_value_error()


class TestDeleteIngestionJobs:
    """
    Test Class for delete_ingestion_jobs
    """

    @responses.activate
    def test_delete_ingestion_jobs_all_params(self):
        """
        delete_ingestion_jobs()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        job_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.delete_ingestion_jobs(
            job_id,
            auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 204

    def test_delete_ingestion_jobs_all_params_with_retries(self):
        # Enable retries and run test_delete_ingestion_jobs_all_params.
        _service.enable_retries()
        self.test_delete_ingestion_jobs_all_params()

        # Disable retries and run test_delete_ingestion_jobs_all_params.
        _service.disable_retries()
        self.test_delete_ingestion_jobs_all_params()

    @responses.activate
    def test_delete_ingestion_jobs_value_error(self):
        """
        test_delete_ingestion_jobs_value_error()
        """
        # Set up mock
        url = preprocess_url('/ingestion_jobs/testString')
        responses.add(
            responses.DELETE,
            url,
            status=204,
        )

        # Set up parameter values
        job_id = 'testString'
        auth_instance_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "job_id": job_id,
            "auth_instance_id": auth_instance_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.delete_ingestion_jobs(**req_copy)

    def test_delete_ingestion_jobs_value_error_with_retries(self):
        # Enable retries and run test_delete_ingestion_jobs_value_error.
        _service.enable_retries()
        self.test_delete_ingestion_jobs_value_error()

        # Disable retries and run test_delete_ingestion_jobs_value_error.
        _service.disable_retries()
        self.test_delete_ingestion_jobs_value_error()


class TestCreatePreviewIngestionFile:
    """
    Test Class for create_preview_ingestion_file
    """

    @responses.activate
    def test_create_preview_ingestion_file_all_params(self):
        """
        create_preview_ingestion_file()
        """
        # Set up mock
        url = preprocess_url('/preview_ingestion_file')
        mock_response = '{"column_names": ["col1"], "column_types": ["int"], "file_name": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "rows": {"row_eight": ["Jane Doe"], "row_five": ["Jane Doe"], "row_four": ["Jane Doe"], "row_nine": ["Jane Doe"], "row_one": ["Jane Doe"], "row_seven": ["Jane Doe"], "row_six": ["Jane Doe"], "row_ten": ["Jane Doe"], "row_three": ["Jane Doe"], "row_two": ["Jane Doe"]}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a PreviewIngestionFilePrototypeCsvProperty model
        preview_ingestion_file_prototype_csv_property_model = {}
        preview_ingestion_file_prototype_csv_property_model['encoding'] = 'utf-8'
        preview_ingestion_file_prototype_csv_property_model['escape_character'] = '\\\\'
        preview_ingestion_file_prototype_csv_property_model['field_delimiter'] = ','
        preview_ingestion_file_prototype_csv_property_model['header'] = True
        preview_ingestion_file_prototype_csv_property_model['line_delimiter'] = '\\n'

        # Set up parameter values
        auth_instance_id = 'testString'
        source_data_files = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        csv_property = preview_ingestion_file_prototype_csv_property_model
        source_file_type = 'csv'

        # Invoke method
        response = _service.create_preview_ingestion_file(
            auth_instance_id,
            source_data_files,
            csv_property=csv_property,
            source_file_type=source_file_type,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['source_data_files'] == 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        assert req_body['csv_property'] == preview_ingestion_file_prototype_csv_property_model
        assert req_body['source_file_type'] == 'csv'

    def test_create_preview_ingestion_file_all_params_with_retries(self):
        # Enable retries and run test_create_preview_ingestion_file_all_params.
        _service.enable_retries()
        self.test_create_preview_ingestion_file_all_params()

        # Disable retries and run test_create_preview_ingestion_file_all_params.
        _service.disable_retries()
        self.test_create_preview_ingestion_file_all_params()

    @responses.activate
    def test_create_preview_ingestion_file_value_error(self):
        """
        test_create_preview_ingestion_file_value_error()
        """
        # Set up mock
        url = preprocess_url('/preview_ingestion_file')
        mock_response = '{"column_names": ["col1"], "column_types": ["int"], "file_name": "s3://demobucket/data/yellow_tripdata_2022-01.parquet", "rows": {"row_eight": ["Jane Doe"], "row_five": ["Jane Doe"], "row_four": ["Jane Doe"], "row_nine": ["Jane Doe"], "row_one": ["Jane Doe"], "row_seven": ["Jane Doe"], "row_six": ["Jane Doe"], "row_ten": ["Jane Doe"], "row_three": ["Jane Doe"], "row_two": ["Jane Doe"]}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Construct a dict representation of a PreviewIngestionFilePrototypeCsvProperty model
        preview_ingestion_file_prototype_csv_property_model = {}
        preview_ingestion_file_prototype_csv_property_model['encoding'] = 'utf-8'
        preview_ingestion_file_prototype_csv_property_model['escape_character'] = '\\\\'
        preview_ingestion_file_prototype_csv_property_model['field_delimiter'] = ','
        preview_ingestion_file_prototype_csv_property_model['header'] = True
        preview_ingestion_file_prototype_csv_property_model['line_delimiter'] = '\\n'

        # Set up parameter values
        auth_instance_id = 'testString'
        source_data_files = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        csv_property = preview_ingestion_file_prototype_csv_property_model
        source_file_type = 'csv'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "auth_instance_id": auth_instance_id,
            "source_data_files": source_data_files,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.create_preview_ingestion_file(**req_copy)

    def test_create_preview_ingestion_file_value_error_with_retries(self):
        # Enable retries and run test_create_preview_ingestion_file_value_error.
        _service.enable_retries()
        self.test_create_preview_ingestion_file_value_error()

        # Disable retries and run test_create_preview_ingestion_file_value_error.
        _service.disable_retries()
        self.test_create_preview_ingestion_file_value_error()


# endregion
##############################################################################
# End of Service: Ingestion
##############################################################################

##############################################################################
# Start of Service: Endpoints
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestGetEndpoints:
    """
    Test Class for get_endpoints
    """

    @responses.activate
    def test_get_endpoints_all_params(self):
        """
        get_endpoints()
        """
        # Set up mock
        url = preprocess_url('/endpoints')
        mock_response = '{"endpoints": [{"external_host": "https://cpg-svc.your-hostname.apps.your-domain.com", "service_type": "cpg"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_endpoints(
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_endpoints_all_params_with_retries(self):
        # Enable retries and run test_get_endpoints_all_params.
        _service.enable_retries()
        self.test_get_endpoints_all_params()

        # Disable retries and run test_get_endpoints_all_params.
        _service.disable_retries()
        self.test_get_endpoints_all_params()

    @responses.activate
    def test_get_endpoints_required_params(self):
        """
        test_get_endpoints_required_params()
        """
        # Set up mock
        url = preprocess_url('/endpoints')
        mock_response = '{"endpoints": [{"external_host": "https://cpg-svc.your-hostname.apps.your-domain.com", "service_type": "cpg"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_endpoints()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_endpoints_required_params_with_retries(self):
        # Enable retries and run test_get_endpoints_required_params.
        _service.enable_retries()
        self.test_get_endpoints_required_params()

        # Disable retries and run test_get_endpoints_required_params.
        _service.disable_retries()
        self.test_get_endpoints_required_params()


# endregion
##############################################################################
# End of Service: Endpoints
##############################################################################

##############################################################################
# Start of Service: Metadata
##############################################################################
# region


class TestNewInstance:
    """
    Test Class for new_instance
    """

    def test_new_instance(self):
        """
        new_instance()
        """
        os.environ['TEST_SERVICE_AUTH_TYPE'] = 'noAuth'

        service = WatsonxDataV2.new_instance(
            service_name='TEST_SERVICE',
        )

        assert service is not None
        assert isinstance(service, WatsonxDataV2)

    def test_new_instance_without_authenticator(self):
        """
        new_instance_without_authenticator()
        """
        with pytest.raises(ValueError, match='authenticator must be provided'):
            service = WatsonxDataV2.new_instance(
                service_name='TEST_SERVICE_NOT_FOUND',
            )


class TestRegisterTable:
    """
    Test Class for register_table
    """

    @responses.activate
    def test_register_table_all_params(self):
        """
        register_table()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/register')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        metadata_location = 's3a://bucketname/path/to/table/metadata_location/_delta_log'
        table_name = 'table1'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.register_table(
            catalog_id,
            schema_id,
            metadata_location,
            table_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['metadata_location'] == 's3a://bucketname/path/to/table/metadata_location/_delta_log'
        assert req_body['table_name'] == 'table1'

    def test_register_table_all_params_with_retries(self):
        # Enable retries and run test_register_table_all_params.
        _service.enable_retries()
        self.test_register_table_all_params()

        # Disable retries and run test_register_table_all_params.
        _service.disable_retries()
        self.test_register_table_all_params()

    @responses.activate
    def test_register_table_required_params(self):
        """
        test_register_table_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/register')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        metadata_location = 's3a://bucketname/path/to/table/metadata_location/_delta_log'
        table_name = 'table1'

        # Invoke method
        response = _service.register_table(
            catalog_id,
            schema_id,
            metadata_location,
            table_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 201
        # Validate body params
        req_body = json.loads(str(responses.calls[0].request.body, 'utf-8'))
        assert req_body['metadata_location'] == 's3a://bucketname/path/to/table/metadata_location/_delta_log'
        assert req_body['table_name'] == 'table1'

    def test_register_table_required_params_with_retries(self):
        # Enable retries and run test_register_table_required_params.
        _service.enable_retries()
        self.test_register_table_required_params()

        # Disable retries and run test_register_table_required_params.
        _service.disable_retries()
        self.test_register_table_required_params()

    @responses.activate
    def test_register_table_value_error(self):
        """
        test_register_table_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/register')
        mock_response = '{"response": {"message": "message", "message_code": "message_code"}}'
        responses.add(
            responses.POST,
            url,
            body=mock_response,
            content_type='application/json',
            status=201,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        metadata_location = 's3a://bucketname/path/to/table/metadata_location/_delta_log'
        table_name = 'table1'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "metadata_location": metadata_location,
            "table_name": table_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.register_table(**req_copy)

    def test_register_table_value_error_with_retries(self):
        # Enable retries and run test_register_table_value_error.
        _service.enable_retries()
        self.test_register_table_value_error()

        # Disable retries and run test_register_table_value_error.
        _service.disable_retries()
        self.test_register_table_value_error()


class TestLoadTable:
    """
    Test Class for load_table
    """

    @responses.activate
    def test_load_table_all_params(self):
        """
        load_table()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/metadata')
        mock_response = '{"metadata_location": "s3a://bucketname/path/to/table/metadata_location/_delta_log", "table_path": "s3a://bucketname/path/to/table"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.load_table(
            catalog_id,
            schema_id,
            table_id,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_load_table_all_params_with_retries(self):
        # Enable retries and run test_load_table_all_params.
        _service.enable_retries()
        self.test_load_table_all_params()

        # Disable retries and run test_load_table_all_params.
        _service.disable_retries()
        self.test_load_table_all_params()

    @responses.activate
    def test_load_table_required_params(self):
        """
        test_load_table_required_params()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/metadata')
        mock_response = '{"metadata_location": "s3a://bucketname/path/to/table/metadata_location/_delta_log", "table_path": "s3a://bucketname/path/to/table"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'

        # Invoke method
        response = _service.load_table(
            catalog_id,
            schema_id,
            table_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_load_table_required_params_with_retries(self):
        # Enable retries and run test_load_table_required_params.
        _service.enable_retries()
        self.test_load_table_required_params()

        # Disable retries and run test_load_table_required_params.
        _service.disable_retries()
        self.test_load_table_required_params()

    @responses.activate
    def test_load_table_value_error(self):
        """
        test_load_table_value_error()
        """
        # Set up mock
        url = preprocess_url('/catalogs/testString/schemas/testString/tables/testString/metadata')
        mock_response = '{"metadata_location": "s3a://bucketname/path/to/table/metadata_location/_delta_log", "table_path": "s3a://bucketname/path/to/table"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_id = 'testString'
        schema_id = 'testString'
        table_id = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "catalog_id": catalog_id,
            "schema_id": schema_id,
            "table_id": table_id,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.load_table(**req_copy)

    def test_load_table_value_error_with_retries(self):
        # Enable retries and run test_load_table_value_error.
        _service.enable_retries()
        self.test_load_table_value_error()

        # Disable retries and run test_load_table_value_error.
        _service.disable_retries()
        self.test_load_table_value_error()


class TestGetAllColumns:
    """
    Test Class for get_all_columns
    """

    @responses.activate
    def test_get_all_columns_all_params(self):
        """
        get_all_columns()
        """
        # Set up mock
        url = preprocess_url('/columns')
        mock_response = '{"columns": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}], "message": "message", "message_code": "message_code"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        table_name = 'testString'
        catalog_name = 'testString'
        schema_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_all_columns(
            table_name=table_name,
            catalog_name=catalog_name,
            schema_name=schema_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'table_name={}'.format(table_name) in query_string
        assert 'catalog_name={}'.format(catalog_name) in query_string
        assert 'schema_name={}'.format(schema_name) in query_string

    def test_get_all_columns_all_params_with_retries(self):
        # Enable retries and run test_get_all_columns_all_params.
        _service.enable_retries()
        self.test_get_all_columns_all_params()

        # Disable retries and run test_get_all_columns_all_params.
        _service.disable_retries()
        self.test_get_all_columns_all_params()

    @responses.activate
    def test_get_all_columns_required_params(self):
        """
        test_get_all_columns_required_params()
        """
        # Set up mock
        url = preprocess_url('/columns')
        mock_response = '{"columns": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}], "message": "message", "message_code": "message_code"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.get_all_columns()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_all_columns_required_params_with_retries(self):
        # Enable retries and run test_get_all_columns_required_params.
        _service.enable_retries()
        self.test_get_all_columns_required_params()

        # Disable retries and run test_get_all_columns_required_params.
        _service.disable_retries()
        self.test_get_all_columns_required_params()


class TestListAllSchemas:
    """
    Test Class for list_all_schemas
    """

    @responses.activate
    def test_list_all_schemas_all_params(self):
        """
        list_all_schemas()
        """
        # Set up mock
        url = preprocess_url('/schemas')
        mock_response = '{"message": "message", "message_code": "message_code", "schemas": [{"bucket": "bucket", "catalog": "catalog", "owner": "owner", "schema_name": "schema_name"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_all_schemas(
            catalog_name=catalog_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_name={}'.format(catalog_name) in query_string

    def test_list_all_schemas_all_params_with_retries(self):
        # Enable retries and run test_list_all_schemas_all_params.
        _service.enable_retries()
        self.test_list_all_schemas_all_params()

        # Disable retries and run test_list_all_schemas_all_params.
        _service.disable_retries()
        self.test_list_all_schemas_all_params()

    @responses.activate
    def test_list_all_schemas_required_params(self):
        """
        test_list_all_schemas_required_params()
        """
        # Set up mock
        url = preprocess_url('/schemas')
        mock_response = '{"message": "message", "message_code": "message_code", "schemas": [{"bucket": "bucket", "catalog": "catalog", "owner": "owner", "schema_name": "schema_name"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_all_schemas()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_all_schemas_required_params_with_retries(self):
        # Enable retries and run test_list_all_schemas_required_params.
        _service.enable_retries()
        self.test_list_all_schemas_required_params()

        # Disable retries and run test_list_all_schemas_required_params.
        _service.disable_retries()
        self.test_list_all_schemas_required_params()


class TestGetSchemaDetails:
    """
    Test Class for get_schema_details
    """

    @responses.activate
    def test_get_schema_details_all_params(self):
        """
        get_schema_details()
        """
        # Set up mock
        url = preprocess_url('/schemas/testString')
        mock_response = '{"bucket": "bucket", "catalog": "catalog", "message": "message", "message_code": "message_code", "owner": "owner", "schema": {"bucket": "bucket", "catalog": "catalog", "owner": "owner", "schema_name": "schema_name"}, "schema_name": "schema_name"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        schema_name = 'testString'
        catalog_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_schema_details(
            schema_name,
            catalog_name=catalog_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_name={}'.format(catalog_name) in query_string

    def test_get_schema_details_all_params_with_retries(self):
        # Enable retries and run test_get_schema_details_all_params.
        _service.enable_retries()
        self.test_get_schema_details_all_params()

        # Disable retries and run test_get_schema_details_all_params.
        _service.disable_retries()
        self.test_get_schema_details_all_params()

    @responses.activate
    def test_get_schema_details_required_params(self):
        """
        test_get_schema_details_required_params()
        """
        # Set up mock
        url = preprocess_url('/schemas/testString')
        mock_response = '{"bucket": "bucket", "catalog": "catalog", "message": "message", "message_code": "message_code", "owner": "owner", "schema": {"bucket": "bucket", "catalog": "catalog", "owner": "owner", "schema_name": "schema_name"}, "schema_name": "schema_name"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        schema_name = 'testString'

        # Invoke method
        response = _service.get_schema_details(
            schema_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_schema_details_required_params_with_retries(self):
        # Enable retries and run test_get_schema_details_required_params.
        _service.enable_retries()
        self.test_get_schema_details_required_params()

        # Disable retries and run test_get_schema_details_required_params.
        _service.disable_retries()
        self.test_get_schema_details_required_params()

    @responses.activate
    def test_get_schema_details_value_error(self):
        """
        test_get_schema_details_value_error()
        """
        # Set up mock
        url = preprocess_url('/schemas/testString')
        mock_response = '{"bucket": "bucket", "catalog": "catalog", "message": "message", "message_code": "message_code", "owner": "owner", "schema": {"bucket": "bucket", "catalog": "catalog", "owner": "owner", "schema_name": "schema_name"}, "schema_name": "schema_name"}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        schema_name = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "schema_name": schema_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_schema_details(**req_copy)

    def test_get_schema_details_value_error_with_retries(self):
        # Enable retries and run test_get_schema_details_value_error.
        _service.enable_retries()
        self.test_get_schema_details_value_error()

        # Disable retries and run test_get_schema_details_value_error.
        _service.disable_retries()
        self.test_get_schema_details_value_error()


class TestListAllTables:
    """
    Test Class for list_all_tables
    """

    @responses.activate
    def test_list_all_tables_all_params(self):
        """
        list_all_tables()
        """
        # Set up mock
        url = preprocess_url('/tables')
        mock_response = '{"message": "message", "message_code": "message_code", "tables": [{"message": "message", "message_code": "message_code", "tables": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        catalog_name = 'testString'
        schema_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.list_all_tables(
            catalog_name=catalog_name,
            schema_name=schema_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_name={}'.format(catalog_name) in query_string
        assert 'schema_name={}'.format(schema_name) in query_string

    def test_list_all_tables_all_params_with_retries(self):
        # Enable retries and run test_list_all_tables_all_params.
        _service.enable_retries()
        self.test_list_all_tables_all_params()

        # Disable retries and run test_list_all_tables_all_params.
        _service.disable_retries()
        self.test_list_all_tables_all_params()

    @responses.activate
    def test_list_all_tables_required_params(self):
        """
        test_list_all_tables_required_params()
        """
        # Set up mock
        url = preprocess_url('/tables')
        mock_response = '{"message": "message", "message_code": "message_code", "tables": [{"message": "message", "message_code": "message_code", "tables": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}]}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Invoke method
        response = _service.list_all_tables()

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_list_all_tables_required_params_with_retries(self):
        # Enable retries and run test_list_all_tables_required_params.
        _service.enable_retries()
        self.test_list_all_tables_required_params()

        # Disable retries and run test_list_all_tables_required_params.
        _service.disable_retries()
        self.test_list_all_tables_required_params()


class TestGetTableDetails:
    """
    Test Class for get_table_details
    """

    @responses.activate
    def test_get_table_details_all_params(self):
        """
        get_table_details()
        """
        # Set up mock
        url = preprocess_url('/tables/testString')
        mock_response = '{"message": "message", "message_code": "message_code", "tables": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        table_name = 'testString'
        catalog_name = 'testString'
        schema_name = 'testString'
        auth_instance_id = 'testString'

        # Invoke method
        response = _service.get_table_details(
            table_name,
            catalog_name=catalog_name,
            schema_name=schema_name,
            auth_instance_id=auth_instance_id,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200
        # Validate query params
        query_string = responses.calls[0].request.url.split('?', 1)[1]
        query_string = urllib.parse.unquote_plus(query_string)
        assert 'catalog_name={}'.format(catalog_name) in query_string
        assert 'schema_name={}'.format(schema_name) in query_string

    def test_get_table_details_all_params_with_retries(self):
        # Enable retries and run test_get_table_details_all_params.
        _service.enable_retries()
        self.test_get_table_details_all_params()

        # Disable retries and run test_get_table_details_all_params.
        _service.disable_retries()
        self.test_get_table_details_all_params()

    @responses.activate
    def test_get_table_details_required_params(self):
        """
        test_get_table_details_required_params()
        """
        # Set up mock
        url = preprocess_url('/tables/testString')
        mock_response = '{"message": "message", "message_code": "message_code", "tables": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        table_name = 'testString'

        # Invoke method
        response = _service.get_table_details(
            table_name,
            headers={},
        )

        # Check for correct operation
        assert len(responses.calls) == 1
        assert response.status_code == 200

    def test_get_table_details_required_params_with_retries(self):
        # Enable retries and run test_get_table_details_required_params.
        _service.enable_retries()
        self.test_get_table_details_required_params()

        # Disable retries and run test_get_table_details_required_params.
        _service.disable_retries()
        self.test_get_table_details_required_params()

    @responses.activate
    def test_get_table_details_value_error(self):
        """
        test_get_table_details_value_error()
        """
        # Set up mock
        url = preprocess_url('/tables/testString')
        mock_response = '{"message": "message", "message_code": "message_code", "tables": [{"bucket": "bucket", "catalog": "catalog", "columns": [{"column": "column", "index": 5, "type": "type"}], "owner": "owner", "schema": "schema", "table": "table"}]}'
        responses.add(
            responses.GET,
            url,
            body=mock_response,
            content_type='application/json',
            status=200,
        )

        # Set up parameter values
        table_name = 'testString'

        # Pass in all but one required param and check for a ValueError
        req_param_dict = {
            "table_name": table_name,
        }
        for param in req_param_dict.keys():
            req_copy = {key: val if key is not param else None for (key, val) in req_param_dict.items()}
            with pytest.raises(ValueError):
                _service.get_table_details(**req_copy)

    def test_get_table_details_value_error_with_retries(self):
        # Enable retries and run test_get_table_details_value_error.
        _service.enable_retries()
        self.test_get_table_details_value_error()

        # Disable retries and run test_get_table_details_value_error.
        _service.disable_retries()
        self.test_get_table_details_value_error()


# endregion
##############################################################################
# End of Service: Metadata
##############################################################################


##############################################################################
# Start of Model Tests
##############################################################################
# region


class TestModel_Bandwidth:
    """
    Test Class for Bandwidth
    """

    def test_bandwidth_serialization(self):
        """
        Test serialization/deserialization for Bandwidth
        """

        # Construct a json representation of a Bandwidth model
        bandwidth_model_json = {}
        bandwidth_model_json['download_bandwidth_mbps'] = 'testString'
        bandwidth_model_json['upload_bandwidth_mbps'] = 'testString'

        # Construct a model instance of Bandwidth by calling from_dict on the json representation
        bandwidth_model = Bandwidth.from_dict(bandwidth_model_json)
        assert bandwidth_model != False

        # Construct a model instance of Bandwidth by calling from_dict on the json representation
        bandwidth_model_dict = Bandwidth.from_dict(bandwidth_model_json).__dict__
        bandwidth_model2 = Bandwidth(**bandwidth_model_dict)

        # Verify the model instances are equivalent
        assert bandwidth_model == bandwidth_model2

        # Convert model instance back to dict and verify no loss of data
        bandwidth_model_json2 = bandwidth_model.to_dict()
        assert bandwidth_model_json2 == bandwidth_model_json


class TestModel_BenchmarkData:
    """
    Test Class for BenchmarkData
    """

    def test_benchmark_data_serialization(self):
        """
        Test serialization/deserialization for BenchmarkData
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bandwidth_model = {}  # Bandwidth
        bandwidth_model['download_bandwidth_mbps'] = 'testString'
        bandwidth_model['upload_bandwidth_mbps'] = 'testString'

        results_model = {}  # Results
        results_model['create_bucket_time_sec'] = 'testString'
        results_model['download_files_time_sec'] = 'testString'
        results_model['erase_bucket_time_sec'] = 'testString'
        results_model['erase_objects_time_sec'] = 'testString'
        results_model['list_files_time_sec'] = 'testString'
        results_model['total_operations_time_sec'] = 'testString'
        results_model['upload_files_time_sec'] = 'testString'

        # Construct a json representation of a BenchmarkData model
        benchmark_data_model_json = {}
        benchmark_data_model_json['bandwidth'] = bandwidth_model
        benchmark_data_model_json['date'] = '2019-01-01'
        benchmark_data_model_json['num_files'] = 0
        benchmark_data_model_json['results'] = results_model
        benchmark_data_model_json['size_files'] = 0
        benchmark_data_model_json['time'] = 'testString'

        # Construct a model instance of BenchmarkData by calling from_dict on the json representation
        benchmark_data_model = BenchmarkData.from_dict(benchmark_data_model_json)
        assert benchmark_data_model != False

        # Construct a model instance of BenchmarkData by calling from_dict on the json representation
        benchmark_data_model_dict = BenchmarkData.from_dict(benchmark_data_model_json).__dict__
        benchmark_data_model2 = BenchmarkData(**benchmark_data_model_dict)

        # Verify the model instances are equivalent
        assert benchmark_data_model == benchmark_data_model2

        # Convert model instance back to dict and verify no loss of data
        benchmark_data_model_json2 = benchmark_data_model.to_dict()
        assert benchmark_data_model_json2 == benchmark_data_model_json


class TestModel_BenchmarkStatusResponse:
    """
    Test Class for BenchmarkStatusResponse
    """

    def test_benchmark_status_response_serialization(self):
        """
        Test serialization/deserialization for BenchmarkStatusResponse
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bandwidth_model = {}  # Bandwidth
        bandwidth_model['download_bandwidth_mbps'] = 'testString'
        bandwidth_model['upload_bandwidth_mbps'] = 'testString'

        results_model = {}  # Results
        results_model['create_bucket_time_sec'] = 'testString'
        results_model['download_files_time_sec'] = 'testString'
        results_model['erase_bucket_time_sec'] = 'testString'
        results_model['erase_objects_time_sec'] = 'testString'
        results_model['list_files_time_sec'] = 'testString'
        results_model['total_operations_time_sec'] = 'testString'
        results_model['upload_files_time_sec'] = 'testString'

        benchmark_data_model = {}  # BenchmarkData
        benchmark_data_model['bandwidth'] = bandwidth_model
        benchmark_data_model['date'] = '2019-01-01'
        benchmark_data_model['num_files'] = 0
        benchmark_data_model['results'] = results_model
        benchmark_data_model['size_files'] = 0
        benchmark_data_model['time'] = 'testString'

        # Construct a json representation of a BenchmarkStatusResponse model
        benchmark_status_response_model_json = {}
        benchmark_status_response_model_json['data'] = benchmark_data_model
        benchmark_status_response_model_json['error'] = 'testString'
        benchmark_status_response_model_json['message'] = 'testString'
        benchmark_status_response_model_json['status'] = 'testString'

        # Construct a model instance of BenchmarkStatusResponse by calling from_dict on the json representation
        benchmark_status_response_model = BenchmarkStatusResponse.from_dict(benchmark_status_response_model_json)
        assert benchmark_status_response_model != False

        # Construct a model instance of BenchmarkStatusResponse by calling from_dict on the json representation
        benchmark_status_response_model_dict = BenchmarkStatusResponse.from_dict(benchmark_status_response_model_json).__dict__
        benchmark_status_response_model2 = BenchmarkStatusResponse(**benchmark_status_response_model_dict)

        # Verify the model instances are equivalent
        assert benchmark_status_response_model == benchmark_status_response_model2

        # Convert model instance back to dict and verify no loss of data
        benchmark_status_response_model_json2 = benchmark_status_response_model.to_dict()
        assert benchmark_status_response_model_json2 == benchmark_status_response_model_json


class TestModel_BucketCatalog:
    """
    Test Class for BucketCatalog
    """

    def test_bucket_catalog_serialization(self):
        """
        Test serialization/deserialization for BucketCatalog
        """

        # Construct a json representation of a BucketCatalog model
        bucket_catalog_model_json = {}
        bucket_catalog_model_json['catalog_name'] = 'sampleCatalog'
        bucket_catalog_model_json['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        bucket_catalog_model_json['catalog_type'] = 'iceberg'

        # Construct a model instance of BucketCatalog by calling from_dict on the json representation
        bucket_catalog_model = BucketCatalog.from_dict(bucket_catalog_model_json)
        assert bucket_catalog_model != False

        # Construct a model instance of BucketCatalog by calling from_dict on the json representation
        bucket_catalog_model_dict = BucketCatalog.from_dict(bucket_catalog_model_json).__dict__
        bucket_catalog_model2 = BucketCatalog(**bucket_catalog_model_dict)

        # Verify the model instances are equivalent
        assert bucket_catalog_model == bucket_catalog_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_catalog_model_json2 = bucket_catalog_model.to_dict()
        assert bucket_catalog_model_json2 == bucket_catalog_model_json


class TestModel_BucketDetails:
    """
    Test Class for BucketDetails
    """

    def test_bucket_details_serialization(self):
        """
        Test serialization/deserialization for BucketDetails
        """

        # Construct a json representation of a BucketDetails model
        bucket_details_model_json = {}
        bucket_details_model_json['access_key'] = '<access_key>'
        bucket_details_model_json['bucket_name'] = 'sample-bucket'
        bucket_details_model_json['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model_json['key_file'] = 'key_file'
        bucket_details_model_json['provider'] = 'ibm-cos'
        bucket_details_model_json['region'] = 'us-south'
        bucket_details_model_json['secret_key'] = 'secret_key'

        # Construct a model instance of BucketDetails by calling from_dict on the json representation
        bucket_details_model = BucketDetails.from_dict(bucket_details_model_json)
        assert bucket_details_model != False

        # Construct a model instance of BucketDetails by calling from_dict on the json representation
        bucket_details_model_dict = BucketDetails.from_dict(bucket_details_model_json).__dict__
        bucket_details_model2 = BucketDetails(**bucket_details_model_dict)

        # Verify the model instances are equivalent
        assert bucket_details_model == bucket_details_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_details_model_json2 = bucket_details_model.to_dict()
        assert bucket_details_model_json2 == bucket_details_model_json


class TestModel_BucketObjectProperties:
    """
    Test Class for BucketObjectProperties
    """

    def test_bucket_object_properties_serialization(self):
        """
        Test serialization/deserialization for BucketObjectProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bucket_registration_object_size_collection_model = {}  # BucketRegistrationObjectSizeCollection
        bucket_registration_object_size_collection_model['content_type'] = 'application/json'
        bucket_registration_object_size_collection_model['file_type'] = 'json'
        bucket_registration_object_size_collection_model['last_modified'] = 'utc-2014-07'
        bucket_registration_object_size_collection_model['metadata'] = {'key1': 'testString'}
        bucket_registration_object_size_collection_model['path'] = 'iceberg/test/data'
        bucket_registration_object_size_collection_model['size'] = '1024'

        # Construct a json representation of a BucketObjectProperties model
        bucket_object_properties_model_json = {}
        bucket_object_properties_model_json['object_properties'] = [bucket_registration_object_size_collection_model]

        # Construct a model instance of BucketObjectProperties by calling from_dict on the json representation
        bucket_object_properties_model = BucketObjectProperties.from_dict(bucket_object_properties_model_json)
        assert bucket_object_properties_model != False

        # Construct a model instance of BucketObjectProperties by calling from_dict on the json representation
        bucket_object_properties_model_dict = BucketObjectProperties.from_dict(bucket_object_properties_model_json).__dict__
        bucket_object_properties_model2 = BucketObjectProperties(**bucket_object_properties_model_dict)

        # Verify the model instances are equivalent
        assert bucket_object_properties_model == bucket_object_properties_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_object_properties_model_json2 = bucket_object_properties_model.to_dict()
        assert bucket_object_properties_model_json2 == bucket_object_properties_model_json


class TestModel_BucketObjectSizePathsItems:
    """
    Test Class for BucketObjectSizePathsItems
    """

    def test_bucket_object_size_paths_items_serialization(self):
        """
        Test serialization/deserialization for BucketObjectSizePathsItems
        """

        # Construct a json representation of a BucketObjectSizePathsItems model
        bucket_object_size_paths_items_model_json = {}
        bucket_object_size_paths_items_model_json['path'] = 'testString'

        # Construct a model instance of BucketObjectSizePathsItems by calling from_dict on the json representation
        bucket_object_size_paths_items_model = BucketObjectSizePathsItems.from_dict(bucket_object_size_paths_items_model_json)
        assert bucket_object_size_paths_items_model != False

        # Construct a model instance of BucketObjectSizePathsItems by calling from_dict on the json representation
        bucket_object_size_paths_items_model_dict = BucketObjectSizePathsItems.from_dict(bucket_object_size_paths_items_model_json).__dict__
        bucket_object_size_paths_items_model2 = BucketObjectSizePathsItems(**bucket_object_size_paths_items_model_dict)

        # Verify the model instances are equivalent
        assert bucket_object_size_paths_items_model == bucket_object_size_paths_items_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_object_size_paths_items_model_json2 = bucket_object_size_paths_items_model.to_dict()
        assert bucket_object_size_paths_items_model_json2 == bucket_object_size_paths_items_model_json


class TestModel_BucketRegistration:
    """
    Test Class for BucketRegistration
    """

    def test_bucket_registration_serialization(self):
        """
        Test serialization/deserialization for BucketRegistration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bucket_catalog_model = {}  # BucketCatalog
        bucket_catalog_model['catalog_name'] = 'hive_data'
        bucket_catalog_model['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        bucket_catalog_model['catalog_type'] = 'hive'

        bucket_details_model = {}  # BucketDetails
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        storage_details_model = {}  # StorageDetails
        storage_details_model['access_key'] = '<access_key>'
        storage_details_model['application_id'] = '<application_id>'
        storage_details_model['auth_mode'] = '<account_key/sas/service_principle>'
        storage_details_model['container_name'] = 'sample-container'
        storage_details_model['directory_id'] = '<directory_id>'
        storage_details_model['endpoint'] = 'abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/'
        storage_details_model['sas_token'] = '<sas_token>'
        storage_details_model['secret_key'] = 'secret_key'
        storage_details_model['storage_account_name'] = 'sample-storage'

        # Construct a json representation of a BucketRegistration model
        bucket_registration_model_json = {}
        bucket_registration_model_json['actions'] = ['read', 'update']
        bucket_registration_model_json['associated_catalog'] = bucket_catalog_model
        bucket_registration_model_json['bucket_details'] = bucket_details_model
        bucket_registration_model_json['bucket_display_name'] = 'sample-bucket-displayname'
        bucket_registration_model_json['bucket_id'] = 'samplebucket123'
        bucket_registration_model_json['bucket_type'] = 'ibm_cos'
        bucket_registration_model_json['created_by'] = '<username>@<domain>.com'
        bucket_registration_model_json['created_on'] = '1686120645'
        bucket_registration_model_json['description'] = 'COS bucket for customer data'
        bucket_registration_model_json['managed_by'] = 'ibm'
        bucket_registration_model_json['region'] = 'us-south'
        bucket_registration_model_json['state'] = 'active'
        bucket_registration_model_json['storage_details'] = storage_details_model
        bucket_registration_model_json['system_bucket_update_credentials'] = True
        bucket_registration_model_json['tags'] = ['testbucket', 'write customer data\'']

        # Construct a model instance of BucketRegistration by calling from_dict on the json representation
        bucket_registration_model = BucketRegistration.from_dict(bucket_registration_model_json)
        assert bucket_registration_model != False

        # Construct a model instance of BucketRegistration by calling from_dict on the json representation
        bucket_registration_model_dict = BucketRegistration.from_dict(bucket_registration_model_json).__dict__
        bucket_registration_model2 = BucketRegistration(**bucket_registration_model_dict)

        # Verify the model instances are equivalent
        assert bucket_registration_model == bucket_registration_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_registration_model_json2 = bucket_registration_model.to_dict()
        assert bucket_registration_model_json2 == bucket_registration_model_json


class TestModel_BucketRegistrationCollection:
    """
    Test Class for BucketRegistrationCollection
    """

    def test_bucket_registration_collection_serialization(self):
        """
        Test serialization/deserialization for BucketRegistrationCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bucket_catalog_model = {}  # BucketCatalog
        bucket_catalog_model['catalog_name'] = 'iceberg_catalog'
        bucket_catalog_model['catalog_tags'] = []
        bucket_catalog_model['catalog_type'] = 'iceberg'

        bucket_details_model = {}  # BucketDetails
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'iceberg-bucket'
        bucket_details_model['endpoint'] = 'http://xyz-minio-svc:9000'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        storage_details_model = {}  # StorageDetails
        storage_details_model['access_key'] = '<access_key>'
        storage_details_model['application_id'] = '<application_id>'
        storage_details_model['auth_mode'] = 'account_key'
        storage_details_model['container_name'] = 'conatiner_name'
        storage_details_model['directory_id'] = '<directory_id>'
        storage_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        storage_details_model['sas_token'] = '<sas_token>'
        storage_details_model['secret_key'] = 'secret_key'
        storage_details_model['storage_account_name'] = 'storage_account_name'

        bucket_registration_model = {}  # BucketRegistration
        bucket_registration_model['actions'] = ['browse', 'view', 'modify', 'create', 'grant', 'revoke', 'update', 'remove', 'activate', 'register']
        bucket_registration_model['associated_catalog'] = bucket_catalog_model
        bucket_registration_model['bucket_details'] = bucket_details_model
        bucket_registration_model['bucket_display_name'] = 'hive-bucket'
        bucket_registration_model['bucket_id'] = 'iceberg-bucket'
        bucket_registration_model['bucket_type'] = 'minio'
        bucket_registration_model['created_by'] = 'user'
        bucket_registration_model['created_on'] = '1699457595'
        bucket_registration_model['description'] = 'default bucket'
        bucket_registration_model['managed_by'] = 'ibm'
        bucket_registration_model['region'] = 'us-south'
        bucket_registration_model['state'] = 'active'
        bucket_registration_model['storage_details'] = storage_details_model
        bucket_registration_model['system_bucket_update_credentials'] = True
        bucket_registration_model['tags'] = ['tag1', 'tag2']

        # Construct a json representation of a BucketRegistrationCollection model
        bucket_registration_collection_model_json = {}
        bucket_registration_collection_model_json['bucket_registrations'] = [bucket_registration_model]

        # Construct a model instance of BucketRegistrationCollection by calling from_dict on the json representation
        bucket_registration_collection_model = BucketRegistrationCollection.from_dict(bucket_registration_collection_model_json)
        assert bucket_registration_collection_model != False

        # Construct a model instance of BucketRegistrationCollection by calling from_dict on the json representation
        bucket_registration_collection_model_dict = BucketRegistrationCollection.from_dict(bucket_registration_collection_model_json).__dict__
        bucket_registration_collection_model2 = BucketRegistrationCollection(**bucket_registration_collection_model_dict)

        # Verify the model instances are equivalent
        assert bucket_registration_collection_model == bucket_registration_collection_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_registration_collection_model_json2 = bucket_registration_collection_model.to_dict()
        assert bucket_registration_collection_model_json2 == bucket_registration_collection_model_json


class TestModel_BucketRegistrationObjectCollection:
    """
    Test Class for BucketRegistrationObjectCollection
    """

    def test_bucket_registration_object_collection_serialization(self):
        """
        Test serialization/deserialization for BucketRegistrationObjectCollection
        """

        # Construct a json representation of a BucketRegistrationObjectCollection model
        bucket_registration_object_collection_model_json = {}
        bucket_registration_object_collection_model_json['objects'] = ['testString']

        # Construct a model instance of BucketRegistrationObjectCollection by calling from_dict on the json representation
        bucket_registration_object_collection_model = BucketRegistrationObjectCollection.from_dict(bucket_registration_object_collection_model_json)
        assert bucket_registration_object_collection_model != False

        # Construct a model instance of BucketRegistrationObjectCollection by calling from_dict on the json representation
        bucket_registration_object_collection_model_dict = BucketRegistrationObjectCollection.from_dict(bucket_registration_object_collection_model_json).__dict__
        bucket_registration_object_collection_model2 = BucketRegistrationObjectCollection(**bucket_registration_object_collection_model_dict)

        # Verify the model instances are equivalent
        assert bucket_registration_object_collection_model == bucket_registration_object_collection_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_registration_object_collection_model_json2 = bucket_registration_object_collection_model.to_dict()
        assert bucket_registration_object_collection_model_json2 == bucket_registration_object_collection_model_json


class TestModel_BucketRegistrationObjectSizeCollection:
    """
    Test Class for BucketRegistrationObjectSizeCollection
    """

    def test_bucket_registration_object_size_collection_serialization(self):
        """
        Test serialization/deserialization for BucketRegistrationObjectSizeCollection
        """

        # Construct a json representation of a BucketRegistrationObjectSizeCollection model
        bucket_registration_object_size_collection_model_json = {}
        bucket_registration_object_size_collection_model_json['content_type'] = 'string'
        bucket_registration_object_size_collection_model_json['file_type'] = 'string'
        bucket_registration_object_size_collection_model_json['last_modified'] = 'utc-2014-07'
        bucket_registration_object_size_collection_model_json['metadata'] = {'key1': 'testString'}
        bucket_registration_object_size_collection_model_json['path'] = 'abc/abc/data'
        bucket_registration_object_size_collection_model_json['size'] = '1024'

        # Construct a model instance of BucketRegistrationObjectSizeCollection by calling from_dict on the json representation
        bucket_registration_object_size_collection_model = BucketRegistrationObjectSizeCollection.from_dict(bucket_registration_object_size_collection_model_json)
        assert bucket_registration_object_size_collection_model != False

        # Construct a model instance of BucketRegistrationObjectSizeCollection by calling from_dict on the json representation
        bucket_registration_object_size_collection_model_dict = BucketRegistrationObjectSizeCollection.from_dict(bucket_registration_object_size_collection_model_json).__dict__
        bucket_registration_object_size_collection_model2 = BucketRegistrationObjectSizeCollection(**bucket_registration_object_size_collection_model_dict)

        # Verify the model instances are equivalent
        assert bucket_registration_object_size_collection_model == bucket_registration_object_size_collection_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_registration_object_size_collection_model_json2 = bucket_registration_object_size_collection_model.to_dict()
        assert bucket_registration_object_size_collection_model_json2 == bucket_registration_object_size_collection_model_json


class TestModel_BucketRegistrationPatch:
    """
    Test Class for BucketRegistrationPatch
    """

    def test_bucket_registration_patch_serialization(self):
        """
        Test serialization/deserialization for BucketRegistrationPatch
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bucket_details_model = {}  # BucketDetails
        bucket_details_model['access_key'] = '<access_key>'
        bucket_details_model['bucket_name'] = 'sample-bucket'
        bucket_details_model['endpoint'] = 'https://s3.us-south.cloud-object-storage.appdomain.cloud/'
        bucket_details_model['key_file'] = 'key_file'
        bucket_details_model['provider'] = 'ibm-cos'
        bucket_details_model['region'] = 'us-south'
        bucket_details_model['secret_key'] = 'secret_key'

        # Construct a json representation of a BucketRegistrationPatch model
        bucket_registration_patch_model_json = {}
        bucket_registration_patch_model_json['bucket_details'] = bucket_details_model
        bucket_registration_patch_model_json['bucket_display_name'] = 'sample-bucket-displayname'
        bucket_registration_patch_model_json['description'] = 'COS bucket for customer data'
        bucket_registration_patch_model_json['system_bucket_update_credentials'] = True
        bucket_registration_patch_model_json['tags'] = ['testbucket', 'userbucket']

        # Construct a model instance of BucketRegistrationPatch by calling from_dict on the json representation
        bucket_registration_patch_model = BucketRegistrationPatch.from_dict(bucket_registration_patch_model_json)
        assert bucket_registration_patch_model != False

        # Construct a model instance of BucketRegistrationPatch by calling from_dict on the json representation
        bucket_registration_patch_model_dict = BucketRegistrationPatch.from_dict(bucket_registration_patch_model_json).__dict__
        bucket_registration_patch_model2 = BucketRegistrationPatch(**bucket_registration_patch_model_dict)

        # Verify the model instances are equivalent
        assert bucket_registration_patch_model == bucket_registration_patch_model2

        # Convert model instance back to dict and verify no loss of data
        bucket_registration_patch_model_json2 = bucket_registration_patch_model.to_dict()
        assert bucket_registration_patch_model_json2 == bucket_registration_patch_model_json


class TestModel_Catalog:
    """
    Test Class for Catalog
    """

    def test_catalog_serialization(self):
        """
        Test serialization/deserialization for Catalog
        """

        # Construct a json representation of a Catalog model
        catalog_model_json = {}
        catalog_model_json['actions'] = ['update', 'delete']
        catalog_model_json['associated_buckets'] = ['bucket_1', 'bucket_2']
        catalog_model_json['associated_databases'] = ['database_1', 'database_2']
        catalog_model_json['associated_engines'] = ['engine_1', 'engine_2']
        catalog_model_json['catalog_name'] = 'sampleCatalog'
        catalog_model_json['catalog_type'] = 'iceberg'
        catalog_model_json['created_by'] = '<username>@<domain>.com'
        catalog_model_json['created_on'] = '1602839833'
        catalog_model_json['days_left'] = '30'
        catalog_model_json['description'] = 'Iceberg catalog description'
        catalog_model_json['hostname'] = 's3a://samplehost.com'
        catalog_model_json['last_sync_at'] = '1602839833'
        catalog_model_json['managed_by'] = 'ibm'
        catalog_model_json['metastore'] = 'glue'
        catalog_model_json['port'] = '3232'
        catalog_model_json['rest_uri'] = 'https://samplehost-catalog:4352'
        catalog_model_json['status'] = 'running'
        catalog_model_json['sync_description'] = 'Table registration was successful'
        catalog_model_json['sync_exception'] = ['Table is corrupted', 'Table metadata not available']
        catalog_model_json['sync_status'] = 'SUCCESS'
        catalog_model_json['tags'] = ['tag1', 'tag2']
        catalog_model_json['thrift_uri'] = 'thrift://samplehost-catalog:4354'

        # Construct a model instance of Catalog by calling from_dict on the json representation
        catalog_model = Catalog.from_dict(catalog_model_json)
        assert catalog_model != False

        # Construct a model instance of Catalog by calling from_dict on the json representation
        catalog_model_dict = Catalog.from_dict(catalog_model_json).__dict__
        catalog_model2 = Catalog(**catalog_model_dict)

        # Verify the model instances are equivalent
        assert catalog_model == catalog_model2

        # Convert model instance back to dict and verify no loss of data
        catalog_model_json2 = catalog_model.to_dict()
        assert catalog_model_json2 == catalog_model_json


class TestModel_CatalogCollection:
    """
    Test Class for CatalogCollection
    """

    def test_catalog_collection_serialization(self):
        """
        Test serialization/deserialization for CatalogCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        catalog_model = {}  # Catalog
        catalog_model['actions'] = ['update', 'delete']
        catalog_model['associated_buckets'] = ['bucket_1', 'bucket_2']
        catalog_model['associated_databases'] = ['database_1', 'database_2']
        catalog_model['associated_engines'] = ['engine_1', 'engine_2']
        catalog_model['catalog_name'] = 'sampleCatalog'
        catalog_model['catalog_type'] = 'iceberg'
        catalog_model['created_by'] = '<username>@<domain>.com'
        catalog_model['created_on'] = '1602839833'
        catalog_model['days_left'] = '30'
        catalog_model['description'] = 'Iceberg catalog description'
        catalog_model['hostname'] = 's3a://samplehost.com'
        catalog_model['last_sync_at'] = '1602839833'
        catalog_model['managed_by'] = 'ibm'
        catalog_model['metastore'] = 'glue'
        catalog_model['port'] = '3232'
        catalog_model['rest_uri'] = 'https://samplehost-catalog:4352'
        catalog_model['status'] = 'running'
        catalog_model['sync_description'] = 'Table registration was successful'
        catalog_model['sync_exception'] = ['Table is corrupted', 'Table metadata not available']
        catalog_model['sync_status'] = 'SUCCESS'
        catalog_model['tags'] = ['tag1', 'tag2']
        catalog_model['thrift_uri'] = 'thrift://samplehost-catalog:4354'

        # Construct a json representation of a CatalogCollection model
        catalog_collection_model_json = {}
        catalog_collection_model_json['catalogs'] = [catalog_model]

        # Construct a model instance of CatalogCollection by calling from_dict on the json representation
        catalog_collection_model = CatalogCollection.from_dict(catalog_collection_model_json)
        assert catalog_collection_model != False

        # Construct a model instance of CatalogCollection by calling from_dict on the json representation
        catalog_collection_model_dict = CatalogCollection.from_dict(catalog_collection_model_json).__dict__
        catalog_collection_model2 = CatalogCollection(**catalog_collection_model_dict)

        # Verify the model instances are equivalent
        assert catalog_collection_model == catalog_collection_model2

        # Convert model instance back to dict and verify no loss of data
        catalog_collection_model_json2 = catalog_collection_model.to_dict()
        assert catalog_collection_model_json2 == catalog_collection_model_json


class TestModel_Column:
    """
    Test Class for Column
    """

    def test_column_serialization(self):
        """
        Test serialization/deserialization for Column
        """

        # Construct a json representation of a Column model
        column_model_json = {}
        column_model_json['column_name'] = 'expenses'
        column_model_json['comment'] = 'expenses column'
        column_model_json['extra'] = 'varchar'
        column_model_json['length'] = '30'
        column_model_json['precision'] = '10'
        column_model_json['scale'] = '2'
        column_model_json['type'] = 'varchar'

        # Construct a model instance of Column by calling from_dict on the json representation
        column_model = Column.from_dict(column_model_json)
        assert column_model != False

        # Construct a model instance of Column by calling from_dict on the json representation
        column_model_dict = Column.from_dict(column_model_json).__dict__
        column_model2 = Column(**column_model_dict)

        # Verify the model instances are equivalent
        assert column_model == column_model2

        # Convert model instance back to dict and verify no loss of data
        column_model_json2 = column_model.to_dict()
        assert column_model_json2 == column_model_json


class TestModel_ColumnCollection:
    """
    Test Class for ColumnCollection
    """

    def test_column_collection_serialization(self):
        """
        Test serialization/deserialization for ColumnCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        column_model = {}  # Column
        column_model['column_name'] = 'customer_data'
        column_model['comment'] = 'customer_data column'
        column_model['extra'] = 'varchar'
        column_model['length'] = '30'
        column_model['precision'] = '10'
        column_model['scale'] = '2'
        column_model['type'] = 'varchar'

        # Construct a json representation of a ColumnCollection model
        column_collection_model_json = {}
        column_collection_model_json['columns'] = [column_model]

        # Construct a model instance of ColumnCollection by calling from_dict on the json representation
        column_collection_model = ColumnCollection.from_dict(column_collection_model_json)
        assert column_collection_model != False

        # Construct a model instance of ColumnCollection by calling from_dict on the json representation
        column_collection_model_dict = ColumnCollection.from_dict(column_collection_model_json).__dict__
        column_collection_model2 = ColumnCollection(**column_collection_model_dict)

        # Verify the model instances are equivalent
        assert column_collection_model == column_collection_model2

        # Convert model instance back to dict and verify no loss of data
        column_collection_model_json2 = column_collection_model.to_dict()
        assert column_collection_model_json2 == column_collection_model_json


class TestModel_ColumnPatch:
    """
    Test Class for ColumnPatch
    """

    def test_column_patch_serialization(self):
        """
        Test serialization/deserialization for ColumnPatch
        """

        # Construct a json representation of a ColumnPatch model
        column_patch_model_json = {}
        column_patch_model_json['column_name'] = 'expenses'

        # Construct a model instance of ColumnPatch by calling from_dict on the json representation
        column_patch_model = ColumnPatch.from_dict(column_patch_model_json)
        assert column_patch_model != False

        # Construct a model instance of ColumnPatch by calling from_dict on the json representation
        column_patch_model_dict = ColumnPatch.from_dict(column_patch_model_json).__dict__
        column_patch_model2 = ColumnPatch(**column_patch_model_dict)

        # Verify the model instances are equivalent
        assert column_patch_model == column_patch_model2

        # Convert model instance back to dict and verify no loss of data
        column_patch_model_json2 = column_patch_model.to_dict()
        assert column_patch_model_json2 == column_patch_model_json


class TestModel_ColumnsResponse:
    """
    Test Class for ColumnsResponse
    """

    def test_columns_response_serialization(self):
        """
        Test serialization/deserialization for ColumnsResponse
        """

        # Construct dict forms of any model objects needed in order to build this model.

        table_colum_detail_columns_items_model = {}  # TableColumDetailColumnsItems
        table_colum_detail_columns_items_model['column'] = 'club_name'
        table_colum_detail_columns_items_model['index'] = 38
        table_colum_detail_columns_items_model['type'] = 'string'

        table_colum_detail_model = {}  # TableColumDetail
        table_colum_detail_model['bucket'] = 'iceberg-bucket'
        table_colum_detail_model['catalog'] = 'iceberg_data'
        table_colum_detail_model['columns'] = [table_colum_detail_columns_items_model]
        table_colum_detail_model['owner'] = 'ibmlhadmin'
        table_colum_detail_model['schema'] = 's3'
        table_colum_detail_model['table'] = 'clubs'

        # Construct a json representation of a ColumnsResponse model
        columns_response_model_json = {}
        columns_response_model_json['columns'] = [table_colum_detail_model]
        columns_response_model_json['message'] = 'testString'
        columns_response_model_json['message_code'] = 'testString'

        # Construct a model instance of ColumnsResponse by calling from_dict on the json representation
        columns_response_model = ColumnsResponse.from_dict(columns_response_model_json)
        assert columns_response_model != False

        # Construct a model instance of ColumnsResponse by calling from_dict on the json representation
        columns_response_model_dict = ColumnsResponse.from_dict(columns_response_model_json).__dict__
        columns_response_model2 = ColumnsResponse(**columns_response_model_dict)

        # Verify the model instances are equivalent
        assert columns_response_model == columns_response_model2

        # Convert model instance back to dict and verify no loss of data
        columns_response_model_json2 = columns_response_model.to_dict()
        assert columns_response_model_json2 == columns_response_model_json


class TestModel_ConnectionPropertiesDetails:
    """
    Test Class for ConnectionPropertiesDetails
    """

    def test_connection_properties_details_serialization(self):
        """
        Test serialization/deserialization for ConnectionPropertiesDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        external_details_model = {}  # ExternalDetails
        external_details_model['port'] = 4553
        external_details_model['hostname'] = 'external hostname'

        internal_details_model = {}  # InternalDetails
        internal_details_model['port'] = 4553
        internal_details_model['hostname'] = 'internal hostname'

        jdbc_thrift_urls_model = {}  # JdbcThriftUrls
        jdbc_thrift_urls_model['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        details_model = {}  # Details
        details_model['ca_certificate'] = 'sample ca certificate'
        details_model['default_configs'] = {'key1': 'testString'}
        details_model['external'] = external_details_model
        details_model['grpc_api_endpoint'] = internal_details_model
        details_model['hostname'] = 'sample hostname'
        details_model['id'] = 'sample ID'
        details_model['instance_crn'] = 'sample instance CRN'
        details_model['instance_id'] = 'sample instance ID'
        details_model['internal'] = internal_details_model
        details_model['jdbc_class'] = 'com.facebook.presto.jdbc.PrestoDriver'
        details_model['jdbc_urls'] = jdbc_thrift_urls_model
        details_model['name'] = 'sample name'
        details_model['port'] = 4553
        details_model['rest_api_endpoint'] = internal_details_model
        details_model['spark_engine_endpoint'] = 'Spark Engine endpoint'
        details_model['ssl_certificate'] = 'sample ssl certificate'
        details_model['thrift_urls'] = jdbc_thrift_urls_model
        details_model['version'] = 'java'
        details_model['watsonx_data_application_endpoint'] = 'sample application end point'

        connection_properties_details_properties_connection_items_model = {}  # ConnectionPropertiesDetailsPropertiesConnectionItems
        connection_properties_details_properties_connection_items_model['name'] = 'host'
        connection_properties_details_properties_connection_items_model['value'] = 'sample_value'

        connection_properties_details_properties_model = {}  # ConnectionPropertiesDetailsProperties
        connection_properties_details_properties_model['connection'] = [connection_properties_details_properties_connection_items_model]

        # Construct a json representation of a ConnectionPropertiesDetails model
        connection_properties_details_model_json = {}
        connection_properties_details_model_json['connection_name'] = 'presto-01'
        connection_properties_details_model_json['details'] = details_model
        connection_properties_details_model_json['properties'] = connection_properties_details_properties_model
        connection_properties_details_model_json['type'] = 'presto'

        # Construct a model instance of ConnectionPropertiesDetails by calling from_dict on the json representation
        connection_properties_details_model = ConnectionPropertiesDetails.from_dict(connection_properties_details_model_json)
        assert connection_properties_details_model != False

        # Construct a model instance of ConnectionPropertiesDetails by calling from_dict on the json representation
        connection_properties_details_model_dict = ConnectionPropertiesDetails.from_dict(connection_properties_details_model_json).__dict__
        connection_properties_details_model2 = ConnectionPropertiesDetails(**connection_properties_details_model_dict)

        # Verify the model instances are equivalent
        assert connection_properties_details_model == connection_properties_details_model2

        # Convert model instance back to dict and verify no loss of data
        connection_properties_details_model_json2 = connection_properties_details_model.to_dict()
        assert connection_properties_details_model_json2 == connection_properties_details_model_json


class TestModel_ConnectionPropertiesDetailsProperties:
    """
    Test Class for ConnectionPropertiesDetailsProperties
    """

    def test_connection_properties_details_properties_serialization(self):
        """
        Test serialization/deserialization for ConnectionPropertiesDetailsProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        connection_properties_details_properties_connection_items_model = {}  # ConnectionPropertiesDetailsPropertiesConnectionItems
        connection_properties_details_properties_connection_items_model['name'] = 'host'
        connection_properties_details_properties_connection_items_model['value'] = 'sample_value'

        # Construct a json representation of a ConnectionPropertiesDetailsProperties model
        connection_properties_details_properties_model_json = {}
        connection_properties_details_properties_model_json['connection'] = [connection_properties_details_properties_connection_items_model]

        # Construct a model instance of ConnectionPropertiesDetailsProperties by calling from_dict on the json representation
        connection_properties_details_properties_model = ConnectionPropertiesDetailsProperties.from_dict(connection_properties_details_properties_model_json)
        assert connection_properties_details_properties_model != False

        # Construct a model instance of ConnectionPropertiesDetailsProperties by calling from_dict on the json representation
        connection_properties_details_properties_model_dict = ConnectionPropertiesDetailsProperties.from_dict(connection_properties_details_properties_model_json).__dict__
        connection_properties_details_properties_model2 = ConnectionPropertiesDetailsProperties(**connection_properties_details_properties_model_dict)

        # Verify the model instances are equivalent
        assert connection_properties_details_properties_model == connection_properties_details_properties_model2

        # Convert model instance back to dict and verify no loss of data
        connection_properties_details_properties_model_json2 = connection_properties_details_properties_model.to_dict()
        assert connection_properties_details_properties_model_json2 == connection_properties_details_properties_model_json


class TestModel_ConnectionPropertiesDetailsPropertiesConnectionItems:
    """
    Test Class for ConnectionPropertiesDetailsPropertiesConnectionItems
    """

    def test_connection_properties_details_properties_connection_items_serialization(self):
        """
        Test serialization/deserialization for ConnectionPropertiesDetailsPropertiesConnectionItems
        """

        # Construct a json representation of a ConnectionPropertiesDetailsPropertiesConnectionItems model
        connection_properties_details_properties_connection_items_model_json = {}
        connection_properties_details_properties_connection_items_model_json['name'] = 'host'
        connection_properties_details_properties_connection_items_model_json['value'] = 'sample_value'

        # Construct a model instance of ConnectionPropertiesDetailsPropertiesConnectionItems by calling from_dict on the json representation
        connection_properties_details_properties_connection_items_model = ConnectionPropertiesDetailsPropertiesConnectionItems.from_dict(connection_properties_details_properties_connection_items_model_json)
        assert connection_properties_details_properties_connection_items_model != False

        # Construct a model instance of ConnectionPropertiesDetailsPropertiesConnectionItems by calling from_dict on the json representation
        connection_properties_details_properties_connection_items_model_dict = ConnectionPropertiesDetailsPropertiesConnectionItems.from_dict(connection_properties_details_properties_connection_items_model_json).__dict__
        connection_properties_details_properties_connection_items_model2 = ConnectionPropertiesDetailsPropertiesConnectionItems(**connection_properties_details_properties_connection_items_model_dict)

        # Verify the model instances are equivalent
        assert connection_properties_details_properties_connection_items_model == connection_properties_details_properties_connection_items_model2

        # Convert model instance back to dict and verify no loss of data
        connection_properties_details_properties_connection_items_model_json2 = connection_properties_details_properties_connection_items_model.to_dict()
        assert connection_properties_details_properties_connection_items_model_json2 == connection_properties_details_properties_connection_items_model_json


class TestModel_CreateActivateBucketCreatedBody:
    """
    Test Class for CreateActivateBucketCreatedBody
    """

    def test_create_activate_bucket_created_body_serialization(self):
        """
        Test serialization/deserialization for CreateActivateBucketCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'Activate bucket'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a CreateActivateBucketCreatedBody model
        create_activate_bucket_created_body_model_json = {}
        create_activate_bucket_created_body_model_json['response'] = success_response_model

        # Construct a model instance of CreateActivateBucketCreatedBody by calling from_dict on the json representation
        create_activate_bucket_created_body_model = CreateActivateBucketCreatedBody.from_dict(create_activate_bucket_created_body_model_json)
        assert create_activate_bucket_created_body_model != False

        # Construct a model instance of CreateActivateBucketCreatedBody by calling from_dict on the json representation
        create_activate_bucket_created_body_model_dict = CreateActivateBucketCreatedBody.from_dict(create_activate_bucket_created_body_model_json).__dict__
        create_activate_bucket_created_body_model2 = CreateActivateBucketCreatedBody(**create_activate_bucket_created_body_model_dict)

        # Verify the model instances are equivalent
        assert create_activate_bucket_created_body_model == create_activate_bucket_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        create_activate_bucket_created_body_model_json2 = create_activate_bucket_created_body_model.to_dict()
        assert create_activate_bucket_created_body_model_json2 == create_activate_bucket_created_body_model_json


class TestModel_CreateEnginePauseCreatedBody:
    """
    Test Class for CreateEnginePauseCreatedBody
    """

    def test_create_engine_pause_created_body_serialization(self):
        """
        Test serialization/deserialization for CreateEnginePauseCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'pause presto engine'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a CreateEnginePauseCreatedBody model
        create_engine_pause_created_body_model_json = {}
        create_engine_pause_created_body_model_json['response'] = success_response_model

        # Construct a model instance of CreateEnginePauseCreatedBody by calling from_dict on the json representation
        create_engine_pause_created_body_model = CreateEnginePauseCreatedBody.from_dict(create_engine_pause_created_body_model_json)
        assert create_engine_pause_created_body_model != False

        # Construct a model instance of CreateEnginePauseCreatedBody by calling from_dict on the json representation
        create_engine_pause_created_body_model_dict = CreateEnginePauseCreatedBody.from_dict(create_engine_pause_created_body_model_json).__dict__
        create_engine_pause_created_body_model2 = CreateEnginePauseCreatedBody(**create_engine_pause_created_body_model_dict)

        # Verify the model instances are equivalent
        assert create_engine_pause_created_body_model == create_engine_pause_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        create_engine_pause_created_body_model_json2 = create_engine_pause_created_body_model.to_dict()
        assert create_engine_pause_created_body_model_json2 == create_engine_pause_created_body_model_json


class TestModel_CreateEngineRestartCreatedBody:
    """
    Test Class for CreateEngineRestartCreatedBody
    """

    def test_create_engine_restart_created_body_serialization(self):
        """
        Test serialization/deserialization for CreateEngineRestartCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'Restart presto engine'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a CreateEngineRestartCreatedBody model
        create_engine_restart_created_body_model_json = {}
        create_engine_restart_created_body_model_json['response'] = success_response_model

        # Construct a model instance of CreateEngineRestartCreatedBody by calling from_dict on the json representation
        create_engine_restart_created_body_model = CreateEngineRestartCreatedBody.from_dict(create_engine_restart_created_body_model_json)
        assert create_engine_restart_created_body_model != False

        # Construct a model instance of CreateEngineRestartCreatedBody by calling from_dict on the json representation
        create_engine_restart_created_body_model_dict = CreateEngineRestartCreatedBody.from_dict(create_engine_restart_created_body_model_json).__dict__
        create_engine_restart_created_body_model2 = CreateEngineRestartCreatedBody(**create_engine_restart_created_body_model_dict)

        # Verify the model instances are equivalent
        assert create_engine_restart_created_body_model == create_engine_restart_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        create_engine_restart_created_body_model_json2 = create_engine_restart_created_body_model.to_dict()
        assert create_engine_restart_created_body_model_json2 == create_engine_restart_created_body_model_json


class TestModel_CreateEngineResumeCreatedBody:
    """
    Test Class for CreateEngineResumeCreatedBody
    """

    def test_create_engine_resume_created_body_serialization(self):
        """
        Test serialization/deserialization for CreateEngineResumeCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'resume presto engine'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a CreateEngineResumeCreatedBody model
        create_engine_resume_created_body_model_json = {}
        create_engine_resume_created_body_model_json['response'] = success_response_model

        # Construct a model instance of CreateEngineResumeCreatedBody by calling from_dict on the json representation
        create_engine_resume_created_body_model = CreateEngineResumeCreatedBody.from_dict(create_engine_resume_created_body_model_json)
        assert create_engine_resume_created_body_model != False

        # Construct a model instance of CreateEngineResumeCreatedBody by calling from_dict on the json representation
        create_engine_resume_created_body_model_dict = CreateEngineResumeCreatedBody.from_dict(create_engine_resume_created_body_model_json).__dict__
        create_engine_resume_created_body_model2 = CreateEngineResumeCreatedBody(**create_engine_resume_created_body_model_dict)

        # Verify the model instances are equivalent
        assert create_engine_resume_created_body_model == create_engine_resume_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        create_engine_resume_created_body_model_json2 = create_engine_resume_created_body_model.to_dict()
        assert create_engine_resume_created_body_model_json2 == create_engine_resume_created_body_model_json


class TestModel_CreateEngineScaleCreatedBody:
    """
    Test Class for CreateEngineScaleCreatedBody
    """

    def test_create_engine_scale_created_body_serialization(self):
        """
        Test serialization/deserialization for CreateEngineScaleCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'scale presto engine'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a CreateEngineScaleCreatedBody model
        create_engine_scale_created_body_model_json = {}
        create_engine_scale_created_body_model_json['response'] = success_response_model

        # Construct a model instance of CreateEngineScaleCreatedBody by calling from_dict on the json representation
        create_engine_scale_created_body_model = CreateEngineScaleCreatedBody.from_dict(create_engine_scale_created_body_model_json)
        assert create_engine_scale_created_body_model != False

        # Construct a model instance of CreateEngineScaleCreatedBody by calling from_dict on the json representation
        create_engine_scale_created_body_model_dict = CreateEngineScaleCreatedBody.from_dict(create_engine_scale_created_body_model_json).__dict__
        create_engine_scale_created_body_model2 = CreateEngineScaleCreatedBody(**create_engine_scale_created_body_model_dict)

        # Verify the model instances are equivalent
        assert create_engine_scale_created_body_model == create_engine_scale_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        create_engine_scale_created_body_model_json2 = create_engine_scale_created_body_model.to_dict()
        assert create_engine_scale_created_body_model_json2 == create_engine_scale_created_body_model_json


class TestModel_CreateSchemaCreatedBody:
    """
    Test Class for CreateSchemaCreatedBody
    """

    def test_create_schema_created_body_serialization(self):
        """
        Test serialization/deserialization for CreateSchemaCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'create schema'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a CreateSchemaCreatedBody model
        create_schema_created_body_model_json = {}
        create_schema_created_body_model_json['response'] = success_response_model

        # Construct a model instance of CreateSchemaCreatedBody by calling from_dict on the json representation
        create_schema_created_body_model = CreateSchemaCreatedBody.from_dict(create_schema_created_body_model_json)
        assert create_schema_created_body_model != False

        # Construct a model instance of CreateSchemaCreatedBody by calling from_dict on the json representation
        create_schema_created_body_model_dict = CreateSchemaCreatedBody.from_dict(create_schema_created_body_model_json).__dict__
        create_schema_created_body_model2 = CreateSchemaCreatedBody(**create_schema_created_body_model_dict)

        # Verify the model instances are equivalent
        assert create_schema_created_body_model == create_schema_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        create_schema_created_body_model_json2 = create_schema_created_body_model.to_dict()
        assert create_schema_created_body_model_json2 == create_schema_created_body_model_json


class TestModel_DatabaseCatalog:
    """
    Test Class for DatabaseCatalog
    """

    def test_database_catalog_serialization(self):
        """
        Test serialization/deserialization for DatabaseCatalog
        """

        # Construct a json representation of a DatabaseCatalog model
        database_catalog_model_json = {}
        database_catalog_model_json['catalog_name'] = 'sampleCatalog'
        database_catalog_model_json['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        database_catalog_model_json['catalog_type'] = 'iceberg'

        # Construct a model instance of DatabaseCatalog by calling from_dict on the json representation
        database_catalog_model = DatabaseCatalog.from_dict(database_catalog_model_json)
        assert database_catalog_model != False

        # Construct a model instance of DatabaseCatalog by calling from_dict on the json representation
        database_catalog_model_dict = DatabaseCatalog.from_dict(database_catalog_model_json).__dict__
        database_catalog_model2 = DatabaseCatalog(**database_catalog_model_dict)

        # Verify the model instances are equivalent
        assert database_catalog_model == database_catalog_model2

        # Convert model instance back to dict and verify no loss of data
        database_catalog_model_json2 = database_catalog_model.to_dict()
        assert database_catalog_model_json2 == database_catalog_model_json


class TestModel_DatabaseCatalogPrototype:
    """
    Test Class for DatabaseCatalogPrototype
    """

    def test_database_catalog_prototype_serialization(self):
        """
        Test serialization/deserialization for DatabaseCatalogPrototype
        """

        # Construct a json representation of a DatabaseCatalogPrototype model
        database_catalog_prototype_model_json = {}
        database_catalog_prototype_model_json['catalog_name'] = 'sampleCatalog'
        database_catalog_prototype_model_json['catalog_type'] = 'iceberg'

        # Construct a model instance of DatabaseCatalogPrototype by calling from_dict on the json representation
        database_catalog_prototype_model = DatabaseCatalogPrototype.from_dict(database_catalog_prototype_model_json)
        assert database_catalog_prototype_model != False

        # Construct a model instance of DatabaseCatalogPrototype by calling from_dict on the json representation
        database_catalog_prototype_model_dict = DatabaseCatalogPrototype.from_dict(database_catalog_prototype_model_json).__dict__
        database_catalog_prototype_model2 = DatabaseCatalogPrototype(**database_catalog_prototype_model_dict)

        # Verify the model instances are equivalent
        assert database_catalog_prototype_model == database_catalog_prototype_model2

        # Convert model instance back to dict and verify no loss of data
        database_catalog_prototype_model_json2 = database_catalog_prototype_model.to_dict()
        assert database_catalog_prototype_model_json2 == database_catalog_prototype_model_json


class TestModel_DatabaseDetails:
    """
    Test Class for DatabaseDetails
    """

    def test_database_details_serialization(self):
        """
        Test serialization/deserialization for DatabaseDetails
        """

        # Construct a json representation of a DatabaseDetails model
        database_details_model_json = {}
        database_details_model_json['authentication_type'] = 'LDAP'
        database_details_model_json['authentication_value'] = 'LDAP'
        database_details_model_json['broker_authentication_password'] = 'samplepassword'
        database_details_model_json['broker_authentication_type'] = 'PASSWORD'
        database_details_model_json['broker_authentication_user'] = 'sampleuser'
        database_details_model_json['broker_host'] = 'samplehost'
        database_details_model_json['broker_port'] = 4553
        database_details_model_json['certificate'] = 'exampleCertificate'
        database_details_model_json['certificate_extension'] = 'pem'
        database_details_model_json['connection_method'] = 'basic, apikey'
        database_details_model_json['connection_mode'] = 'service_name'
        database_details_model_json['connection_mode_value'] = 'orclpdb'
        database_details_model_json['connection_type'] = 'JDBC, Arrow flight'
        database_details_model_json['controller_authentication_password'] = 'samplepassword'
        database_details_model_json['controller_authentication_type'] = 'PASSWORD'
        database_details_model_json['controller_authentication_user'] = 'sampleuser'
        database_details_model_json['coordinator_host'] = 'samplehost'
        database_details_model_json['coordinator_port'] = 4553
        database_details_model_json['cpd_hostname'] = 'samplecpdhostname'
        database_details_model_json['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_details_model_json['database_name'] = 'new_database'
        database_details_model_json['hostname'] = 'http://db2@localhost:9900.com'
        database_details_model_json['hostname_in_certificate'] = 'samplehostname'
        database_details_model_json['hosts'] = 'abc.com:1234,xyz.com:4321'
        database_details_model_json['informix_server'] = 'ol_informix1410'
        database_details_model_json['password'] = 'samplepassword'
        database_details_model_json['port'] = 4553
        database_details_model_json['project_id'] = 'conops-bigquery'
        database_details_model_json['sasl'] = True
        database_details_model_json['sasl_mechanism'] = 'plain'
        database_details_model_json['schema_name'] = 'sampleSchema'
        database_details_model_json['schemas'] = 'redis__name'
        database_details_model_json['service_api_key'] = 'sampleapikey'
        database_details_model_json['service_hostname'] = 'api.dataplatform.dev.cloud.ibm.com'
        database_details_model_json['service_password'] = 'samplepassword'
        database_details_model_json['service_port'] = 443
        database_details_model_json['service_ssl'] = True
        database_details_model_json['service_token_url'] = 'sampletoakenurl'
        database_details_model_json['service_username'] = 'sampleusername'
        database_details_model_json['ssl'] = True
        database_details_model_json['tables'] = 'kafka_table_name, redis_table_name'
        database_details_model_json['username'] = 'sampleuser'
        database_details_model_json['validate_server_certificate'] = True
        database_details_model_json['verify_host_name'] = True
        database_details_model_json['warehouse_name'] = 'samplewrehouse'

        # Construct a model instance of DatabaseDetails by calling from_dict on the json representation
        database_details_model = DatabaseDetails.from_dict(database_details_model_json)
        assert database_details_model != False

        # Construct a model instance of DatabaseDetails by calling from_dict on the json representation
        database_details_model_dict = DatabaseDetails.from_dict(database_details_model_json).__dict__
        database_details_model2 = DatabaseDetails(**database_details_model_dict)

        # Verify the model instances are equivalent
        assert database_details_model == database_details_model2

        # Convert model instance back to dict and verify no loss of data
        database_details_model_json2 = database_details_model.to_dict()
        assert database_details_model_json2 == database_details_model_json


class TestModel_DatabaseRegistration:
    """
    Test Class for DatabaseRegistration
    """

    def test_database_registration_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        database_catalog_model = {}  # DatabaseCatalog
        database_catalog_model['catalog_name'] = 'iceberg_data'
        database_catalog_model['catalog_tags'] = ['tag1', 'tag2']
        database_catalog_model['catalog_type'] = 'iceberg'

        database_details_model = {}  # DatabaseDetails
        database_details_model['authentication_type'] = 'LDAP'
        database_details_model['authentication_value'] = 'LDAP'
        database_details_model['broker_authentication_password'] = 'samplepassword'
        database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_details_model['broker_authentication_user'] = 'sampleuser'
        database_details_model['broker_host'] = 'samplehost'
        database_details_model['broker_port'] = 4553
        database_details_model['certificate'] = 'exampleCertificate'
        database_details_model['certificate_extension'] = 'pem'
        database_details_model['connection_method'] = 'basic, apikey'
        database_details_model['connection_mode'] = 'service_name'
        database_details_model['connection_mode_value'] = 'orclpdb'
        database_details_model['connection_type'] = 'JDBC, Arrow flight'
        database_details_model['controller_authentication_password'] = 'samplepassword'
        database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_details_model['controller_authentication_user'] = 'sampleuser'
        database_details_model['coordinator_host'] = 'samplehost'
        database_details_model['coordinator_port'] = 4553
        database_details_model['cpd_hostname'] = 'samplecpdhostname'
        database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_details_model['database_name'] = 'new_database'
        database_details_model['hostname'] = 'netezza://abc.efg.com'
        database_details_model['hostname_in_certificate'] = 'samplehostname'
        database_details_model['hosts'] = 'abc.com:1234,xyz.com:4321'
        database_details_model['informix_server'] = 'ol_informix1410'
        database_details_model['password'] = 'samplepassword'
        database_details_model['port'] = 4353
        database_details_model['project_id'] = 'conops-bigquery'
        database_details_model['sasl'] = True
        database_details_model['sasl_mechanism'] = 'plain'
        database_details_model['schema_name'] = 'sampleSchema'
        database_details_model['schemas'] = 'redis__name'
        database_details_model['service_api_key'] = 'sampleapikey'
        database_details_model['service_hostname'] = 'api.dataplatform.dev.cloud.ibm.com'
        database_details_model['service_password'] = 'samplepassword'
        database_details_model['service_port'] = 443
        database_details_model['service_ssl'] = True
        database_details_model['service_token_url'] = 'sampletoakenurl'
        database_details_model['service_username'] = 'sampleusername'
        database_details_model['ssl'] = True
        database_details_model['tables'] = 'netezza_table_name'
        database_details_model['username'] = 'sampleuser'
        database_details_model['validate_server_certificate'] = True
        database_details_model['verify_host_name'] = True
        database_details_model['warehouse_name'] = 'samplewrehouse'

        database_registration_database_properties_items_model = {}  # DatabaseRegistrationDatabasePropertiesItems
        database_registration_database_properties_items_model['encrypt'] = True
        database_registration_database_properties_items_model['key'] = 'abc'
        database_registration_database_properties_items_model['value'] = 'xyz'

        database_registration_tables_items_model = {}  # DatabaseRegistrationTablesItems
        database_registration_tables_items_model['created_on'] = '1686792721'
        database_registration_tables_items_model['file_contents'] = 'qweerty'
        database_registration_tables_items_model['file_name'] = 'test.json'
        database_registration_tables_items_model['schema_name'] = 'testschema123'
        database_registration_tables_items_model['table_name'] = 'customer'

        database_registration_topics_items_model = {}  # DatabaseRegistrationTopicsItems
        database_registration_topics_items_model['created_on'] = '1686792721'
        database_registration_topics_items_model['file_contents'] = 'qweerty'
        database_registration_topics_items_model['file_name'] = 'test.json'
        database_registration_topics_items_model['topic_name'] = 'customer'

        # Construct a json representation of a DatabaseRegistration model
        database_registration_model_json = {}
        database_registration_model_json['actions'] = ['update', 'delete']
        database_registration_model_json['associated_catalog'] = database_catalog_model
        database_registration_model_json['catalog_name'] = 'sampleCatalog'
        database_registration_model_json['created_by'] = 'user1@ibm.com'
        database_registration_model_json['created_on'] = '1686792721'
        database_registration_model_json['database_details'] = database_details_model
        database_registration_model_json['database_display_name'] = 'new_database'
        database_registration_model_json['database_id'] = 'mysql123'
        database_registration_model_json['database_properties'] = [database_registration_database_properties_items_model]
        database_registration_model_json['database_type'] = 'netezza'
        database_registration_model_json['description'] = 'Description of the external database'
        database_registration_model_json['tables'] = [database_registration_tables_items_model]
        database_registration_model_json['tags'] = ['testdatabase', 'userdatabase']
        database_registration_model_json['topics'] = [database_registration_topics_items_model]

        # Construct a model instance of DatabaseRegistration by calling from_dict on the json representation
        database_registration_model = DatabaseRegistration.from_dict(database_registration_model_json)
        assert database_registration_model != False

        # Construct a model instance of DatabaseRegistration by calling from_dict on the json representation
        database_registration_model_dict = DatabaseRegistration.from_dict(database_registration_model_json).__dict__
        database_registration_model2 = DatabaseRegistration(**database_registration_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_model == database_registration_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_model_json2 = database_registration_model.to_dict()
        assert database_registration_model_json2 == database_registration_model_json


class TestModel_DatabaseRegistrationCollection:
    """
    Test Class for DatabaseRegistrationCollection
    """

    def test_database_registration_collection_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        database_catalog_model = {}  # DatabaseCatalog
        database_catalog_model['catalog_name'] = 'hive_data'
        database_catalog_model['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        database_catalog_model['catalog_type'] = 'hive'

        database_details_model = {}  # DatabaseDetails
        database_details_model['authentication_type'] = 'LDAP'
        database_details_model['authentication_value'] = 'LDAP'
        database_details_model['broker_authentication_password'] = 'samplepassword'
        database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_details_model['broker_authentication_user'] = 'sampleuser'
        database_details_model['broker_host'] = 'samplehost'
        database_details_model['broker_port'] = 4553
        database_details_model['certificate'] = 'exampleCertificate'
        database_details_model['certificate_extension'] = 'pem'
        database_details_model['connection_method'] = 'basic, apikey'
        database_details_model['connection_mode'] = 'service_name'
        database_details_model['connection_mode_value'] = 'orclpdb'
        database_details_model['connection_type'] = 'JDBC, Arrow flight'
        database_details_model['controller_authentication_password'] = 'samplepassword'
        database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_details_model['controller_authentication_user'] = 'sampleuser'
        database_details_model['coordinator_host'] = 'samplehost'
        database_details_model['coordinator_port'] = 4553
        database_details_model['cpd_hostname'] = 'samplecpdhostname'
        database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_details_model['database_name'] = 'new_database'
        database_details_model['hostname'] = 'netezza://ps.fyre.com'
        database_details_model['hostname_in_certificate'] = 'samplehostname'
        database_details_model['hosts'] = 'abc.com:1234,xyz.com:4321'
        database_details_model['informix_server'] = 'ol_informix1410'
        database_details_model['password'] = 'samplepassword'
        database_details_model['port'] = 4353
        database_details_model['project_id'] = 'conops-bigquery'
        database_details_model['sasl'] = True
        database_details_model['sasl_mechanism'] = 'plain'
        database_details_model['schema_name'] = 'sampleSchema'
        database_details_model['schemas'] = 'redis__name'
        database_details_model['service_api_key'] = 'sampleapikey'
        database_details_model['service_hostname'] = 'api.dataplatform.dev.cloud.ibm.com'
        database_details_model['service_password'] = 'samplepassword'
        database_details_model['service_port'] = 443
        database_details_model['service_ssl'] = True
        database_details_model['service_token_url'] = 'sampletoakenurl'
        database_details_model['service_username'] = 'sampleusername'
        database_details_model['ssl'] = True
        database_details_model['tables'] = 'netezza_table_name'
        database_details_model['username'] = 'sampleuser'
        database_details_model['validate_server_certificate'] = True
        database_details_model['verify_host_name'] = True
        database_details_model['warehouse_name'] = 'samplewrehouse'

        database_registration_database_properties_items_model = {}  # DatabaseRegistrationDatabasePropertiesItems
        database_registration_database_properties_items_model['encrypt'] = True
        database_registration_database_properties_items_model['key'] = 'abc'
        database_registration_database_properties_items_model['value'] = 'xyz'

        database_registration_tables_items_model = {}  # DatabaseRegistrationTablesItems
        database_registration_tables_items_model['created_on'] = '1686792721'
        database_registration_tables_items_model['file_contents'] = 'qweerty'
        database_registration_tables_items_model['file_name'] = 'test.txt'
        database_registration_tables_items_model['schema_name'] = 'testschema123'
        database_registration_tables_items_model['table_name'] = 'customer'

        database_registration_topics_items_model = {}  # DatabaseRegistrationTopicsItems
        database_registration_topics_items_model['created_on'] = '1686792721'
        database_registration_topics_items_model['file_contents'] = 'qweerty'
        database_registration_topics_items_model['file_name'] = 'test.txt'
        database_registration_topics_items_model['topic_name'] = 'customer'

        database_registration_model = {}  # DatabaseRegistration
        database_registration_model['actions'] = ['update', 'delete']
        database_registration_model['associated_catalog'] = database_catalog_model
        database_registration_model['catalog_name'] = 'sampleCatalog'
        database_registration_model['created_by'] = 'user1@bim.com'
        database_registration_model['created_on'] = '1686792721'
        database_registration_model['database_details'] = database_details_model
        database_registration_model['database_display_name'] = 'new_database'
        database_registration_model['database_id'] = 'netezza23'
        database_registration_model['database_properties'] = [database_registration_database_properties_items_model]
        database_registration_model['database_type'] = 'netezza'
        database_registration_model['description'] = 'Description of the external database'
        database_registration_model['tables'] = [database_registration_tables_items_model]
        database_registration_model['tags'] = ['testdatabase', 'userdatabase']
        database_registration_model['topics'] = [database_registration_topics_items_model]

        # Construct a json representation of a DatabaseRegistrationCollection model
        database_registration_collection_model_json = {}
        database_registration_collection_model_json['database_registrations'] = [database_registration_model]

        # Construct a model instance of DatabaseRegistrationCollection by calling from_dict on the json representation
        database_registration_collection_model = DatabaseRegistrationCollection.from_dict(database_registration_collection_model_json)
        assert database_registration_collection_model != False

        # Construct a model instance of DatabaseRegistrationCollection by calling from_dict on the json representation
        database_registration_collection_model_dict = DatabaseRegistrationCollection.from_dict(database_registration_collection_model_json).__dict__
        database_registration_collection_model2 = DatabaseRegistrationCollection(**database_registration_collection_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_collection_model == database_registration_collection_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_collection_model_json2 = database_registration_collection_model.to_dict()
        assert database_registration_collection_model_json2 == database_registration_collection_model_json


class TestModel_DatabaseRegistrationDatabasePropertiesItems:
    """
    Test Class for DatabaseRegistrationDatabasePropertiesItems
    """

    def test_database_registration_database_properties_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationDatabasePropertiesItems
        """

        # Construct a json representation of a DatabaseRegistrationDatabasePropertiesItems model
        database_registration_database_properties_items_model_json = {}
        database_registration_database_properties_items_model_json['encrypt'] = True
        database_registration_database_properties_items_model_json['key'] = 'hive.metastore'
        database_registration_database_properties_items_model_json['value'] = 'glue'

        # Construct a model instance of DatabaseRegistrationDatabasePropertiesItems by calling from_dict on the json representation
        database_registration_database_properties_items_model = DatabaseRegistrationDatabasePropertiesItems.from_dict(database_registration_database_properties_items_model_json)
        assert database_registration_database_properties_items_model != False

        # Construct a model instance of DatabaseRegistrationDatabasePropertiesItems by calling from_dict on the json representation
        database_registration_database_properties_items_model_dict = DatabaseRegistrationDatabasePropertiesItems.from_dict(database_registration_database_properties_items_model_json).__dict__
        database_registration_database_properties_items_model2 = DatabaseRegistrationDatabasePropertiesItems(**database_registration_database_properties_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_database_properties_items_model == database_registration_database_properties_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_database_properties_items_model_json2 = database_registration_database_properties_items_model.to_dict()
        assert database_registration_database_properties_items_model_json2 == database_registration_database_properties_items_model_json


class TestModel_DatabaseRegistrationPatch:
    """
    Test Class for DatabaseRegistrationPatch
    """

    def test_database_registration_patch_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationPatch
        """

        # Construct dict forms of any model objects needed in order to build this model.

        database_registration_patch_database_details_database_properties_items_model = {}  # DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems
        database_registration_patch_database_details_database_properties_items_model['encrypt'] = True
        database_registration_patch_database_details_database_properties_items_model['key'] = 'abc'
        database_registration_patch_database_details_database_properties_items_model['value'] = 'xyz'

        database_registration_patch_database_details_model = {}  # DatabaseRegistrationPatchDatabaseDetails
        database_registration_patch_database_details_model['authentication_value'] = 'LDAP'
        database_registration_patch_database_details_model['broker_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['broker_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['broker_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['controller_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model['controller_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model['controller_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_registration_patch_database_details_model['database_properties'] = [database_registration_patch_database_details_database_properties_items_model]
        database_registration_patch_database_details_model['password'] = 'samplepassword'
        database_registration_patch_database_details_model['username'] = 'sampleuser'

        database_registration_patch_tables_items_model = {}  # DatabaseRegistrationPatchTablesItems
        database_registration_patch_tables_items_model['created_on'] = '1686792721'
        database_registration_patch_tables_items_model['file_contents'] = 'sample file content'
        database_registration_patch_tables_items_model['file_name'] = 'test.json'
        database_registration_patch_tables_items_model['schema_name'] = 'customer'
        database_registration_patch_tables_items_model['table_name'] = 'customer'

        database_registration_patch_topics_items_model = {}  # DatabaseRegistrationPatchTopicsItems
        database_registration_patch_topics_items_model['created_on'] = '1686792721'
        database_registration_patch_topics_items_model['file_contents'] = 'sample file contents'
        database_registration_patch_topics_items_model['file_name'] = 'test.json'
        database_registration_patch_topics_items_model['topic_name'] = 'customer'

        # Construct a json representation of a DatabaseRegistrationPatch model
        database_registration_patch_model_json = {}
        database_registration_patch_model_json['database_details'] = database_registration_patch_database_details_model
        database_registration_patch_model_json['database_display_name'] = 'new_database'
        database_registration_patch_model_json['description'] = 'External database description'
        database_registration_patch_model_json['tables'] = [database_registration_patch_tables_items_model]
        database_registration_patch_model_json['tags'] = ['testdatabase', 'userdatabase']
        database_registration_patch_model_json['topics'] = [database_registration_patch_topics_items_model]

        # Construct a model instance of DatabaseRegistrationPatch by calling from_dict on the json representation
        database_registration_patch_model = DatabaseRegistrationPatch.from_dict(database_registration_patch_model_json)
        assert database_registration_patch_model != False

        # Construct a model instance of DatabaseRegistrationPatch by calling from_dict on the json representation
        database_registration_patch_model_dict = DatabaseRegistrationPatch.from_dict(database_registration_patch_model_json).__dict__
        database_registration_patch_model2 = DatabaseRegistrationPatch(**database_registration_patch_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_patch_model == database_registration_patch_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_patch_model_json2 = database_registration_patch_model.to_dict()
        assert database_registration_patch_model_json2 == database_registration_patch_model_json


class TestModel_DatabaseRegistrationPatchDatabaseDetails:
    """
    Test Class for DatabaseRegistrationPatchDatabaseDetails
    """

    def test_database_registration_patch_database_details_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationPatchDatabaseDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        database_registration_patch_database_details_database_properties_items_model = {}  # DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems
        database_registration_patch_database_details_database_properties_items_model['encrypt'] = True
        database_registration_patch_database_details_database_properties_items_model['key'] = 'abc'
        database_registration_patch_database_details_database_properties_items_model['value'] = 'xyz'

        # Construct a json representation of a DatabaseRegistrationPatchDatabaseDetails model
        database_registration_patch_database_details_model_json = {}
        database_registration_patch_database_details_model_json['authentication_value'] = 'LDAP'
        database_registration_patch_database_details_model_json['broker_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model_json['broker_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model_json['broker_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model_json['controller_authentication_password'] = 'samplepassword'
        database_registration_patch_database_details_model_json['controller_authentication_type'] = 'PASSWORD'
        database_registration_patch_database_details_model_json['controller_authentication_user'] = 'sampleuser'
        database_registration_patch_database_details_model_json['credentials_key'] = 'eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImNvbm9wcy1iaWdxdWVyeSIsInByaXZhdGVfa2V5X2lkIjoiMGY3......'
        database_registration_patch_database_details_model_json['database_properties'] = [database_registration_patch_database_details_database_properties_items_model]
        database_registration_patch_database_details_model_json['password'] = 'samplepassword'
        database_registration_patch_database_details_model_json['username'] = 'sampleuser'

        # Construct a model instance of DatabaseRegistrationPatchDatabaseDetails by calling from_dict on the json representation
        database_registration_patch_database_details_model = DatabaseRegistrationPatchDatabaseDetails.from_dict(database_registration_patch_database_details_model_json)
        assert database_registration_patch_database_details_model != False

        # Construct a model instance of DatabaseRegistrationPatchDatabaseDetails by calling from_dict on the json representation
        database_registration_patch_database_details_model_dict = DatabaseRegistrationPatchDatabaseDetails.from_dict(database_registration_patch_database_details_model_json).__dict__
        database_registration_patch_database_details_model2 = DatabaseRegistrationPatchDatabaseDetails(**database_registration_patch_database_details_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_patch_database_details_model == database_registration_patch_database_details_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_patch_database_details_model_json2 = database_registration_patch_database_details_model.to_dict()
        assert database_registration_patch_database_details_model_json2 == database_registration_patch_database_details_model_json


class TestModel_DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems:
    """
    Test Class for DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems
    """

    def test_database_registration_patch_database_details_database_properties_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems
        """

        # Construct a json representation of a DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems model
        database_registration_patch_database_details_database_properties_items_model_json = {}
        database_registration_patch_database_details_database_properties_items_model_json['encrypt'] = True
        database_registration_patch_database_details_database_properties_items_model_json['key'] = 'hive.metastore'
        database_registration_patch_database_details_database_properties_items_model_json['value'] = 'glue'

        # Construct a model instance of DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems by calling from_dict on the json representation
        database_registration_patch_database_details_database_properties_items_model = DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems.from_dict(database_registration_patch_database_details_database_properties_items_model_json)
        assert database_registration_patch_database_details_database_properties_items_model != False

        # Construct a model instance of DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems by calling from_dict on the json representation
        database_registration_patch_database_details_database_properties_items_model_dict = DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems.from_dict(database_registration_patch_database_details_database_properties_items_model_json).__dict__
        database_registration_patch_database_details_database_properties_items_model2 = DatabaseRegistrationPatchDatabaseDetailsDatabasePropertiesItems(**database_registration_patch_database_details_database_properties_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_patch_database_details_database_properties_items_model == database_registration_patch_database_details_database_properties_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_patch_database_details_database_properties_items_model_json2 = database_registration_patch_database_details_database_properties_items_model.to_dict()
        assert database_registration_patch_database_details_database_properties_items_model_json2 == database_registration_patch_database_details_database_properties_items_model_json


class TestModel_DatabaseRegistrationPatchTablesItems:
    """
    Test Class for DatabaseRegistrationPatchTablesItems
    """

    def test_database_registration_patch_tables_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationPatchTablesItems
        """

        # Construct a json representation of a DatabaseRegistrationPatchTablesItems model
        database_registration_patch_tables_items_model_json = {}
        database_registration_patch_tables_items_model_json['created_on'] = '1686792721'
        database_registration_patch_tables_items_model_json['file_contents'] = 'sample file content'
        database_registration_patch_tables_items_model_json['file_name'] = 'test.json'
        database_registration_patch_tables_items_model_json['schema_name'] = 'customer'
        database_registration_patch_tables_items_model_json['table_name'] = 'customer'

        # Construct a model instance of DatabaseRegistrationPatchTablesItems by calling from_dict on the json representation
        database_registration_patch_tables_items_model = DatabaseRegistrationPatchTablesItems.from_dict(database_registration_patch_tables_items_model_json)
        assert database_registration_patch_tables_items_model != False

        # Construct a model instance of DatabaseRegistrationPatchTablesItems by calling from_dict on the json representation
        database_registration_patch_tables_items_model_dict = DatabaseRegistrationPatchTablesItems.from_dict(database_registration_patch_tables_items_model_json).__dict__
        database_registration_patch_tables_items_model2 = DatabaseRegistrationPatchTablesItems(**database_registration_patch_tables_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_patch_tables_items_model == database_registration_patch_tables_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_patch_tables_items_model_json2 = database_registration_patch_tables_items_model.to_dict()
        assert database_registration_patch_tables_items_model_json2 == database_registration_patch_tables_items_model_json


class TestModel_DatabaseRegistrationPatchTopicsItems:
    """
    Test Class for DatabaseRegistrationPatchTopicsItems
    """

    def test_database_registration_patch_topics_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationPatchTopicsItems
        """

        # Construct a json representation of a DatabaseRegistrationPatchTopicsItems model
        database_registration_patch_topics_items_model_json = {}
        database_registration_patch_topics_items_model_json['created_on'] = '1686792721'
        database_registration_patch_topics_items_model_json['file_contents'] = 'sample file contents'
        database_registration_patch_topics_items_model_json['file_name'] = 'test.json'
        database_registration_patch_topics_items_model_json['topic_name'] = 'customer'

        # Construct a model instance of DatabaseRegistrationPatchTopicsItems by calling from_dict on the json representation
        database_registration_patch_topics_items_model = DatabaseRegistrationPatchTopicsItems.from_dict(database_registration_patch_topics_items_model_json)
        assert database_registration_patch_topics_items_model != False

        # Construct a model instance of DatabaseRegistrationPatchTopicsItems by calling from_dict on the json representation
        database_registration_patch_topics_items_model_dict = DatabaseRegistrationPatchTopicsItems.from_dict(database_registration_patch_topics_items_model_json).__dict__
        database_registration_patch_topics_items_model2 = DatabaseRegistrationPatchTopicsItems(**database_registration_patch_topics_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_patch_topics_items_model == database_registration_patch_topics_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_patch_topics_items_model_json2 = database_registration_patch_topics_items_model.to_dict()
        assert database_registration_patch_topics_items_model_json2 == database_registration_patch_topics_items_model_json


class TestModel_DatabaseRegistrationPrototypeDatabasePropertiesItems:
    """
    Test Class for DatabaseRegistrationPrototypeDatabasePropertiesItems
    """

    def test_database_registration_prototype_database_properties_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationPrototypeDatabasePropertiesItems
        """

        # Construct a json representation of a DatabaseRegistrationPrototypeDatabasePropertiesItems model
        database_registration_prototype_database_properties_items_model_json = {}
        database_registration_prototype_database_properties_items_model_json['encrypt'] = True
        database_registration_prototype_database_properties_items_model_json['key'] = 'hive.metastore'
        database_registration_prototype_database_properties_items_model_json['value'] = 'glue'

        # Construct a model instance of DatabaseRegistrationPrototypeDatabasePropertiesItems by calling from_dict on the json representation
        database_registration_prototype_database_properties_items_model = DatabaseRegistrationPrototypeDatabasePropertiesItems.from_dict(database_registration_prototype_database_properties_items_model_json)
        assert database_registration_prototype_database_properties_items_model != False

        # Construct a model instance of DatabaseRegistrationPrototypeDatabasePropertiesItems by calling from_dict on the json representation
        database_registration_prototype_database_properties_items_model_dict = DatabaseRegistrationPrototypeDatabasePropertiesItems.from_dict(database_registration_prototype_database_properties_items_model_json).__dict__
        database_registration_prototype_database_properties_items_model2 = DatabaseRegistrationPrototypeDatabasePropertiesItems(**database_registration_prototype_database_properties_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_prototype_database_properties_items_model == database_registration_prototype_database_properties_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_prototype_database_properties_items_model_json2 = database_registration_prototype_database_properties_items_model.to_dict()
        assert database_registration_prototype_database_properties_items_model_json2 == database_registration_prototype_database_properties_items_model_json


class TestModel_DatabaseRegistrationTablesItems:
    """
    Test Class for DatabaseRegistrationTablesItems
    """

    def test_database_registration_tables_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationTablesItems
        """

        # Construct a json representation of a DatabaseRegistrationTablesItems model
        database_registration_tables_items_model_json = {}
        database_registration_tables_items_model_json['created_on'] = '1686792721'
        database_registration_tables_items_model_json['file_contents'] = 'sample file content'
        database_registration_tables_items_model_json['file_name'] = 'test.json'
        database_registration_tables_items_model_json['schema_name'] = 'customer'
        database_registration_tables_items_model_json['table_name'] = 'customer'

        # Construct a model instance of DatabaseRegistrationTablesItems by calling from_dict on the json representation
        database_registration_tables_items_model = DatabaseRegistrationTablesItems.from_dict(database_registration_tables_items_model_json)
        assert database_registration_tables_items_model != False

        # Construct a model instance of DatabaseRegistrationTablesItems by calling from_dict on the json representation
        database_registration_tables_items_model_dict = DatabaseRegistrationTablesItems.from_dict(database_registration_tables_items_model_json).__dict__
        database_registration_tables_items_model2 = DatabaseRegistrationTablesItems(**database_registration_tables_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_tables_items_model == database_registration_tables_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_tables_items_model_json2 = database_registration_tables_items_model.to_dict()
        assert database_registration_tables_items_model_json2 == database_registration_tables_items_model_json


class TestModel_DatabaseRegistrationTopicsItems:
    """
    Test Class for DatabaseRegistrationTopicsItems
    """

    def test_database_registration_topics_items_serialization(self):
        """
        Test serialization/deserialization for DatabaseRegistrationTopicsItems
        """

        # Construct a json representation of a DatabaseRegistrationTopicsItems model
        database_registration_topics_items_model_json = {}
        database_registration_topics_items_model_json['created_on'] = '1686792721'
        database_registration_topics_items_model_json['file_contents'] = 'sample file content'
        database_registration_topics_items_model_json['file_name'] = 'employee.json'
        database_registration_topics_items_model_json['topic_name'] = 'customer'

        # Construct a model instance of DatabaseRegistrationTopicsItems by calling from_dict on the json representation
        database_registration_topics_items_model = DatabaseRegistrationTopicsItems.from_dict(database_registration_topics_items_model_json)
        assert database_registration_topics_items_model != False

        # Construct a model instance of DatabaseRegistrationTopicsItems by calling from_dict on the json representation
        database_registration_topics_items_model_dict = DatabaseRegistrationTopicsItems.from_dict(database_registration_topics_items_model_json).__dict__
        database_registration_topics_items_model2 = DatabaseRegistrationTopicsItems(**database_registration_topics_items_model_dict)

        # Verify the model instances are equivalent
        assert database_registration_topics_items_model == database_registration_topics_items_model2

        # Convert model instance back to dict and verify no loss of data
        database_registration_topics_items_model_json2 = database_registration_topics_items_model.to_dict()
        assert database_registration_topics_items_model_json2 == database_registration_topics_items_model_json


class TestModel_Db2Engine:
    """
    Test Class for Db2Engine
    """

    def test_db2_engine_serialization(self):
        """
        Test serialization/deserialization for Db2Engine
        """

        # Construct dict forms of any model objects needed in order to build this model.

        db2_engine_details_model = {}  # Db2EngineDetails
        db2_engine_details_model['connection_string'] = '1.2.3.4'
        db2_engine_details_model['metastore_host'] = 'thrift://mh-connection-string-sample.com'

        # Construct a json representation of a Db2Engine model
        db2_engine_model_json = {}
        db2_engine_model_json['actions'] = ['update', 'delete']
        db2_engine_model_json['build_version'] = '1.0.3.0.0'
        db2_engine_model_json['created_by'] = '<username>@<domain>.com'
        db2_engine_model_json['created_on'] = 0
        db2_engine_model_json['description'] = 'db2 engine to run sql queries'
        db2_engine_model_json['engine_details'] = db2_engine_details_model
        db2_engine_model_json['engine_display_name'] = 'sample-engine'
        db2_engine_model_json['engine_id'] = 'sampleEngine123'
        db2_engine_model_json['host_name'] = 'xyz-db2-01-db2-svc'
        db2_engine_model_json['origin'] = 'ibm'
        db2_engine_model_json['port'] = 0
        db2_engine_model_json['status'] = 'REGISTERED'
        db2_engine_model_json['tags'] = ['tag1', 'tag2']
        db2_engine_model_json['type'] = 'db2'

        # Construct a model instance of Db2Engine by calling from_dict on the json representation
        db2_engine_model = Db2Engine.from_dict(db2_engine_model_json)
        assert db2_engine_model != False

        # Construct a model instance of Db2Engine by calling from_dict on the json representation
        db2_engine_model_dict = Db2Engine.from_dict(db2_engine_model_json).__dict__
        db2_engine_model2 = Db2Engine(**db2_engine_model_dict)

        # Verify the model instances are equivalent
        assert db2_engine_model == db2_engine_model2

        # Convert model instance back to dict and verify no loss of data
        db2_engine_model_json2 = db2_engine_model.to_dict()
        assert db2_engine_model_json2 == db2_engine_model_json


class TestModel_Db2EngineCollection:
    """
    Test Class for Db2EngineCollection
    """

    def test_db2_engine_collection_serialization(self):
        """
        Test serialization/deserialization for Db2EngineCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        db2_engine_details_model = {}  # Db2EngineDetails
        db2_engine_details_model['connection_string'] = 'jdbc:db2://localhost:5480/database'
        db2_engine_details_model['metastore_host'] = 'thrift://mh-connection-string-sample.com'

        db2_engine_model = {}  # Db2Engine
        db2_engine_model['actions'] = ['create']
        db2_engine_model['build_version'] = '1.0.3.0.0'
        db2_engine_model['created_by'] = 'user@test.com'
        db2_engine_model['created_on'] = 1700322436
        db2_engine_model['description'] = 'db2 engine to run sql queries'
        db2_engine_model['engine_details'] = db2_engine_details_model
        db2_engine_model['engine_display_name'] = 'db2'
        db2_engine_model['engine_id'] = 'db2505'
        db2_engine_model['host_name'] = 'xyz-db2-01-db2-svc'
        db2_engine_model['origin'] = 'external'
        db2_engine_model['port'] = 0
        db2_engine_model['status'] = 'REGISTERED'
        db2_engine_model['tags'] = ['tag1', 'tag2']
        db2_engine_model['type'] = 'db2'

        # Construct a json representation of a Db2EngineCollection model
        db2_engine_collection_model_json = {}
        db2_engine_collection_model_json['db2_engines'] = [db2_engine_model]

        # Construct a model instance of Db2EngineCollection by calling from_dict on the json representation
        db2_engine_collection_model = Db2EngineCollection.from_dict(db2_engine_collection_model_json)
        assert db2_engine_collection_model != False

        # Construct a model instance of Db2EngineCollection by calling from_dict on the json representation
        db2_engine_collection_model_dict = Db2EngineCollection.from_dict(db2_engine_collection_model_json).__dict__
        db2_engine_collection_model2 = Db2EngineCollection(**db2_engine_collection_model_dict)

        # Verify the model instances are equivalent
        assert db2_engine_collection_model == db2_engine_collection_model2

        # Convert model instance back to dict and verify no loss of data
        db2_engine_collection_model_json2 = db2_engine_collection_model.to_dict()
        assert db2_engine_collection_model_json2 == db2_engine_collection_model_json


class TestModel_Db2EngineDetails:
    """
    Test Class for Db2EngineDetails
    """

    def test_db2_engine_details_serialization(self):
        """
        Test serialization/deserialization for Db2EngineDetails
        """

        # Construct a json representation of a Db2EngineDetails model
        db2_engine_details_model_json = {}
        db2_engine_details_model_json['connection_string'] = '1.2.3.4'
        db2_engine_details_model_json['metastore_host'] = '1.2.3.4'

        # Construct a model instance of Db2EngineDetails by calling from_dict on the json representation
        db2_engine_details_model = Db2EngineDetails.from_dict(db2_engine_details_model_json)
        assert db2_engine_details_model != False

        # Construct a model instance of Db2EngineDetails by calling from_dict on the json representation
        db2_engine_details_model_dict = Db2EngineDetails.from_dict(db2_engine_details_model_json).__dict__
        db2_engine_details_model2 = Db2EngineDetails(**db2_engine_details_model_dict)

        # Verify the model instances are equivalent
        assert db2_engine_details_model == db2_engine_details_model2

        # Convert model instance back to dict and verify no loss of data
        db2_engine_details_model_json2 = db2_engine_details_model.to_dict()
        assert db2_engine_details_model_json2 == db2_engine_details_model_json


class TestModel_Db2EngineDetailsBody:
    """
    Test Class for Db2EngineDetailsBody
    """

    def test_db2_engine_details_body_serialization(self):
        """
        Test serialization/deserialization for Db2EngineDetailsBody
        """

        # Construct a json representation of a Db2EngineDetailsBody model
        db2_engine_details_body_model_json = {}
        db2_engine_details_body_model_json['connection_string'] = '1.2.3.4'

        # Construct a model instance of Db2EngineDetailsBody by calling from_dict on the json representation
        db2_engine_details_body_model = Db2EngineDetailsBody.from_dict(db2_engine_details_body_model_json)
        assert db2_engine_details_body_model != False

        # Construct a model instance of Db2EngineDetailsBody by calling from_dict on the json representation
        db2_engine_details_body_model_dict = Db2EngineDetailsBody.from_dict(db2_engine_details_body_model_json).__dict__
        db2_engine_details_body_model2 = Db2EngineDetailsBody(**db2_engine_details_body_model_dict)

        # Verify the model instances are equivalent
        assert db2_engine_details_body_model == db2_engine_details_body_model2

        # Convert model instance back to dict and verify no loss of data
        db2_engine_details_body_model_json2 = db2_engine_details_body_model.to_dict()
        assert db2_engine_details_body_model_json2 == db2_engine_details_body_model_json


class TestModel_Db2EnginePatch:
    """
    Test Class for Db2EnginePatch
    """

    def test_db2_engine_patch_serialization(self):
        """
        Test serialization/deserialization for Db2EnginePatch
        """

        # Construct a json representation of a Db2EnginePatch model
        db2_engine_patch_model_json = {}
        db2_engine_patch_model_json['description'] = 'db2 engine updated description'
        db2_engine_patch_model_json['engine_display_name'] = 'sampleEngine'
        db2_engine_patch_model_json['tags'] = ['tag1', 'tag2']

        # Construct a model instance of Db2EnginePatch by calling from_dict on the json representation
        db2_engine_patch_model = Db2EnginePatch.from_dict(db2_engine_patch_model_json)
        assert db2_engine_patch_model != False

        # Construct a model instance of Db2EnginePatch by calling from_dict on the json representation
        db2_engine_patch_model_dict = Db2EnginePatch.from_dict(db2_engine_patch_model_json).__dict__
        db2_engine_patch_model2 = Db2EnginePatch(**db2_engine_patch_model_dict)

        # Verify the model instances are equivalent
        assert db2_engine_patch_model == db2_engine_patch_model2

        # Convert model instance back to dict and verify no loss of data
        db2_engine_patch_model_json2 = db2_engine_patch_model.to_dict()
        assert db2_engine_patch_model_json2 == db2_engine_patch_model_json


class TestModel_Details:
    """
    Test Class for Details
    """

    def test_details_serialization(self):
        """
        Test serialization/deserialization for Details
        """

        # Construct dict forms of any model objects needed in order to build this model.

        external_details_model = {}  # ExternalDetails
        external_details_model['port'] = 4553
        external_details_model['hostname'] = 'external hostname'

        internal_details_model = {}  # InternalDetails
        internal_details_model['port'] = 4553
        internal_details_model['hostname'] = 'internal hostname'

        jdbc_thrift_urls_model = {}  # JdbcThriftUrls
        jdbc_thrift_urls_model['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        # Construct a json representation of a Details model
        details_model_json = {}
        details_model_json['ca_certificate'] = 'sample ca certificate'
        details_model_json['default_configs'] = {'key1': 'testString'}
        details_model_json['external'] = external_details_model
        details_model_json['grpc_api_endpoint'] = internal_details_model
        details_model_json['hostname'] = 'sample hostname'
        details_model_json['id'] = 'sample ID'
        details_model_json['instance_crn'] = 'sample instance CRN'
        details_model_json['instance_id'] = 'sample instance ID'
        details_model_json['internal'] = internal_details_model
        details_model_json['jdbc_class'] = 'com.facebook.presto.jdbc.PrestoDriver'
        details_model_json['jdbc_urls'] = jdbc_thrift_urls_model
        details_model_json['name'] = 'sample name'
        details_model_json['port'] = 4553
        details_model_json['rest_api_endpoint'] = internal_details_model
        details_model_json['spark_engine_endpoint'] = 'Spark Engine endpoint'
        details_model_json['ssl_certificate'] = 'sample ssl certificate'
        details_model_json['thrift_urls'] = jdbc_thrift_urls_model
        details_model_json['version'] = 'java'
        details_model_json['watsonx_data_application_endpoint'] = 'sample application end point'

        # Construct a model instance of Details by calling from_dict on the json representation
        details_model = Details.from_dict(details_model_json)
        assert details_model != False

        # Construct a model instance of Details by calling from_dict on the json representation
        details_model_dict = Details.from_dict(details_model_json).__dict__
        details_model2 = Details(**details_model_dict)

        # Verify the model instances are equivalent
        assert details_model == details_model2

        # Convert model instance back to dict and verify no loss of data
        details_model_json2 = details_model.to_dict()
        assert details_model_json2 == details_model_json


class TestModel_Driver:
    """
    Test Class for Driver
    """

    def test_driver_serialization(self):
        """
        Test serialization/deserialization for Driver
        """

        # Construct a json representation of a Driver model
        driver_model_json = {}
        driver_model_json['connection_type'] = 'saphana'
        driver_model_json['driver_id'] = 'saphanadriver123'
        driver_model_json['driver_name'] = 'saphanadriver-1.2.3'
        driver_model_json['driver_version'] = '1.2.3'

        # Construct a model instance of Driver by calling from_dict on the json representation
        driver_model = Driver.from_dict(driver_model_json)
        assert driver_model != False

        # Construct a model instance of Driver by calling from_dict on the json representation
        driver_model_dict = Driver.from_dict(driver_model_json).__dict__
        driver_model2 = Driver(**driver_model_dict)

        # Verify the model instances are equivalent
        assert driver_model == driver_model2

        # Convert model instance back to dict and verify no loss of data
        driver_model_json2 = driver_model.to_dict()
        assert driver_model_json2 == driver_model_json


class TestModel_Endpoint:
    """
    Test Class for Endpoint
    """

    def test_endpoint_serialization(self):
        """
        Test serialization/deserialization for Endpoint
        """

        # Construct a json representation of a Endpoint model
        endpoint_model_json = {}
        endpoint_model_json['external_host'] = 'https://cpg-svc.your-hostname.apps.your-domain.com'
        endpoint_model_json['service_type'] = 'cpg'

        # Construct a model instance of Endpoint by calling from_dict on the json representation
        endpoint_model = Endpoint.from_dict(endpoint_model_json)
        assert endpoint_model != False

        # Construct a model instance of Endpoint by calling from_dict on the json representation
        endpoint_model_dict = Endpoint.from_dict(endpoint_model_json).__dict__
        endpoint_model2 = Endpoint(**endpoint_model_dict)

        # Verify the model instances are equivalent
        assert endpoint_model == endpoint_model2

        # Convert model instance back to dict and verify no loss of data
        endpoint_model_json2 = endpoint_model.to_dict()
        assert endpoint_model_json2 == endpoint_model_json


class TestModel_EndpointCollection:
    """
    Test Class for EndpointCollection
    """

    def test_endpoint_collection_serialization(self):
        """
        Test serialization/deserialization for EndpointCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        endpoint_model = {}  # Endpoint
        endpoint_model['external_host'] = 'https://cpg-svc.your-hostname.apps.your-domain.com'
        endpoint_model['service_type'] = 'cpg'

        # Construct a json representation of a EndpointCollection model
        endpoint_collection_model_json = {}
        endpoint_collection_model_json['endpoints'] = [endpoint_model]

        # Construct a model instance of EndpointCollection by calling from_dict on the json representation
        endpoint_collection_model = EndpointCollection.from_dict(endpoint_collection_model_json)
        assert endpoint_collection_model != False

        # Construct a model instance of EndpointCollection by calling from_dict on the json representation
        endpoint_collection_model_dict = EndpointCollection.from_dict(endpoint_collection_model_json).__dict__
        endpoint_collection_model2 = EndpointCollection(**endpoint_collection_model_dict)

        # Verify the model instances are equivalent
        assert endpoint_collection_model == endpoint_collection_model2

        # Convert model instance back to dict and verify no loss of data
        endpoint_collection_model_json2 = endpoint_collection_model.to_dict()
        assert endpoint_collection_model_json2 == endpoint_collection_model_json


class TestModel_EngineDetailsBody:
    """
    Test Class for EngineDetailsBody
    """

    def test_engine_details_body_serialization(self):
        """
        Test serialization/deserialization for EngineDetailsBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a json representation of a EngineDetailsBody model
        engine_details_body_model_json = {}
        engine_details_body_model_json['api_key'] = '<api_key>'
        engine_details_body_model_json['connection_string'] = '1.2.3.4'
        engine_details_body_model_json['coordinator'] = node_description_body_model
        engine_details_body_model_json['instance_id'] = 'instance_id'
        engine_details_body_model_json['managed_by'] = 'fully/self'
        engine_details_body_model_json['size_config'] = 'starter'
        engine_details_body_model_json['worker'] = node_description_body_model

        # Construct a model instance of EngineDetailsBody by calling from_dict on the json representation
        engine_details_body_model = EngineDetailsBody.from_dict(engine_details_body_model_json)
        assert engine_details_body_model != False

        # Construct a model instance of EngineDetailsBody by calling from_dict on the json representation
        engine_details_body_model_dict = EngineDetailsBody.from_dict(engine_details_body_model_json).__dict__
        engine_details_body_model2 = EngineDetailsBody(**engine_details_body_model_dict)

        # Verify the model instances are equivalent
        assert engine_details_body_model == engine_details_body_model2

        # Convert model instance back to dict and verify no loss of data
        engine_details_body_model_json2 = engine_details_body_model.to_dict()
        assert engine_details_body_model_json2 == engine_details_body_model_json


class TestModel_EnginePropertiesLogConfiguration:
    """
    Test Class for EnginePropertiesLogConfiguration
    """

    def test_engine_properties_log_configuration_serialization(self):
        """
        Test serialization/deserialization for EnginePropertiesLogConfiguration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a json representation of a EnginePropertiesLogConfiguration model
        engine_properties_log_configuration_model_json = {}
        engine_properties_log_configuration_model_json['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model_json['worker'] = node_description_body_model

        # Construct a model instance of EnginePropertiesLogConfiguration by calling from_dict on the json representation
        engine_properties_log_configuration_model = EnginePropertiesLogConfiguration.from_dict(engine_properties_log_configuration_model_json)
        assert engine_properties_log_configuration_model != False

        # Construct a model instance of EnginePropertiesLogConfiguration by calling from_dict on the json representation
        engine_properties_log_configuration_model_dict = EnginePropertiesLogConfiguration.from_dict(engine_properties_log_configuration_model_json).__dict__
        engine_properties_log_configuration_model2 = EnginePropertiesLogConfiguration(**engine_properties_log_configuration_model_dict)

        # Verify the model instances are equivalent
        assert engine_properties_log_configuration_model == engine_properties_log_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        engine_properties_log_configuration_model_json2 = engine_properties_log_configuration_model.to_dict()
        assert engine_properties_log_configuration_model_json2 == engine_properties_log_configuration_model_json


class TestModel_EnginePropertiesOaiGen1Configuration:
    """
    Test Class for EnginePropertiesOaiGen1Configuration
    """

    def test_engine_properties_oai_gen1_configuration_serialization(self):
        """
        Test serialization/deserialization for EnginePropertiesOaiGen1Configuration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a json representation of a EnginePropertiesOaiGen1Configuration model
        engine_properties_oai_gen1_configuration_model_json = {}
        engine_properties_oai_gen1_configuration_model_json['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model_json['worker'] = node_description_body_model

        # Construct a model instance of EnginePropertiesOaiGen1Configuration by calling from_dict on the json representation
        engine_properties_oai_gen1_configuration_model = EnginePropertiesOaiGen1Configuration.from_dict(engine_properties_oai_gen1_configuration_model_json)
        assert engine_properties_oai_gen1_configuration_model != False

        # Construct a model instance of EnginePropertiesOaiGen1Configuration by calling from_dict on the json representation
        engine_properties_oai_gen1_configuration_model_dict = EnginePropertiesOaiGen1Configuration.from_dict(engine_properties_oai_gen1_configuration_model_json).__dict__
        engine_properties_oai_gen1_configuration_model2 = EnginePropertiesOaiGen1Configuration(**engine_properties_oai_gen1_configuration_model_dict)

        # Verify the model instances are equivalent
        assert engine_properties_oai_gen1_configuration_model == engine_properties_oai_gen1_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        engine_properties_oai_gen1_configuration_model_json2 = engine_properties_oai_gen1_configuration_model.to_dict()
        assert engine_properties_oai_gen1_configuration_model_json2 == engine_properties_oai_gen1_configuration_model_json


class TestModel_EnginePropertiesOaiGen1Jvm:
    """
    Test Class for EnginePropertiesOaiGen1Jvm
    """

    def test_engine_properties_oai_gen1_jvm_serialization(self):
        """
        Test serialization/deserialization for EnginePropertiesOaiGen1Jvm
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a json representation of a EnginePropertiesOaiGen1Jvm model
        engine_properties_oai_gen1_jvm_model_json = {}
        engine_properties_oai_gen1_jvm_model_json['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model_json['worker'] = node_description_body_model

        # Construct a model instance of EnginePropertiesOaiGen1Jvm by calling from_dict on the json representation
        engine_properties_oai_gen1_jvm_model = EnginePropertiesOaiGen1Jvm.from_dict(engine_properties_oai_gen1_jvm_model_json)
        assert engine_properties_oai_gen1_jvm_model != False

        # Construct a model instance of EnginePropertiesOaiGen1Jvm by calling from_dict on the json representation
        engine_properties_oai_gen1_jvm_model_dict = EnginePropertiesOaiGen1Jvm.from_dict(engine_properties_oai_gen1_jvm_model_json).__dict__
        engine_properties_oai_gen1_jvm_model2 = EnginePropertiesOaiGen1Jvm(**engine_properties_oai_gen1_jvm_model_dict)

        # Verify the model instances are equivalent
        assert engine_properties_oai_gen1_jvm_model == engine_properties_oai_gen1_jvm_model2

        # Convert model instance back to dict and verify no loss of data
        engine_properties_oai_gen1_jvm_model_json2 = engine_properties_oai_gen1_jvm_model.to_dict()
        assert engine_properties_oai_gen1_jvm_model_json2 == engine_properties_oai_gen1_jvm_model_json


class TestModel_EnginePropertiesOaiGenConfiguration:
    """
    Test Class for EnginePropertiesOaiGenConfiguration
    """

    def test_engine_properties_oai_gen_configuration_serialization(self):
        """
        Test serialization/deserialization for EnginePropertiesOaiGenConfiguration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_node_description_body_model = {}  # PrestissimoNodeDescriptionBody
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        # Construct a json representation of a EnginePropertiesOaiGenConfiguration model
        engine_properties_oai_gen_configuration_model_json = {}
        engine_properties_oai_gen_configuration_model_json['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model_json['worker'] = prestissimo_node_description_body_model

        # Construct a model instance of EnginePropertiesOaiGenConfiguration by calling from_dict on the json representation
        engine_properties_oai_gen_configuration_model = EnginePropertiesOaiGenConfiguration.from_dict(engine_properties_oai_gen_configuration_model_json)
        assert engine_properties_oai_gen_configuration_model != False

        # Construct a model instance of EnginePropertiesOaiGenConfiguration by calling from_dict on the json representation
        engine_properties_oai_gen_configuration_model_dict = EnginePropertiesOaiGenConfiguration.from_dict(engine_properties_oai_gen_configuration_model_json).__dict__
        engine_properties_oai_gen_configuration_model2 = EnginePropertiesOaiGenConfiguration(**engine_properties_oai_gen_configuration_model_dict)

        # Verify the model instances are equivalent
        assert engine_properties_oai_gen_configuration_model == engine_properties_oai_gen_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        engine_properties_oai_gen_configuration_model_json2 = engine_properties_oai_gen_configuration_model.to_dict()
        assert engine_properties_oai_gen_configuration_model_json2 == engine_properties_oai_gen_configuration_model_json


class TestModel_EngineServiceDetailsCollection:
    """
    Test Class for EngineServiceDetailsCollection
    """

    def test_engine_service_details_collection_serialization(self):
        """
        Test serialization/deserialization for EngineServiceDetailsCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        external_details_model = {}  # ExternalDetails
        external_details_model['port'] = 4553
        external_details_model['hostname'] = 'external hostname'

        internal_details_model = {}  # InternalDetails
        internal_details_model['port'] = 4553
        internal_details_model['hostname'] = 'internal hostname'

        jdbc_thrift_urls_model = {}  # JdbcThriftUrls
        jdbc_thrift_urls_model['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        details_model = {}  # Details
        details_model['ca_certificate'] = 'sample ca certificate'
        details_model['default_configs'] = {'key1': 'testString'}
        details_model['external'] = external_details_model
        details_model['grpc_api_endpoint'] = internal_details_model
        details_model['hostname'] = 'sample hostname'
        details_model['id'] = 'sample ID'
        details_model['instance_crn'] = 'sample instance CRN'
        details_model['instance_id'] = 'sample instance ID'
        details_model['internal'] = internal_details_model
        details_model['jdbc_class'] = 'com.facebook.presto.jdbc.PrestoDriver'
        details_model['jdbc_urls'] = jdbc_thrift_urls_model
        details_model['name'] = 'sample name'
        details_model['port'] = 4553
        details_model['rest_api_endpoint'] = internal_details_model
        details_model['spark_engine_endpoint'] = 'Spark Engine endpoint'
        details_model['ssl_certificate'] = 'sample ssl certificate'
        details_model['thrift_urls'] = jdbc_thrift_urls_model
        details_model['version'] = 'java'
        details_model['watsonx_data_application_endpoint'] = 'sample application end point'

        # Construct a json representation of a EngineServiceDetailsCollection model
        engine_service_details_collection_model_json = {}
        engine_service_details_collection_model_json['details'] = [details_model]
        engine_service_details_collection_model_json['type'] = 'presto'

        # Construct a model instance of EngineServiceDetailsCollection by calling from_dict on the json representation
        engine_service_details_collection_model = EngineServiceDetailsCollection.from_dict(engine_service_details_collection_model_json)
        assert engine_service_details_collection_model != False

        # Construct a model instance of EngineServiceDetailsCollection by calling from_dict on the json representation
        engine_service_details_collection_model_dict = EngineServiceDetailsCollection.from_dict(engine_service_details_collection_model_json).__dict__
        engine_service_details_collection_model2 = EngineServiceDetailsCollection(**engine_service_details_collection_model_dict)

        # Verify the model instances are equivalent
        assert engine_service_details_collection_model == engine_service_details_collection_model2

        # Convert model instance back to dict and verify no loss of data
        engine_service_details_collection_model_json2 = engine_service_details_collection_model.to_dict()
        assert engine_service_details_collection_model_json2 == engine_service_details_collection_model_json


class TestModel_EnginesServicesDetails:
    """
    Test Class for EnginesServicesDetails
    """

    def test_engines_services_details_serialization(self):
        """
        Test serialization/deserialization for EnginesServicesDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        external_details_model = {}  # ExternalDetails
        external_details_model['port'] = 4553
        external_details_model['hostname'] = 'external hostname'

        internal_details_model = {}  # InternalDetails
        internal_details_model['port'] = 4553
        internal_details_model['hostname'] = 'internal hostname'

        jdbc_thrift_urls_model = {}  # JdbcThriftUrls
        jdbc_thrift_urls_model['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        details_model = {}  # Details
        details_model['ca_certificate'] = 'sample ca certificate'
        details_model['default_configs'] = {'key1': 'testString'}
        details_model['external'] = external_details_model
        details_model['grpc_api_endpoint'] = internal_details_model
        details_model['hostname'] = 'sample hostname'
        details_model['id'] = 'sample ID'
        details_model['instance_crn'] = 'sample instance CRN'
        details_model['instance_id'] = 'sample instance ID'
        details_model['internal'] = internal_details_model
        details_model['jdbc_class'] = 'com.facebook.presto.jdbc.PrestoDriver'
        details_model['jdbc_urls'] = jdbc_thrift_urls_model
        details_model['name'] = 'sample name'
        details_model['port'] = 4553
        details_model['rest_api_endpoint'] = internal_details_model
        details_model['spark_engine_endpoint'] = 'Spark Engine endpoint'
        details_model['ssl_certificate'] = 'sample ssl certificate'
        details_model['thrift_urls'] = jdbc_thrift_urls_model
        details_model['version'] = 'java'
        details_model['watsonx_data_application_endpoint'] = 'sample application end point'

        connection_properties_details_properties_connection_items_model = {}  # ConnectionPropertiesDetailsPropertiesConnectionItems
        connection_properties_details_properties_connection_items_model['name'] = 'host'
        connection_properties_details_properties_connection_items_model['value'] = 'sample_value'

        connection_properties_details_properties_model = {}  # ConnectionPropertiesDetailsProperties
        connection_properties_details_properties_model['connection'] = [connection_properties_details_properties_connection_items_model]

        connection_properties_details_model = {}  # ConnectionPropertiesDetails
        connection_properties_details_model['connection_name'] = 'presto-01'
        connection_properties_details_model['details'] = details_model
        connection_properties_details_model['properties'] = connection_properties_details_properties_model
        connection_properties_details_model['type'] = 'presto'

        # Construct a json representation of a EnginesServicesDetails model
        engines_services_details_model_json = {}
        engines_services_details_model_json['engines_services'] = [connection_properties_details_model]

        # Construct a model instance of EnginesServicesDetails by calling from_dict on the json representation
        engines_services_details_model = EnginesServicesDetails.from_dict(engines_services_details_model_json)
        assert engines_services_details_model != False

        # Construct a model instance of EnginesServicesDetails by calling from_dict on the json representation
        engines_services_details_model_dict = EnginesServicesDetails.from_dict(engines_services_details_model_json).__dict__
        engines_services_details_model2 = EnginesServicesDetails(**engines_services_details_model_dict)

        # Verify the model instances are equivalent
        assert engines_services_details_model == engines_services_details_model2

        # Convert model instance back to dict and verify no loss of data
        engines_services_details_model_json2 = engines_services_details_model.to_dict()
        assert engines_services_details_model_json2 == engines_services_details_model_json


class TestModel_EnrichmentAsset:
    """
    Test Class for EnrichmentAsset
    """

    def test_enrichment_asset_serialization(self):
        """
        Test serialization/deserialization for EnrichmentAsset
        """

        # Construct a json representation of a EnrichmentAsset model
        enrichment_asset_model_json = {}
        enrichment_asset_model_json['asset_attributes'] = ['testString']
        enrichment_asset_model_json['asset_id'] = 'ee0383b9-dcab-4c1a-b03d-bf521837b6ed'
        enrichment_asset_model_json['asset_name'] = 'newtable'
        enrichment_asset_model_json['resource_key'] = '0000:0000:0000:0000:0000:FFFF:9EB0:04E2|31134|:/iceberg_data/new_schema/sampletable'
        enrichment_asset_model_json['schema_name'] = 'sampleschema'

        # Construct a model instance of EnrichmentAsset by calling from_dict on the json representation
        enrichment_asset_model = EnrichmentAsset.from_dict(enrichment_asset_model_json)
        assert enrichment_asset_model != False

        # Construct a model instance of EnrichmentAsset by calling from_dict on the json representation
        enrichment_asset_model_dict = EnrichmentAsset.from_dict(enrichment_asset_model_json).__dict__
        enrichment_asset_model2 = EnrichmentAsset(**enrichment_asset_model_dict)

        # Verify the model instances are equivalent
        assert enrichment_asset_model == enrichment_asset_model2

        # Convert model instance back to dict and verify no loss of data
        enrichment_asset_model_json2 = enrichment_asset_model.to_dict()
        assert enrichment_asset_model_json2 == enrichment_asset_model_json


class TestModel_EnrichmentObj:
    """
    Test Class for EnrichmentObj
    """

    def test_enrichment_obj_serialization(self):
        """
        Test serialization/deserialization for EnrichmentObj
        """

        # Construct a json representation of a EnrichmentObj model
        enrichment_obj_model_json = {}
        enrichment_obj_model_json['catalog'] = 'iceberg_data'
        enrichment_obj_model_json['operation'] = 'create'
        enrichment_obj_model_json['schema'] = 'testString'
        enrichment_obj_model_json['tables'] = ['testString']

        # Construct a model instance of EnrichmentObj by calling from_dict on the json representation
        enrichment_obj_model = EnrichmentObj.from_dict(enrichment_obj_model_json)
        assert enrichment_obj_model != False

        # Construct a model instance of EnrichmentObj by calling from_dict on the json representation
        enrichment_obj_model_dict = EnrichmentObj.from_dict(enrichment_obj_model_json).__dict__
        enrichment_obj_model2 = EnrichmentObj(**enrichment_obj_model_dict)

        # Verify the model instances are equivalent
        assert enrichment_obj_model == enrichment_obj_model2

        # Convert model instance back to dict and verify no loss of data
        enrichment_obj_model_json2 = enrichment_obj_model.to_dict()
        assert enrichment_obj_model_json2 == enrichment_obj_model_json


class TestModel_ErrorObj:
    """
    Test Class for ErrorObj
    """

    def test_error_obj_serialization(self):
        """
        Test serialization/deserialization for ErrorObj
        """

        # Construct a json representation of a ErrorObj model
        error_obj_model_json = {}
        error_obj_model_json['code'] = 'unable_to_perform'
        error_obj_model_json['message'] = 'Failed to process integration settings for watsonx.data instance'

        # Construct a model instance of ErrorObj by calling from_dict on the json representation
        error_obj_model = ErrorObj.from_dict(error_obj_model_json)
        assert error_obj_model != False

        # Construct a model instance of ErrorObj by calling from_dict on the json representation
        error_obj_model_dict = ErrorObj.from_dict(error_obj_model_json).__dict__
        error_obj_model2 = ErrorObj(**error_obj_model_dict)

        # Verify the model instances are equivalent
        assert error_obj_model == error_obj_model2

        # Convert model instance back to dict and verify no loss of data
        error_obj_model_json2 = error_obj_model.to_dict()
        assert error_obj_model_json2 == error_obj_model_json


class TestModel_ExecuteQueryCreatedBody:
    """
    Test Class for ExecuteQueryCreatedBody
    """

    def test_execute_query_created_body_serialization(self):
        """
        Test serialization/deserialization for ExecuteQueryCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        result_execute_query_model = {}  # ResultExecuteQuery
        result_execute_query_model['result'] = [{'key1': 'testString'}]

        # Construct a json representation of a ExecuteQueryCreatedBody model
        execute_query_created_body_model_json = {}
        execute_query_created_body_model_json['response'] = result_execute_query_model

        # Construct a model instance of ExecuteQueryCreatedBody by calling from_dict on the json representation
        execute_query_created_body_model = ExecuteQueryCreatedBody.from_dict(execute_query_created_body_model_json)
        assert execute_query_created_body_model != False

        # Construct a model instance of ExecuteQueryCreatedBody by calling from_dict on the json representation
        execute_query_created_body_model_dict = ExecuteQueryCreatedBody.from_dict(execute_query_created_body_model_json).__dict__
        execute_query_created_body_model2 = ExecuteQueryCreatedBody(**execute_query_created_body_model_dict)

        # Verify the model instances are equivalent
        assert execute_query_created_body_model == execute_query_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        execute_query_created_body_model_json2 = execute_query_created_body_model.to_dict()
        assert execute_query_created_body_model_json2 == execute_query_created_body_model_json


class TestModel_ExternalDetails:
    """
    Test Class for ExternalDetails
    """

    def test_external_details_serialization(self):
        """
        Test serialization/deserialization for ExternalDetails
        """

        # Construct a json representation of a ExternalDetails model
        external_details_model_json = {}
        external_details_model_json['port'] = 4553
        external_details_model_json['hostname'] = 'external hostname'

        # Construct a model instance of ExternalDetails by calling from_dict on the json representation
        external_details_model = ExternalDetails.from_dict(external_details_model_json)
        assert external_details_model != False

        # Construct a model instance of ExternalDetails by calling from_dict on the json representation
        external_details_model_dict = ExternalDetails.from_dict(external_details_model_json).__dict__
        external_details_model2 = ExternalDetails(**external_details_model_dict)

        # Verify the model instances are equivalent
        assert external_details_model == external_details_model2

        # Convert model instance back to dict and verify no loss of data
        external_details_model_json2 = external_details_model.to_dict()
        assert external_details_model_json2 == external_details_model_json


class TestModel_GenerateBenchmarkReportOKBody:
    """
    Test Class for GenerateBenchmarkReportOKBody
    """

    def test_generate_benchmark_report_ok_body_serialization(self):
        """
        Test serialization/deserialization for GenerateBenchmarkReportOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        generate_benchmark_report_ok_body_response_model = {}  # GenerateBenchmarkReportOKBodyResponse
        generate_benchmark_report_ok_body_response_model['message'] = 'bucket benchmarking is in progress.Trigger /generate_benchmark_report/status?req_id=<xx> for the status'
        generate_benchmark_report_ok_body_response_model['req_id'] = 'c3a3dbd4-98f8-4268-9128-12339ca8566b'
        generate_benchmark_report_ok_body_response_model['status'] = 'success'

        # Construct a json representation of a GenerateBenchmarkReportOKBody model
        generate_benchmark_report_ok_body_model_json = {}
        generate_benchmark_report_ok_body_model_json['response'] = generate_benchmark_report_ok_body_response_model

        # Construct a model instance of GenerateBenchmarkReportOKBody by calling from_dict on the json representation
        generate_benchmark_report_ok_body_model = GenerateBenchmarkReportOKBody.from_dict(generate_benchmark_report_ok_body_model_json)
        assert generate_benchmark_report_ok_body_model != False

        # Construct a model instance of GenerateBenchmarkReportOKBody by calling from_dict on the json representation
        generate_benchmark_report_ok_body_model_dict = GenerateBenchmarkReportOKBody.from_dict(generate_benchmark_report_ok_body_model_json).__dict__
        generate_benchmark_report_ok_body_model2 = GenerateBenchmarkReportOKBody(**generate_benchmark_report_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert generate_benchmark_report_ok_body_model == generate_benchmark_report_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        generate_benchmark_report_ok_body_model_json2 = generate_benchmark_report_ok_body_model.to_dict()
        assert generate_benchmark_report_ok_body_model_json2 == generate_benchmark_report_ok_body_model_json


class TestModel_GenerateBenchmarkReportOKBodyResponse:
    """
    Test Class for GenerateBenchmarkReportOKBodyResponse
    """

    def test_generate_benchmark_report_ok_body_response_serialization(self):
        """
        Test serialization/deserialization for GenerateBenchmarkReportOKBodyResponse
        """

        # Construct a json representation of a GenerateBenchmarkReportOKBodyResponse model
        generate_benchmark_report_ok_body_response_model_json = {}
        generate_benchmark_report_ok_body_response_model_json['message'] = 'testString'
        generate_benchmark_report_ok_body_response_model_json['req_id'] = 'testString'
        generate_benchmark_report_ok_body_response_model_json['status'] = 'testString'

        # Construct a model instance of GenerateBenchmarkReportOKBodyResponse by calling from_dict on the json representation
        generate_benchmark_report_ok_body_response_model = GenerateBenchmarkReportOKBodyResponse.from_dict(generate_benchmark_report_ok_body_response_model_json)
        assert generate_benchmark_report_ok_body_response_model != False

        # Construct a model instance of GenerateBenchmarkReportOKBodyResponse by calling from_dict on the json representation
        generate_benchmark_report_ok_body_response_model_dict = GenerateBenchmarkReportOKBodyResponse.from_dict(generate_benchmark_report_ok_body_response_model_json).__dict__
        generate_benchmark_report_ok_body_response_model2 = GenerateBenchmarkReportOKBodyResponse(**generate_benchmark_report_ok_body_response_model_dict)

        # Verify the model instances are equivalent
        assert generate_benchmark_report_ok_body_response_model == generate_benchmark_report_ok_body_response_model2

        # Convert model instance back to dict and verify no loss of data
        generate_benchmark_report_ok_body_response_model_json2 = generate_benchmark_report_ok_body_response_model.to_dict()
        assert generate_benchmark_report_ok_body_response_model_json2 == generate_benchmark_report_ok_body_response_model_json


class TestModel_GenerateEngineDumpOKBody:
    """
    Test Class for GenerateEngineDumpOKBody
    """

    def test_generate_engine_dump_ok_body_serialization(self):
        """
        Test serialization/deserialization for GenerateEngineDumpOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        generate_engine_dump_ok_body_response_model = {}  # GenerateEngineDumpOKBodyResponse
        generate_engine_dump_ok_body_response_model['message'] = 'Dump creation trigerred for the pod <pod name>'
        generate_engine_dump_ok_body_response_model['status'] = 'success'

        # Construct a json representation of a GenerateEngineDumpOKBody model
        generate_engine_dump_ok_body_model_json = {}
        generate_engine_dump_ok_body_model_json['response'] = generate_engine_dump_ok_body_response_model

        # Construct a model instance of GenerateEngineDumpOKBody by calling from_dict on the json representation
        generate_engine_dump_ok_body_model = GenerateEngineDumpOKBody.from_dict(generate_engine_dump_ok_body_model_json)
        assert generate_engine_dump_ok_body_model != False

        # Construct a model instance of GenerateEngineDumpOKBody by calling from_dict on the json representation
        generate_engine_dump_ok_body_model_dict = GenerateEngineDumpOKBody.from_dict(generate_engine_dump_ok_body_model_json).__dict__
        generate_engine_dump_ok_body_model2 = GenerateEngineDumpOKBody(**generate_engine_dump_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert generate_engine_dump_ok_body_model == generate_engine_dump_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        generate_engine_dump_ok_body_model_json2 = generate_engine_dump_ok_body_model.to_dict()
        assert generate_engine_dump_ok_body_model_json2 == generate_engine_dump_ok_body_model_json


class TestModel_GenerateEngineDumpOKBodyResponse:
    """
    Test Class for GenerateEngineDumpOKBodyResponse
    """

    def test_generate_engine_dump_ok_body_response_serialization(self):
        """
        Test serialization/deserialization for GenerateEngineDumpOKBodyResponse
        """

        # Construct a json representation of a GenerateEngineDumpOKBodyResponse model
        generate_engine_dump_ok_body_response_model_json = {}
        generate_engine_dump_ok_body_response_model_json['message'] = 'testString'
        generate_engine_dump_ok_body_response_model_json['status'] = 'testString'

        # Construct a model instance of GenerateEngineDumpOKBodyResponse by calling from_dict on the json representation
        generate_engine_dump_ok_body_response_model = GenerateEngineDumpOKBodyResponse.from_dict(generate_engine_dump_ok_body_response_model_json)
        assert generate_engine_dump_ok_body_response_model != False

        # Construct a model instance of GenerateEngineDumpOKBodyResponse by calling from_dict on the json representation
        generate_engine_dump_ok_body_response_model_dict = GenerateEngineDumpOKBodyResponse.from_dict(generate_engine_dump_ok_body_response_model_json).__dict__
        generate_engine_dump_ok_body_response_model2 = GenerateEngineDumpOKBodyResponse(**generate_engine_dump_ok_body_response_model_dict)

        # Verify the model instances are equivalent
        assert generate_engine_dump_ok_body_response_model == generate_engine_dump_ok_body_response_model2

        # Convert model instance back to dict and verify no loss of data
        generate_engine_dump_ok_body_response_model_json2 = generate_engine_dump_ok_body_response_model.to_dict()
        assert generate_engine_dump_ok_body_response_model_json2 == generate_engine_dump_ok_body_response_model_json


class TestModel_GlossaryObject:
    """
    Test Class for GlossaryObject
    """

    def test_glossary_object_serialization(self):
        """
        Test serialization/deserialization for GlossaryObject
        """

        # Construct a json representation of a GlossaryObject model
        glossary_object_model_json = {}
        glossary_object_model_json['description'] = 'First Name'
        glossary_object_model_json['name'] = 'Name'

        # Construct a model instance of GlossaryObject by calling from_dict on the json representation
        glossary_object_model = GlossaryObject.from_dict(glossary_object_model_json)
        assert glossary_object_model != False

        # Construct a model instance of GlossaryObject by calling from_dict on the json representation
        glossary_object_model_dict = GlossaryObject.from_dict(glossary_object_model_json).__dict__
        glossary_object_model2 = GlossaryObject(**glossary_object_model_dict)

        # Verify the model instances are equivalent
        assert glossary_object_model == glossary_object_model2

        # Convert model instance back to dict and verify no loss of data
        glossary_object_model_json2 = glossary_object_model.to_dict()
        assert glossary_object_model_json2 == glossary_object_model_json


class TestModel_HdfsStorageRegistration:
    """
    Test Class for HdfsStorageRegistration
    """

    def test_hdfs_storage_registration_serialization(self):
        """
        Test serialization/deserialization for HdfsStorageRegistration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        bucket_catalog_model = {}  # BucketCatalog
        bucket_catalog_model['catalog_name'] = 'hive_data'
        bucket_catalog_model['catalog_tags'] = ['catalog_tag_1', 'catalog_tag_2']
        bucket_catalog_model['catalog_type'] = 'hive'

        # Construct a json representation of a HdfsStorageRegistration model
        hdfs_storage_registration_model_json = {}
        hdfs_storage_registration_model_json['actions'] = ['read', 'update']
        hdfs_storage_registration_model_json['associated_catalog'] = bucket_catalog_model
        hdfs_storage_registration_model_json['bucket_display_name'] = 'sample hdfs displayname'
        hdfs_storage_registration_model_json['bucket_id'] = 'hdfs123'
        hdfs_storage_registration_model_json['bucket_type'] = 'hdfs'
        hdfs_storage_registration_model_json['created_by'] = '<username>@<domain>.com'
        hdfs_storage_registration_model_json['created_on'] = '1686120645'
        hdfs_storage_registration_model_json['description'] = 'HDFS description for storage'
        hdfs_storage_registration_model_json['managed_by'] = 'customer'
        hdfs_storage_registration_model_json['state'] = 'active'
        hdfs_storage_registration_model_json['tags'] = ['test', 'write customer data\'']

        # Construct a model instance of HdfsStorageRegistration by calling from_dict on the json representation
        hdfs_storage_registration_model = HdfsStorageRegistration.from_dict(hdfs_storage_registration_model_json)
        assert hdfs_storage_registration_model != False

        # Construct a model instance of HdfsStorageRegistration by calling from_dict on the json representation
        hdfs_storage_registration_model_dict = HdfsStorageRegistration.from_dict(hdfs_storage_registration_model_json).__dict__
        hdfs_storage_registration_model2 = HdfsStorageRegistration(**hdfs_storage_registration_model_dict)

        # Verify the model instances are equivalent
        assert hdfs_storage_registration_model == hdfs_storage_registration_model2

        # Convert model instance back to dict and verify no loss of data
        hdfs_storage_registration_model_json2 = hdfs_storage_registration_model.to_dict()
        assert hdfs_storage_registration_model_json2 == hdfs_storage_registration_model_json


class TestModel_IngestionJob:
    """
    Test Class for IngestionJob
    """

    def test_ingestion_job_serialization(self):
        """
        Test serialization/deserialization for IngestionJob
        """

        # Construct dict forms of any model objects needed in order to build this model.

        ingestion_job_csv_property_model = {}  # IngestionJobCsvProperty
        ingestion_job_csv_property_model['encoding'] = 'utf-8'
        ingestion_job_csv_property_model['escape_character'] = '|'
        ingestion_job_csv_property_model['field_delimiter'] = ','
        ingestion_job_csv_property_model['header'] = True
        ingestion_job_csv_property_model['line_delimiter'] = '\n'

        ingestion_job_execute_config_model = {}  # IngestionJobExecuteConfig
        ingestion_job_execute_config_model['driver_cores'] = 1
        ingestion_job_execute_config_model['driver_memory'] = '2G'
        ingestion_job_execute_config_model['executor_cores'] = 1
        ingestion_job_execute_config_model['executor_memory'] = '2G'
        ingestion_job_execute_config_model['num_executors'] = 1

        # Construct a json representation of a IngestionJob model
        ingestion_job_model_json = {}
        ingestion_job_model_json['create_if_not_exist'] = False
        ingestion_job_model_json['csv_property'] = ingestion_job_csv_property_model
        ingestion_job_model_json['details'] = 'Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory'
        ingestion_job_model_json['end_timestamp'] = '1685088775'
        ingestion_job_model_json['engine_id'] = 'spark123'
        ingestion_job_model_json['engine_name'] = 'sparkdemo'
        ingestion_job_model_json['execute_config'] = ingestion_job_execute_config_model
        ingestion_job_model_json['instance_id'] = '1684432229673971'
        ingestion_job_model_json['job_id'] = 'ingestion-1699459946935'
        ingestion_job_model_json['partition_by'] = 'col1, col2'
        ingestion_job_model_json['schema'] = '{"type":"struct","schema-id":0,"fields":[{"id":1,"name":"ID","required":true,"type":"int"},{"id":2,"name":"Name","required":true,"type":"string"}]}'
        ingestion_job_model_json['source_data_files'] = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        ingestion_job_model_json['source_file_type'] = 'csv'
        ingestion_job_model_json['start_timestamp'] = '1685084455'
        ingestion_job_model_json['status'] = 'running'
        ingestion_job_model_json['target_table'] = 'demodb.test.targettable'
        ingestion_job_model_json['username'] = 'ibmlhadmin'
        ingestion_job_model_json['validate_csv_header'] = False

        # Construct a model instance of IngestionJob by calling from_dict on the json representation
        ingestion_job_model = IngestionJob.from_dict(ingestion_job_model_json)
        assert ingestion_job_model != False

        # Construct a model instance of IngestionJob by calling from_dict on the json representation
        ingestion_job_model_dict = IngestionJob.from_dict(ingestion_job_model_json).__dict__
        ingestion_job_model2 = IngestionJob(**ingestion_job_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_model == ingestion_job_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_model_json2 = ingestion_job_model.to_dict()
        assert ingestion_job_model_json2 == ingestion_job_model_json


class TestModel_IngestionJobCollection:
    """
    Test Class for IngestionJobCollection
    """

    def test_ingestion_job_collection_serialization(self):
        """
        Test serialization/deserialization for IngestionJobCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        ingestion_job_csv_property_model = {}  # IngestionJobCsvProperty
        ingestion_job_csv_property_model['encoding'] = 'utf-8'
        ingestion_job_csv_property_model['escape_character'] = '|'
        ingestion_job_csv_property_model['field_delimiter'] = ','
        ingestion_job_csv_property_model['header'] = True
        ingestion_job_csv_property_model['line_delimiter'] = '\\n'

        ingestion_job_execute_config_model = {}  # IngestionJobExecuteConfig
        ingestion_job_execute_config_model['driver_cores'] = 1
        ingestion_job_execute_config_model['driver_memory'] = '2G'
        ingestion_job_execute_config_model['executor_cores'] = 1
        ingestion_job_execute_config_model['executor_memory'] = '2G'
        ingestion_job_execute_config_model['num_executors'] = 1

        ingestion_job_model = {}  # IngestionJob
        ingestion_job_model['create_if_not_exist'] = False
        ingestion_job_model['csv_property'] = ingestion_job_csv_property_model
        ingestion_job_model['details'] = 'Path does not exist \'demobucket/data/yellow_tripdata_2022-01.parquet\'. Detail: [errno 2] No such file or directory'
        ingestion_job_model['end_timestamp'] = '1685088775'
        ingestion_job_model['engine_id'] = 'spark123'
        ingestion_job_model['engine_name'] = 'sparkdemo'
        ingestion_job_model['execute_config'] = ingestion_job_execute_config_model
        ingestion_job_model['instance_id'] = '1684432229673971'
        ingestion_job_model['job_id'] = 'ingestion-1699459946935'
        ingestion_job_model['partition_by'] = 'col1, col2'
        ingestion_job_model['schema'] = '{"type":"struct","schema-id":0,"fields":[{"id":1,"name":"ID","required":true,"type":"int"},{"id":2,"name":"Name","required":true,"type":"string"}]}'
        ingestion_job_model['source_data_files'] = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        ingestion_job_model['source_file_type'] = 'csv'
        ingestion_job_model['start_timestamp'] = '1685084455'
        ingestion_job_model['status'] = 'running'
        ingestion_job_model['target_table'] = 'demodb.test.targettable'
        ingestion_job_model['username'] = 'ibmlhadmin'
        ingestion_job_model['validate_csv_header'] = False

        ingestion_job_collection_page_model = {}  # IngestionJobCollectionPage

        # Construct a json representation of a IngestionJobCollection model
        ingestion_job_collection_model_json = {}
        ingestion_job_collection_model_json['ingestion_jobs'] = [ingestion_job_model]
        ingestion_job_collection_model_json['first'] = ingestion_job_collection_page_model
        ingestion_job_collection_model_json['next'] = ingestion_job_collection_page_model

        # Construct a model instance of IngestionJobCollection by calling from_dict on the json representation
        ingestion_job_collection_model = IngestionJobCollection.from_dict(ingestion_job_collection_model_json)
        assert ingestion_job_collection_model != False

        # Construct a model instance of IngestionJobCollection by calling from_dict on the json representation
        ingestion_job_collection_model_dict = IngestionJobCollection.from_dict(ingestion_job_collection_model_json).__dict__
        ingestion_job_collection_model2 = IngestionJobCollection(**ingestion_job_collection_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_collection_model == ingestion_job_collection_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_collection_model_json2 = ingestion_job_collection_model.to_dict()
        assert ingestion_job_collection_model_json2 == ingestion_job_collection_model_json


class TestModel_IngestionJobCollectionPage:
    """
    Test Class for IngestionJobCollectionPage
    """

    def test_ingestion_job_collection_page_serialization(self):
        """
        Test serialization/deserialization for IngestionJobCollectionPage
        """

        # Construct a json representation of a IngestionJobCollectionPage model
        ingestion_job_collection_page_model_json = {}

        # Construct a model instance of IngestionJobCollectionPage by calling from_dict on the json representation
        ingestion_job_collection_page_model = IngestionJobCollectionPage.from_dict(ingestion_job_collection_page_model_json)
        assert ingestion_job_collection_page_model != False

        # Construct a model instance of IngestionJobCollectionPage by calling from_dict on the json representation
        ingestion_job_collection_page_model_dict = IngestionJobCollectionPage.from_dict(ingestion_job_collection_page_model_json).__dict__
        ingestion_job_collection_page_model2 = IngestionJobCollectionPage(**ingestion_job_collection_page_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_collection_page_model == ingestion_job_collection_page_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_collection_page_model_json2 = ingestion_job_collection_page_model.to_dict()
        assert ingestion_job_collection_page_model_json2 == ingestion_job_collection_page_model_json


class TestModel_IngestionJobCsvProperty:
    """
    Test Class for IngestionJobCsvProperty
    """

    def test_ingestion_job_csv_property_serialization(self):
        """
        Test serialization/deserialization for IngestionJobCsvProperty
        """

        # Construct a json representation of a IngestionJobCsvProperty model
        ingestion_job_csv_property_model_json = {}
        ingestion_job_csv_property_model_json['encoding'] = 'utf-8'
        ingestion_job_csv_property_model_json['escape_character'] = '|'
        ingestion_job_csv_property_model_json['field_delimiter'] = ','
        ingestion_job_csv_property_model_json['header'] = True
        ingestion_job_csv_property_model_json['line_delimiter'] = '\\n'

        # Construct a model instance of IngestionJobCsvProperty by calling from_dict on the json representation
        ingestion_job_csv_property_model = IngestionJobCsvProperty.from_dict(ingestion_job_csv_property_model_json)
        assert ingestion_job_csv_property_model != False

        # Construct a model instance of IngestionJobCsvProperty by calling from_dict on the json representation
        ingestion_job_csv_property_model_dict = IngestionJobCsvProperty.from_dict(ingestion_job_csv_property_model_json).__dict__
        ingestion_job_csv_property_model2 = IngestionJobCsvProperty(**ingestion_job_csv_property_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_csv_property_model == ingestion_job_csv_property_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_csv_property_model_json2 = ingestion_job_csv_property_model.to_dict()
        assert ingestion_job_csv_property_model_json2 == ingestion_job_csv_property_model_json


class TestModel_IngestionJobExecuteConfig:
    """
    Test Class for IngestionJobExecuteConfig
    """

    def test_ingestion_job_execute_config_serialization(self):
        """
        Test serialization/deserialization for IngestionJobExecuteConfig
        """

        # Construct a json representation of a IngestionJobExecuteConfig model
        ingestion_job_execute_config_model_json = {}
        ingestion_job_execute_config_model_json['driver_cores'] = 1
        ingestion_job_execute_config_model_json['driver_memory'] = '2G'
        ingestion_job_execute_config_model_json['executor_cores'] = 1
        ingestion_job_execute_config_model_json['executor_memory'] = '2G'
        ingestion_job_execute_config_model_json['num_executors'] = 1

        # Construct a model instance of IngestionJobExecuteConfig by calling from_dict on the json representation
        ingestion_job_execute_config_model = IngestionJobExecuteConfig.from_dict(ingestion_job_execute_config_model_json)
        assert ingestion_job_execute_config_model != False

        # Construct a model instance of IngestionJobExecuteConfig by calling from_dict on the json representation
        ingestion_job_execute_config_model_dict = IngestionJobExecuteConfig.from_dict(ingestion_job_execute_config_model_json).__dict__
        ingestion_job_execute_config_model2 = IngestionJobExecuteConfig(**ingestion_job_execute_config_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_execute_config_model == ingestion_job_execute_config_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_execute_config_model_json2 = ingestion_job_execute_config_model.to_dict()
        assert ingestion_job_execute_config_model_json2 == ingestion_job_execute_config_model_json


class TestModel_IngestionJobPrototypeCsvProperty:
    """
    Test Class for IngestionJobPrototypeCsvProperty
    """

    def test_ingestion_job_prototype_csv_property_serialization(self):
        """
        Test serialization/deserialization for IngestionJobPrototypeCsvProperty
        """

        # Construct a json representation of a IngestionJobPrototypeCsvProperty model
        ingestion_job_prototype_csv_property_model_json = {}
        ingestion_job_prototype_csv_property_model_json['encoding'] = 'utf-8'
        ingestion_job_prototype_csv_property_model_json['escape_character'] = '\\\\'
        ingestion_job_prototype_csv_property_model_json['field_delimiter'] = ','
        ingestion_job_prototype_csv_property_model_json['header'] = True
        ingestion_job_prototype_csv_property_model_json['line_delimiter'] = '\\n'

        # Construct a model instance of IngestionJobPrototypeCsvProperty by calling from_dict on the json representation
        ingestion_job_prototype_csv_property_model = IngestionJobPrototypeCsvProperty.from_dict(ingestion_job_prototype_csv_property_model_json)
        assert ingestion_job_prototype_csv_property_model != False

        # Construct a model instance of IngestionJobPrototypeCsvProperty by calling from_dict on the json representation
        ingestion_job_prototype_csv_property_model_dict = IngestionJobPrototypeCsvProperty.from_dict(ingestion_job_prototype_csv_property_model_json).__dict__
        ingestion_job_prototype_csv_property_model2 = IngestionJobPrototypeCsvProperty(**ingestion_job_prototype_csv_property_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_prototype_csv_property_model == ingestion_job_prototype_csv_property_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_prototype_csv_property_model_json2 = ingestion_job_prototype_csv_property_model.to_dict()
        assert ingestion_job_prototype_csv_property_model_json2 == ingestion_job_prototype_csv_property_model_json


class TestModel_IngestionJobPrototypeExecuteConfig:
    """
    Test Class for IngestionJobPrototypeExecuteConfig
    """

    def test_ingestion_job_prototype_execute_config_serialization(self):
        """
        Test serialization/deserialization for IngestionJobPrototypeExecuteConfig
        """

        # Construct a json representation of a IngestionJobPrototypeExecuteConfig model
        ingestion_job_prototype_execute_config_model_json = {}
        ingestion_job_prototype_execute_config_model_json['driver_cores'] = 1
        ingestion_job_prototype_execute_config_model_json['driver_memory'] = '2G'
        ingestion_job_prototype_execute_config_model_json['executor_cores'] = 1
        ingestion_job_prototype_execute_config_model_json['executor_memory'] = '2G'
        ingestion_job_prototype_execute_config_model_json['num_executors'] = 1

        # Construct a model instance of IngestionJobPrototypeExecuteConfig by calling from_dict on the json representation
        ingestion_job_prototype_execute_config_model = IngestionJobPrototypeExecuteConfig.from_dict(ingestion_job_prototype_execute_config_model_json)
        assert ingestion_job_prototype_execute_config_model != False

        # Construct a model instance of IngestionJobPrototypeExecuteConfig by calling from_dict on the json representation
        ingestion_job_prototype_execute_config_model_dict = IngestionJobPrototypeExecuteConfig.from_dict(ingestion_job_prototype_execute_config_model_json).__dict__
        ingestion_job_prototype_execute_config_model2 = IngestionJobPrototypeExecuteConfig(**ingestion_job_prototype_execute_config_model_dict)

        # Verify the model instances are equivalent
        assert ingestion_job_prototype_execute_config_model == ingestion_job_prototype_execute_config_model2

        # Convert model instance back to dict and verify no loss of data
        ingestion_job_prototype_execute_config_model_json2 = ingestion_job_prototype_execute_config_model.to_dict()
        assert ingestion_job_prototype_execute_config_model_json2 == ingestion_job_prototype_execute_config_model_json


class TestModel_Integration:
    """
    Test Class for Integration
    """

    def test_integration_serialization(self):
        """
        Test serialization/deserialization for Integration
        """

        # Construct a json representation of a Integration model
        integration_model_json = {}
        integration_model_json['access_token'] = 'accessToken'
        integration_model_json['apikey'] = 'apikey'
        integration_model_json['auth_url'] = 'https://abc.ibm.com'
        integration_model_json['config_properties'] = 'ikc-env.password=ibm-abcefghijklmno==\\nikc-env.url=ikc\\nikc-enabled-catalogs=\\nikc-username=\\nlh-unique-identifier=1711796957622126\\nlh-crn=1711796957622126'
        integration_model_json['cross_account_integration'] = True
        integration_model_json['enable_data_policy_within_wxd'] = False
        integration_model_json['governance_properties'] = 'query-governance.name=external'
        integration_model_json['ikc_user_account_id'] = 'abcdefghijklmnopqrstuvwxyz'
        integration_model_json['integration_id'] = 'ikc001'
        integration_model_json['manta_url'] = 'https://abcd.com/gov_lineage/v2/lineage_events/openlineage'
        integration_model_json['modified_at'] = 123456789
        integration_model_json['modified_by'] = 'username@email.com'
        integration_model_json['password'] = 'password'
        integration_model_json['resource'] = 'presto01'
        integration_model_json['service_type'] = 'ikc'
        integration_model_json['state'] = 'active'
        integration_model_json['storage_catalogs'] = ['iceberg_data', 'hive_data']
        integration_model_json['url'] = 'http://abcd.efgh.com:9876/'
        integration_model_json['username'] = 'username@email.com'

        # Construct a model instance of Integration by calling from_dict on the json representation
        integration_model = Integration.from_dict(integration_model_json)
        assert integration_model != False

        # Construct a model instance of Integration by calling from_dict on the json representation
        integration_model_dict = Integration.from_dict(integration_model_json).__dict__
        integration_model2 = Integration(**integration_model_dict)

        # Verify the model instances are equivalent
        assert integration_model == integration_model2

        # Convert model instance back to dict and verify no loss of data
        integration_model_json2 = integration_model.to_dict()
        assert integration_model_json2 == integration_model_json


class TestModel_IntegrationCollection:
    """
    Test Class for IntegrationCollection
    """

    def test_integration_collection_serialization(self):
        """
        Test serialization/deserialization for IntegrationCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        integration_model = {}  # Integration
        integration_model['access_token'] = 'accessToken'
        integration_model['apikey'] = 'apikey'
        integration_model['auth_url'] = 'https://abc.ibm.com'
        integration_model['config_properties'] = 'ikc-env.password=ibmlhenc__0001__uMkFATDDZNnxJ7z6BA/QqA==\\\\nikc-env.url=ikc\\\\nikc-username=\\\\nikc-enabled-catalogs=\\\\nlh-unique-identifier=1711796957622126\\\\nlh-crn=1711796957622126'
        integration_model['cross_account_integration'] = True
        integration_model['enable_data_policy_within_wxd'] = False
        integration_model['governance_properties'] = 'query-governance.name=external'
        integration_model['ikc_user_account_id'] = 'abcdefghijklmnopqrstuvwxyz'
        integration_model['integration_id'] = 'ikc543'
        integration_model['manta_url'] = 'https://abcd.com/gov_lineage/v2/lineage_events/openlineage'
        integration_model['modified_at'] = 1716878292
        integration_model['modified_by'] = 'admin'
        integration_model['password'] = 'password'
        integration_model['resource'] = 'presto01'
        integration_model['service_type'] = 'ikc'
        integration_model['state'] = 'active'
        integration_model['storage_catalogs'] = ['iceberg_data', 'hive_data']
        integration_model['url'] = 'http://abcd.efgh.com:9876/'
        integration_model['username'] = 'admin'

        # Construct a json representation of a IntegrationCollection model
        integration_collection_model_json = {}
        integration_collection_model_json['integrations'] = [integration_model]

        # Construct a model instance of IntegrationCollection by calling from_dict on the json representation
        integration_collection_model = IntegrationCollection.from_dict(integration_collection_model_json)
        assert integration_collection_model != False

        # Construct a model instance of IntegrationCollection by calling from_dict on the json representation
        integration_collection_model_dict = IntegrationCollection.from_dict(integration_collection_model_json).__dict__
        integration_collection_model2 = IntegrationCollection(**integration_collection_model_dict)

        # Verify the model instances are equivalent
        assert integration_collection_model == integration_collection_model2

        # Convert model instance back to dict and verify no loss of data
        integration_collection_model_json2 = integration_collection_model.to_dict()
        assert integration_collection_model_json2 == integration_collection_model_json


class TestModel_IntegrationPatch:
    """
    Test Class for IntegrationPatch
    """

    def test_integration_patch_serialization(self):
        """
        Test serialization/deserialization for IntegrationPatch
        """

        # Construct a json representation of a IntegrationPatch model
        integration_patch_model_json = {}
        integration_patch_model_json['access_token'] = 'uiOO90kklop'
        integration_patch_model_json['apikey'] = 'apikey'
        integration_patch_model_json['cross_account_integration'] = False
        integration_patch_model_json['enable_data_policy_within_wxd'] = False
        integration_patch_model_json['ikc_user_account_id'] = 'abcdefghijklmnopqrstuvwxyz'
        integration_patch_model_json['password'] = 'password'
        integration_patch_model_json['resource'] = 'presto01'
        integration_patch_model_json['state'] = 'active'
        integration_patch_model_json['storage_catalogs'] = ['iceberg_data', 'hive_data']
        integration_patch_model_json['url'] = 'http://abcd.efgh.com:9876/'
        integration_patch_model_json['username'] = 'username@email.com'

        # Construct a model instance of IntegrationPatch by calling from_dict on the json representation
        integration_patch_model = IntegrationPatch.from_dict(integration_patch_model_json)
        assert integration_patch_model != False

        # Construct a model instance of IntegrationPatch by calling from_dict on the json representation
        integration_patch_model_dict = IntegrationPatch.from_dict(integration_patch_model_json).__dict__
        integration_patch_model2 = IntegrationPatch(**integration_patch_model_dict)

        # Verify the model instances are equivalent
        assert integration_patch_model == integration_patch_model2

        # Convert model instance back to dict and verify no loss of data
        integration_patch_model_json2 = integration_patch_model.to_dict()
        assert integration_patch_model_json2 == integration_patch_model_json


class TestModel_InternalDetails:
    """
    Test Class for InternalDetails
    """

    def test_internal_details_serialization(self):
        """
        Test serialization/deserialization for InternalDetails
        """

        # Construct a json representation of a InternalDetails model
        internal_details_model_json = {}
        internal_details_model_json['port'] = 4553
        internal_details_model_json['hostname'] = 'internal hostname'

        # Construct a model instance of InternalDetails by calling from_dict on the json representation
        internal_details_model = InternalDetails.from_dict(internal_details_model_json)
        assert internal_details_model != False

        # Construct a model instance of InternalDetails by calling from_dict on the json representation
        internal_details_model_dict = InternalDetails.from_dict(internal_details_model_json).__dict__
        internal_details_model2 = InternalDetails(**internal_details_model_dict)

        # Verify the model instances are equivalent
        assert internal_details_model == internal_details_model2

        # Convert model instance back to dict and verify no loss of data
        internal_details_model_json2 = internal_details_model.to_dict()
        assert internal_details_model_json2 == internal_details_model_json


class TestModel_JdbcThriftUrls:
    """
    Test Class for JdbcThriftUrls
    """

    def test_jdbc_thrift_urls_serialization(self):
        """
        Test serialization/deserialization for JdbcThriftUrls
        """

        # Construct a json representation of a JdbcThriftUrls model
        jdbc_thrift_urls_model_json = {}
        jdbc_thrift_urls_model_json['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model_json['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        # Construct a model instance of JdbcThriftUrls by calling from_dict on the json representation
        jdbc_thrift_urls_model = JdbcThriftUrls.from_dict(jdbc_thrift_urls_model_json)
        assert jdbc_thrift_urls_model != False

        # Construct a model instance of JdbcThriftUrls by calling from_dict on the json representation
        jdbc_thrift_urls_model_dict = JdbcThriftUrls.from_dict(jdbc_thrift_urls_model_json).__dict__
        jdbc_thrift_urls_model2 = JdbcThriftUrls(**jdbc_thrift_urls_model_dict)

        # Verify the model instances are equivalent
        assert jdbc_thrift_urls_model == jdbc_thrift_urls_model2

        # Convert model instance back to dict and verify no loss of data
        jdbc_thrift_urls_model_json2 = jdbc_thrift_urls_model.to_dict()
        assert jdbc_thrift_urls_model_json2 == jdbc_thrift_urls_model_json


class TestModel_ListSchemasOKBody:
    """
    Test Class for ListSchemasOKBody
    """

    def test_list_schemas_ok_body_serialization(self):
        """
        Test serialization/deserialization for ListSchemasOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'list all schemas'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a ListSchemasOKBody model
        list_schemas_ok_body_model_json = {}
        list_schemas_ok_body_model_json['response'] = success_response_model
        list_schemas_ok_body_model_json['schemas'] = ['testString']

        # Construct a model instance of ListSchemasOKBody by calling from_dict on the json representation
        list_schemas_ok_body_model = ListSchemasOKBody.from_dict(list_schemas_ok_body_model_json)
        assert list_schemas_ok_body_model != False

        # Construct a model instance of ListSchemasOKBody by calling from_dict on the json representation
        list_schemas_ok_body_model_dict = ListSchemasOKBody.from_dict(list_schemas_ok_body_model_json).__dict__
        list_schemas_ok_body_model2 = ListSchemasOKBody(**list_schemas_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert list_schemas_ok_body_model == list_schemas_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        list_schemas_ok_body_model_json2 = list_schemas_ok_body_model.to_dict()
        assert list_schemas_ok_body_model_json2 == list_schemas_ok_body_model_json


class TestModel_ListSparkVersionsOKBody:
    """
    Test Class for ListSparkVersionsOKBody
    """

    def test_list_spark_versions_ok_body_serialization(self):
        """
        Test serialization/deserialization for ListSparkVersionsOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'List spark versions'
        success_response_model['message_code'] = 'success'

        spark_versions_info_response_model = {}  # SparkVersionsInfoResponse
        spark_versions_info_response_model['display_name'] = 'Instance Name'
        spark_versions_info_response_model['value'] = 'Instance Name'

        spark_versions_model = {}  # SparkVersions
        spark_versions_model['cpp'] = [spark_versions_info_response_model]
        spark_versions_model['java'] = [spark_versions_info_response_model]

        # Construct a json representation of a ListSparkVersionsOKBody model
        list_spark_versions_ok_body_model_json = {}
        list_spark_versions_ok_body_model_json['response'] = success_response_model
        list_spark_versions_ok_body_model_json['spark_versions'] = [spark_versions_model]

        # Construct a model instance of ListSparkVersionsOKBody by calling from_dict on the json representation
        list_spark_versions_ok_body_model = ListSparkVersionsOKBody.from_dict(list_spark_versions_ok_body_model_json)
        assert list_spark_versions_ok_body_model != False

        # Construct a model instance of ListSparkVersionsOKBody by calling from_dict on the json representation
        list_spark_versions_ok_body_model_dict = ListSparkVersionsOKBody.from_dict(list_spark_versions_ok_body_model_json).__dict__
        list_spark_versions_ok_body_model2 = ListSparkVersionsOKBody(**list_spark_versions_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert list_spark_versions_ok_body_model == list_spark_versions_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        list_spark_versions_ok_body_model_json2 = list_spark_versions_ok_body_model.to_dict()
        assert list_spark_versions_ok_body_model_json2 == list_spark_versions_ok_body_model_json


class TestModel_LoadTableResponse:
    """
    Test Class for LoadTableResponse
    """

    def test_load_table_response_serialization(self):
        """
        Test serialization/deserialization for LoadTableResponse
        """

        # Construct a json representation of a LoadTableResponse model
        load_table_response_model_json = {}
        load_table_response_model_json['metadata_location'] = 's3a://bucketname/path/to/table/metadata_location/_delta_log'
        load_table_response_model_json['table_path'] = 's3a://bucketname/path/to/table'

        # Construct a model instance of LoadTableResponse by calling from_dict on the json representation
        load_table_response_model = LoadTableResponse.from_dict(load_table_response_model_json)
        assert load_table_response_model != False

        # Construct a model instance of LoadTableResponse by calling from_dict on the json representation
        load_table_response_model_dict = LoadTableResponse.from_dict(load_table_response_model_json).__dict__
        load_table_response_model2 = LoadTableResponse(**load_table_response_model_dict)

        # Verify the model instances are equivalent
        assert load_table_response_model == load_table_response_model2

        # Convert model instance back to dict and verify no loss of data
        load_table_response_model_json2 = load_table_response_model.to_dict()
        assert load_table_response_model_json2 == load_table_response_model_json


class TestModel_MilvusDatabaseCollections:
    """
    Test Class for MilvusDatabaseCollections
    """

    def test_milvus_database_collections_serialization(self):
        """
        Test serialization/deserialization for MilvusDatabaseCollections
        """

        # Construct dict forms of any model objects needed in order to build this model.

        milvusdbcollection_model = {}  # Milvusdbcollection
        milvusdbcollection_model['collection_id'] = 449533249905689150
        milvusdbcollection_model['collection_name'] = 'new'
        milvusdbcollection_model['physical_channels'] = []
        milvusdbcollection_model['virtual_channels'] = []

        # Construct a json representation of a MilvusDatabaseCollections model
        milvus_database_collections_model_json = {}
        milvus_database_collections_model_json['collections'] = [milvusdbcollection_model]

        # Construct a model instance of MilvusDatabaseCollections by calling from_dict on the json representation
        milvus_database_collections_model = MilvusDatabaseCollections.from_dict(milvus_database_collections_model_json)
        assert milvus_database_collections_model != False

        # Construct a model instance of MilvusDatabaseCollections by calling from_dict on the json representation
        milvus_database_collections_model_dict = MilvusDatabaseCollections.from_dict(milvus_database_collections_model_json).__dict__
        milvus_database_collections_model2 = MilvusDatabaseCollections(**milvus_database_collections_model_dict)

        # Verify the model instances are equivalent
        assert milvus_database_collections_model == milvus_database_collections_model2

        # Convert model instance back to dict and verify no loss of data
        milvus_database_collections_model_json2 = milvus_database_collections_model.to_dict()
        assert milvus_database_collections_model_json2 == milvus_database_collections_model_json


class TestModel_MilvusService:
    """
    Test Class for MilvusService
    """

    def test_milvus_service_serialization(self):
        """
        Test serialization/deserialization for MilvusService
        """

        # Construct a json representation of a MilvusService model
        milvus_service_model_json = {}
        milvus_service_model_json['access_key'] = 'Sample bucket access key'
        milvus_service_model_json['actions'] = ['update', 'delete']
        milvus_service_model_json['bucket_name'] = 'Sample bucket name'
        milvus_service_model_json['bucket_type'] = 'Sample bucket type'
        milvus_service_model_json['created_by'] = '<username>@<domain>.com'
        milvus_service_model_json['created_on'] = 1
        milvus_service_model_json['description'] = 'milvus service for running sql queries'
        milvus_service_model_json['endpoint'] = 'Sample bucket type'
        milvus_service_model_json['grpc_host'] = 'example.grpc.host'
        milvus_service_model_json['grpc_port'] = 1
        milvus_service_model_json['host_name'] = 'sampleMilvus'
        milvus_service_model_json['https_host'] = 'example.https.host'
        milvus_service_model_json['https_port'] = 1
        milvus_service_model_json['origin'] = 'native'
        milvus_service_model_json['root_path'] = 'Sample path'
        milvus_service_model_json['secret_key'] = 'Sample bucket secret access key'
        milvus_service_model_json['service_display_name'] = 'sampleService'
        milvus_service_model_json['service_id'] = 'sampleService123'
        milvus_service_model_json['status'] = 'running'
        milvus_service_model_json['status_code'] = 38
        milvus_service_model_json['tags'] = ['tag1', 'tag2']
        milvus_service_model_json['tshirt_size'] = 'small'
        milvus_service_model_json['type'] = 'milvus'

        # Construct a model instance of MilvusService by calling from_dict on the json representation
        milvus_service_model = MilvusService.from_dict(milvus_service_model_json)
        assert milvus_service_model != False

        # Construct a model instance of MilvusService by calling from_dict on the json representation
        milvus_service_model_dict = MilvusService.from_dict(milvus_service_model_json).__dict__
        milvus_service_model2 = MilvusService(**milvus_service_model_dict)

        # Verify the model instances are equivalent
        assert milvus_service_model == milvus_service_model2

        # Convert model instance back to dict and verify no loss of data
        milvus_service_model_json2 = milvus_service_model.to_dict()
        assert milvus_service_model_json2 == milvus_service_model_json


class TestModel_MilvusServiceBucketPatch:
    """
    Test Class for MilvusServiceBucketPatch
    """

    def test_milvus_service_bucket_patch_serialization(self):
        """
        Test serialization/deserialization for MilvusServiceBucketPatch
        """

        # Construct a json representation of a MilvusServiceBucketPatch model
        milvus_service_bucket_patch_model_json = {}
        milvus_service_bucket_patch_model_json['bucket_name'] = 'Sample bucket name'
        milvus_service_bucket_patch_model_json['managed_by'] = 'customer'
        milvus_service_bucket_patch_model_json['root_path'] = 'Sample path'
        milvus_service_bucket_patch_model_json['tshirt_size'] = 'small'

        # Construct a model instance of MilvusServiceBucketPatch by calling from_dict on the json representation
        milvus_service_bucket_patch_model = MilvusServiceBucketPatch.from_dict(milvus_service_bucket_patch_model_json)
        assert milvus_service_bucket_patch_model != False

        # Construct a model instance of MilvusServiceBucketPatch by calling from_dict on the json representation
        milvus_service_bucket_patch_model_dict = MilvusServiceBucketPatch.from_dict(milvus_service_bucket_patch_model_json).__dict__
        milvus_service_bucket_patch_model2 = MilvusServiceBucketPatch(**milvus_service_bucket_patch_model_dict)

        # Verify the model instances are equivalent
        assert milvus_service_bucket_patch_model == milvus_service_bucket_patch_model2

        # Convert model instance back to dict and verify no loss of data
        milvus_service_bucket_patch_model_json2 = milvus_service_bucket_patch_model.to_dict()
        assert milvus_service_bucket_patch_model_json2 == milvus_service_bucket_patch_model_json


class TestModel_MilvusServiceCollection:
    """
    Test Class for MilvusServiceCollection
    """

    def test_milvus_service_collection_serialization(self):
        """
        Test serialization/deserialization for MilvusServiceCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        milvus_service_model = {}  # MilvusService
        milvus_service_model['access_key'] = 'Sample bucket access key'
        milvus_service_model['actions'] = ['update', 'delete']
        milvus_service_model['bucket_name'] = 'Sample bucket name'
        milvus_service_model['bucket_type'] = 'Sample bucket type'
        milvus_service_model['created_by'] = 'username@domain.com'
        milvus_service_model['created_on'] = 1700201877
        milvus_service_model['description'] = 'milvus service for running sql queries'
        milvus_service_model['endpoint'] = 'Sample bucket type'
        milvus_service_model['grpc_host'] = 'example.grpc.host'
        milvus_service_model['grpc_port'] = 31501
        milvus_service_model['host_name'] = '<formation_id>.<kubernetes_cluster>.databases.appdomain.cloud'
        milvus_service_model['https_host'] = 'example.https.host'
        milvus_service_model['https_port'] = 31012
        milvus_service_model['origin'] = 'native'
        milvus_service_model['root_path'] = 'Sample path'
        milvus_service_model['secret_key'] = 'Sample bucket secret access key'
        milvus_service_model['service_display_name'] = 'test-milvus'
        milvus_service_model['service_id'] = 'milvus76'
        milvus_service_model['status'] = 'running'
        milvus_service_model['status_code'] = 11
        milvus_service_model['tags'] = ['tag1', 'tag2']
        milvus_service_model['tshirt_size'] = 'string'
        milvus_service_model['type'] = 'milvus'

        # Construct a json representation of a MilvusServiceCollection model
        milvus_service_collection_model_json = {}
        milvus_service_collection_model_json['milvus_services'] = [milvus_service_model]

        # Construct a model instance of MilvusServiceCollection by calling from_dict on the json representation
        milvus_service_collection_model = MilvusServiceCollection.from_dict(milvus_service_collection_model_json)
        assert milvus_service_collection_model != False

        # Construct a model instance of MilvusServiceCollection by calling from_dict on the json representation
        milvus_service_collection_model_dict = MilvusServiceCollection.from_dict(milvus_service_collection_model_json).__dict__
        milvus_service_collection_model2 = MilvusServiceCollection(**milvus_service_collection_model_dict)

        # Verify the model instances are equivalent
        assert milvus_service_collection_model == milvus_service_collection_model2

        # Convert model instance back to dict and verify no loss of data
        milvus_service_collection_model_json2 = milvus_service_collection_model.to_dict()
        assert milvus_service_collection_model_json2 == milvus_service_collection_model_json


class TestModel_MilvusServiceDatabases:
    """
    Test Class for MilvusServiceDatabases
    """

    def test_milvus_service_databases_serialization(self):
        """
        Test serialization/deserialization for MilvusServiceDatabases
        """

        # Construct a json representation of a MilvusServiceDatabases model
        milvus_service_databases_model_json = {}
        milvus_service_databases_model_json['milvus_databases'] = ['["default","new"]']

        # Construct a model instance of MilvusServiceDatabases by calling from_dict on the json representation
        milvus_service_databases_model = MilvusServiceDatabases.from_dict(milvus_service_databases_model_json)
        assert milvus_service_databases_model != False

        # Construct a model instance of MilvusServiceDatabases by calling from_dict on the json representation
        milvus_service_databases_model_dict = MilvusServiceDatabases.from_dict(milvus_service_databases_model_json).__dict__
        milvus_service_databases_model2 = MilvusServiceDatabases(**milvus_service_databases_model_dict)

        # Verify the model instances are equivalent
        assert milvus_service_databases_model == milvus_service_databases_model2

        # Convert model instance back to dict and verify no loss of data
        milvus_service_databases_model_json2 = milvus_service_databases_model.to_dict()
        assert milvus_service_databases_model_json2 == milvus_service_databases_model_json


class TestModel_MilvusServicePatch:
    """
    Test Class for MilvusServicePatch
    """

    def test_milvus_service_patch_serialization(self):
        """
        Test serialization/deserialization for MilvusServicePatch
        """

        # Construct a json representation of a MilvusServicePatch model
        milvus_service_patch_model_json = {}
        milvus_service_patch_model_json['description'] = 'updated description for milvus service'
        milvus_service_patch_model_json['service_display_name'] = 'sampleService'
        milvus_service_patch_model_json['tags'] = ['tag1', 'tag2']

        # Construct a model instance of MilvusServicePatch by calling from_dict on the json representation
        milvus_service_patch_model = MilvusServicePatch.from_dict(milvus_service_patch_model_json)
        assert milvus_service_patch_model != False

        # Construct a model instance of MilvusServicePatch by calling from_dict on the json representation
        milvus_service_patch_model_dict = MilvusServicePatch.from_dict(milvus_service_patch_model_json).__dict__
        milvus_service_patch_model2 = MilvusServicePatch(**milvus_service_patch_model_dict)

        # Verify the model instances are equivalent
        assert milvus_service_patch_model == milvus_service_patch_model2

        # Convert model instance back to dict and verify no loss of data
        milvus_service_patch_model_json2 = milvus_service_patch_model.to_dict()
        assert milvus_service_patch_model_json2 == milvus_service_patch_model_json


class TestModel_Milvusdbcollection:
    """
    Test Class for Milvusdbcollection
    """

    def test_milvusdbcollection_serialization(self):
        """
        Test serialization/deserialization for Milvusdbcollection
        """

        # Construct a json representation of a Milvusdbcollection model
        milvusdbcollection_model_json = {}
        milvusdbcollection_model_json['collection_id'] = 1
        milvusdbcollection_model_json['collection_name'] = 'col1'
        milvusdbcollection_model_json['physical_channels'] = ['testString']
        milvusdbcollection_model_json['virtual_channels'] = ['testString']

        # Construct a model instance of Milvusdbcollection by calling from_dict on the json representation
        milvusdbcollection_model = Milvusdbcollection.from_dict(milvusdbcollection_model_json)
        assert milvusdbcollection_model != False

        # Construct a model instance of Milvusdbcollection by calling from_dict on the json representation
        milvusdbcollection_model_dict = Milvusdbcollection.from_dict(milvusdbcollection_model_json).__dict__
        milvusdbcollection_model2 = Milvusdbcollection(**milvusdbcollection_model_dict)

        # Verify the model instances are equivalent
        assert milvusdbcollection_model == milvusdbcollection_model2

        # Convert model instance back to dict and verify no loss of data
        milvusdbcollection_model_json2 = milvusdbcollection_model.to_dict()
        assert milvusdbcollection_model_json2 == milvusdbcollection_model_json


class TestModel_NetezzaEngine:
    """
    Test Class for NetezzaEngine
    """

    def test_netezza_engine_serialization(self):
        """
        Test serialization/deserialization for NetezzaEngine
        """

        # Construct dict forms of any model objects needed in order to build this model.

        netezza_engine_details_model = {}  # NetezzaEngineDetails
        netezza_engine_details_model['connection_string'] = '1.2.3.4'
        netezza_engine_details_model['metastore_host'] = 'thrift://mh-connection-string-sample.com'

        # Construct a json representation of a NetezzaEngine model
        netezza_engine_model_json = {}
        netezza_engine_model_json['actions'] = ['update', 'delete']
        netezza_engine_model_json['build_version'] = '1.0.3.0.0'
        netezza_engine_model_json['created_by'] = '<username>@<domain>.com'
        netezza_engine_model_json['created_on'] = 0
        netezza_engine_model_json['description'] = 'netezza engine for running sql queries'
        netezza_engine_model_json['engine_details'] = netezza_engine_details_model
        netezza_engine_model_json['engine_display_name'] = 'sampleEngine'
        netezza_engine_model_json['engine_id'] = 'sampleEngine123'
        netezza_engine_model_json['host_name'] = 'xyz-netezza-01-netezza-svc'
        netezza_engine_model_json['origin'] = 'ibm'
        netezza_engine_model_json['port'] = 0
        netezza_engine_model_json['status'] = 'REGISTERED'
        netezza_engine_model_json['tags'] = ['tag1', 'tag2']
        netezza_engine_model_json['type'] = 'netezza'

        # Construct a model instance of NetezzaEngine by calling from_dict on the json representation
        netezza_engine_model = NetezzaEngine.from_dict(netezza_engine_model_json)
        assert netezza_engine_model != False

        # Construct a model instance of NetezzaEngine by calling from_dict on the json representation
        netezza_engine_model_dict = NetezzaEngine.from_dict(netezza_engine_model_json).__dict__
        netezza_engine_model2 = NetezzaEngine(**netezza_engine_model_dict)

        # Verify the model instances are equivalent
        assert netezza_engine_model == netezza_engine_model2

        # Convert model instance back to dict and verify no loss of data
        netezza_engine_model_json2 = netezza_engine_model.to_dict()
        assert netezza_engine_model_json2 == netezza_engine_model_json


class TestModel_NetezzaEngineCollection:
    """
    Test Class for NetezzaEngineCollection
    """

    def test_netezza_engine_collection_serialization(self):
        """
        Test serialization/deserialization for NetezzaEngineCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        netezza_engine_details_model = {}  # NetezzaEngineDetails
        netezza_engine_details_model['connection_string'] = 'jdbc:netezza://localhost:5480/database'
        netezza_engine_details_model['metastore_host'] = 'thrift://mh-connection-string-sample.com'

        netezza_engine_model = {}  # NetezzaEngine
        netezza_engine_model['actions'] = ['create']
        netezza_engine_model['build_version'] = '1.0.3.0.0'
        netezza_engine_model['created_by'] = 'user@test.com'
        netezza_engine_model['created_on'] = 1700322469
        netezza_engine_model['description'] = 'netezza engine for running sql queries'
        netezza_engine_model['engine_details'] = netezza_engine_details_model
        netezza_engine_model['engine_display_name'] = 'netezza'
        netezza_engine_model['engine_id'] = 'netezza170'
        netezza_engine_model['host_name'] = 'xyz-netezza-01-netezza-svc'
        netezza_engine_model['origin'] = 'external'
        netezza_engine_model['port'] = 0
        netezza_engine_model['status'] = 'REGISTERED'
        netezza_engine_model['tags'] = ['tag1', 'tag2']
        netezza_engine_model['type'] = 'netezza'

        # Construct a json representation of a NetezzaEngineCollection model
        netezza_engine_collection_model_json = {}
        netezza_engine_collection_model_json['netezza_engines'] = [netezza_engine_model]

        # Construct a model instance of NetezzaEngineCollection by calling from_dict on the json representation
        netezza_engine_collection_model = NetezzaEngineCollection.from_dict(netezza_engine_collection_model_json)
        assert netezza_engine_collection_model != False

        # Construct a model instance of NetezzaEngineCollection by calling from_dict on the json representation
        netezza_engine_collection_model_dict = NetezzaEngineCollection.from_dict(netezza_engine_collection_model_json).__dict__
        netezza_engine_collection_model2 = NetezzaEngineCollection(**netezza_engine_collection_model_dict)

        # Verify the model instances are equivalent
        assert netezza_engine_collection_model == netezza_engine_collection_model2

        # Convert model instance back to dict and verify no loss of data
        netezza_engine_collection_model_json2 = netezza_engine_collection_model.to_dict()
        assert netezza_engine_collection_model_json2 == netezza_engine_collection_model_json


class TestModel_NetezzaEngineDetails:
    """
    Test Class for NetezzaEngineDetails
    """

    def test_netezza_engine_details_serialization(self):
        """
        Test serialization/deserialization for NetezzaEngineDetails
        """

        # Construct a json representation of a NetezzaEngineDetails model
        netezza_engine_details_model_json = {}
        netezza_engine_details_model_json['connection_string'] = '1.2.3.4'
        netezza_engine_details_model_json['metastore_host'] = '1.2.3.4'

        # Construct a model instance of NetezzaEngineDetails by calling from_dict on the json representation
        netezza_engine_details_model = NetezzaEngineDetails.from_dict(netezza_engine_details_model_json)
        assert netezza_engine_details_model != False

        # Construct a model instance of NetezzaEngineDetails by calling from_dict on the json representation
        netezza_engine_details_model_dict = NetezzaEngineDetails.from_dict(netezza_engine_details_model_json).__dict__
        netezza_engine_details_model2 = NetezzaEngineDetails(**netezza_engine_details_model_dict)

        # Verify the model instances are equivalent
        assert netezza_engine_details_model == netezza_engine_details_model2

        # Convert model instance back to dict and verify no loss of data
        netezza_engine_details_model_json2 = netezza_engine_details_model.to_dict()
        assert netezza_engine_details_model_json2 == netezza_engine_details_model_json


class TestModel_NetezzaEngineDetailsBody:
    """
    Test Class for NetezzaEngineDetailsBody
    """

    def test_netezza_engine_details_body_serialization(self):
        """
        Test serialization/deserialization for NetezzaEngineDetailsBody
        """

        # Construct a json representation of a NetezzaEngineDetailsBody model
        netezza_engine_details_body_model_json = {}
        netezza_engine_details_body_model_json['connection_string'] = '1.2.3.4'

        # Construct a model instance of NetezzaEngineDetailsBody by calling from_dict on the json representation
        netezza_engine_details_body_model = NetezzaEngineDetailsBody.from_dict(netezza_engine_details_body_model_json)
        assert netezza_engine_details_body_model != False

        # Construct a model instance of NetezzaEngineDetailsBody by calling from_dict on the json representation
        netezza_engine_details_body_model_dict = NetezzaEngineDetailsBody.from_dict(netezza_engine_details_body_model_json).__dict__
        netezza_engine_details_body_model2 = NetezzaEngineDetailsBody(**netezza_engine_details_body_model_dict)

        # Verify the model instances are equivalent
        assert netezza_engine_details_body_model == netezza_engine_details_body_model2

        # Convert model instance back to dict and verify no loss of data
        netezza_engine_details_body_model_json2 = netezza_engine_details_body_model.to_dict()
        assert netezza_engine_details_body_model_json2 == netezza_engine_details_body_model_json


class TestModel_NetezzaEnginePatch:
    """
    Test Class for NetezzaEnginePatch
    """

    def test_netezza_engine_patch_serialization(self):
        """
        Test serialization/deserialization for NetezzaEnginePatch
        """

        # Construct a json representation of a NetezzaEnginePatch model
        netezza_engine_patch_model_json = {}
        netezza_engine_patch_model_json['description'] = 'netezza engine updated description'
        netezza_engine_patch_model_json['engine_display_name'] = 'sampleEngine'
        netezza_engine_patch_model_json['tags'] = ['tag1', 'tag2']

        # Construct a model instance of NetezzaEnginePatch by calling from_dict on the json representation
        netezza_engine_patch_model = NetezzaEnginePatch.from_dict(netezza_engine_patch_model_json)
        assert netezza_engine_patch_model != False

        # Construct a model instance of NetezzaEnginePatch by calling from_dict on the json representation
        netezza_engine_patch_model_dict = NetezzaEnginePatch.from_dict(netezza_engine_patch_model_json).__dict__
        netezza_engine_patch_model2 = NetezzaEnginePatch(**netezza_engine_patch_model_dict)

        # Verify the model instances are equivalent
        assert netezza_engine_patch_model == netezza_engine_patch_model2

        # Convert model instance back to dict and verify no loss of data
        netezza_engine_patch_model_json2 = netezza_engine_patch_model.to_dict()
        assert netezza_engine_patch_model_json2 == netezza_engine_patch_model_json


class TestModel_NodeDescription:
    """
    Test Class for NodeDescription
    """

    def test_node_description_serialization(self):
        """
        Test serialization/deserialization for NodeDescription
        """

        # Construct a json representation of a NodeDescription model
        node_description_model_json = {}
        node_description_model_json['node_type'] = 'worker'
        node_description_model_json['quantity'] = 38

        # Construct a model instance of NodeDescription by calling from_dict on the json representation
        node_description_model = NodeDescription.from_dict(node_description_model_json)
        assert node_description_model != False

        # Construct a model instance of NodeDescription by calling from_dict on the json representation
        node_description_model_dict = NodeDescription.from_dict(node_description_model_json).__dict__
        node_description_model2 = NodeDescription(**node_description_model_dict)

        # Verify the model instances are equivalent
        assert node_description_model == node_description_model2

        # Convert model instance back to dict and verify no loss of data
        node_description_model_json2 = node_description_model.to_dict()
        assert node_description_model_json2 == node_description_model_json


class TestModel_NodeDescriptionBody:
    """
    Test Class for NodeDescriptionBody
    """

    def test_node_description_body_serialization(self):
        """
        Test serialization/deserialization for NodeDescriptionBody
        """

        # Construct a json representation of a NodeDescriptionBody model
        node_description_body_model_json = {}
        node_description_body_model_json['node_type'] = 'worker'
        node_description_body_model_json['quantity'] = 38

        # Construct a model instance of NodeDescriptionBody by calling from_dict on the json representation
        node_description_body_model = NodeDescriptionBody.from_dict(node_description_body_model_json)
        assert node_description_body_model != False

        # Construct a model instance of NodeDescriptionBody by calling from_dict on the json representation
        node_description_body_model_dict = NodeDescriptionBody.from_dict(node_description_body_model_json).__dict__
        node_description_body_model2 = NodeDescriptionBody(**node_description_body_model_dict)

        # Verify the model instances are equivalent
        assert node_description_body_model == node_description_body_model2

        # Convert model instance back to dict and verify no loss of data
        node_description_body_model_json2 = node_description_body_model.to_dict()
        assert node_description_body_model_json2 == node_description_body_model_json


class TestModel_OtherEngine:
    """
    Test Class for OtherEngine
    """

    def test_other_engine_serialization(self):
        """
        Test serialization/deserialization for OtherEngine
        """

        # Construct dict forms of any model objects needed in order to build this model.

        other_engine_details_model = {}  # OtherEngineDetails
        other_engine_details_model['connection_string'] = '1.2.3.4'
        other_engine_details_model['engine_type'] = 'netezza'
        other_engine_details_model['metastore_host'] = '1.2.3.4'

        # Construct a json representation of a OtherEngine model
        other_engine_model_json = {}
        other_engine_model_json['actions'] = ['update', 'delete']
        other_engine_model_json['created_by'] = '<username>@<domain>.com'
        other_engine_model_json['created_on'] = 38
        other_engine_model_json['description'] = 'engine for running sql queries'
        other_engine_model_json['engine_details'] = other_engine_details_model
        other_engine_model_json['engine_display_name'] = 'sampleEngine'
        other_engine_model_json['engine_id'] = 'sampleEngine123'
        other_engine_model_json['host_name'] = 'xyz-netezza-01-netezza-svc'
        other_engine_model_json['origin'] = 'ibm'
        other_engine_model_json['port'] = 38
        other_engine_model_json['status'] = 'registered'
        other_engine_model_json['tags'] = ['tag1', 'tag2']
        other_engine_model_json['type'] = 'external'

        # Construct a model instance of OtherEngine by calling from_dict on the json representation
        other_engine_model = OtherEngine.from_dict(other_engine_model_json)
        assert other_engine_model != False

        # Construct a model instance of OtherEngine by calling from_dict on the json representation
        other_engine_model_dict = OtherEngine.from_dict(other_engine_model_json).__dict__
        other_engine_model2 = OtherEngine(**other_engine_model_dict)

        # Verify the model instances are equivalent
        assert other_engine_model == other_engine_model2

        # Convert model instance back to dict and verify no loss of data
        other_engine_model_json2 = other_engine_model.to_dict()
        assert other_engine_model_json2 == other_engine_model_json


class TestModel_OtherEngineCollection:
    """
    Test Class for OtherEngineCollection
    """

    def test_other_engine_collection_serialization(self):
        """
        Test serialization/deserialization for OtherEngineCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        other_engine_details_model = {}  # OtherEngineDetails
        other_engine_details_model['connection_string'] = 'https://other-connection-string-sample.com'
        other_engine_details_model['engine_type'] = 'netezza'
        other_engine_details_model['metastore_host'] = '1.2.3.4'

        other_engine_model = {}  # OtherEngine
        other_engine_model['actions'] = ['update', 'delete']
        other_engine_model['created_by'] = '<username>@<domain>.com'
        other_engine_model['created_on'] = 163788384993
        other_engine_model['description'] = 'other engine for running queries'
        other_engine_model['engine_details'] = other_engine_details_model
        other_engine_model['engine_display_name'] = 'sampleEngine'
        other_engine_model['engine_id'] = 'sampleEngine123'
        other_engine_model['host_name'] = 'xyz-netezza-01-netezza-svc'
        other_engine_model['origin'] = 'external'
        other_engine_model['port'] = 38
        other_engine_model['status'] = 'registered'
        other_engine_model['tags'] = ['tag1', 'tag2']
        other_engine_model['type'] = 'other'

        # Construct a json representation of a OtherEngineCollection model
        other_engine_collection_model_json = {}
        other_engine_collection_model_json['other_engines'] = [other_engine_model]

        # Construct a model instance of OtherEngineCollection by calling from_dict on the json representation
        other_engine_collection_model = OtherEngineCollection.from_dict(other_engine_collection_model_json)
        assert other_engine_collection_model != False

        # Construct a model instance of OtherEngineCollection by calling from_dict on the json representation
        other_engine_collection_model_dict = OtherEngineCollection.from_dict(other_engine_collection_model_json).__dict__
        other_engine_collection_model2 = OtherEngineCollection(**other_engine_collection_model_dict)

        # Verify the model instances are equivalent
        assert other_engine_collection_model == other_engine_collection_model2

        # Convert model instance back to dict and verify no loss of data
        other_engine_collection_model_json2 = other_engine_collection_model.to_dict()
        assert other_engine_collection_model_json2 == other_engine_collection_model_json


class TestModel_OtherEngineDetails:
    """
    Test Class for OtherEngineDetails
    """

    def test_other_engine_details_serialization(self):
        """
        Test serialization/deserialization for OtherEngineDetails
        """

        # Construct a json representation of a OtherEngineDetails model
        other_engine_details_model_json = {}
        other_engine_details_model_json['connection_string'] = '1.2.3.4'
        other_engine_details_model_json['engine_type'] = 'netezza'
        other_engine_details_model_json['metastore_host'] = '1.2.3.4'

        # Construct a model instance of OtherEngineDetails by calling from_dict on the json representation
        other_engine_details_model = OtherEngineDetails.from_dict(other_engine_details_model_json)
        assert other_engine_details_model != False

        # Construct a model instance of OtherEngineDetails by calling from_dict on the json representation
        other_engine_details_model_dict = OtherEngineDetails.from_dict(other_engine_details_model_json).__dict__
        other_engine_details_model2 = OtherEngineDetails(**other_engine_details_model_dict)

        # Verify the model instances are equivalent
        assert other_engine_details_model == other_engine_details_model2

        # Convert model instance back to dict and verify no loss of data
        other_engine_details_model_json2 = other_engine_details_model.to_dict()
        assert other_engine_details_model_json2 == other_engine_details_model_json


class TestModel_OtherEngineDetailsBody:
    """
    Test Class for OtherEngineDetailsBody
    """

    def test_other_engine_details_body_serialization(self):
        """
        Test serialization/deserialization for OtherEngineDetailsBody
        """

        # Construct a json representation of a OtherEngineDetailsBody model
        other_engine_details_body_model_json = {}
        other_engine_details_body_model_json['connection_string'] = '1.2.3.4'
        other_engine_details_body_model_json['engine_type'] = 'netezza'

        # Construct a model instance of OtherEngineDetailsBody by calling from_dict on the json representation
        other_engine_details_body_model = OtherEngineDetailsBody.from_dict(other_engine_details_body_model_json)
        assert other_engine_details_body_model != False

        # Construct a model instance of OtherEngineDetailsBody by calling from_dict on the json representation
        other_engine_details_body_model_dict = OtherEngineDetailsBody.from_dict(other_engine_details_body_model_json).__dict__
        other_engine_details_body_model2 = OtherEngineDetailsBody(**other_engine_details_body_model_dict)

        # Verify the model instances are equivalent
        assert other_engine_details_body_model == other_engine_details_body_model2

        # Convert model instance back to dict and verify no loss of data
        other_engine_details_body_model_json2 = other_engine_details_body_model.to_dict()
        assert other_engine_details_body_model_json2 == other_engine_details_body_model_json


class TestModel_PrestissimoEndpoints:
    """
    Test Class for PrestissimoEndpoints
    """

    def test_prestissimo_endpoints_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEndpoints
        """

        # Construct a json representation of a PrestissimoEndpoints model
        prestissimo_endpoints_model_json = {}
        prestissimo_endpoints_model_json['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model_json['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model_json['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model_json['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model_json['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model_json['view_history_server'] = 'testString'
        prestissimo_endpoints_model_json['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        # Construct a model instance of PrestissimoEndpoints by calling from_dict on the json representation
        prestissimo_endpoints_model = PrestissimoEndpoints.from_dict(prestissimo_endpoints_model_json)
        assert prestissimo_endpoints_model != False

        # Construct a model instance of PrestissimoEndpoints by calling from_dict on the json representation
        prestissimo_endpoints_model_dict = PrestissimoEndpoints.from_dict(prestissimo_endpoints_model_json).__dict__
        prestissimo_endpoints_model2 = PrestissimoEndpoints(**prestissimo_endpoints_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_endpoints_model == prestissimo_endpoints_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_endpoints_model_json2 = prestissimo_endpoints_model.to_dict()
        assert prestissimo_endpoints_model_json2 == prestissimo_endpoints_model_json


class TestModel_PrestissimoEngine:
    """
    Test Class for PrestissimoEngine
    """

    def test_prestissimo_engine_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEngine
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_node_description_body_model = {}  # PrestissimoNodeDescriptionBody
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 1

        prestissimo_endpoints_model = {}  # PrestissimoEndpoints
        prestissimo_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model['view_history_server'] = 'testString'
        prestissimo_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        prestissimo_engine_details_model = {}  # PrestissimoEngineDetails
        prestissimo_engine_details_model['api_key'] = '<api_key>'
        prestissimo_engine_details_model['connection_string'] = '1.2.3.4'
        prestissimo_engine_details_model['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_details_model['endpoints'] = prestissimo_endpoints_model
        prestissimo_engine_details_model['instance_id'] = 'instance_id'
        prestissimo_engine_details_model['managed_by'] = 'fully/self'
        prestissimo_engine_details_model['metastore_host'] = '1.2.3.4'
        prestissimo_engine_details_model['size_config'] = 'starter'
        prestissimo_engine_details_model['worker'] = prestissimo_node_description_body_model

        prestissimo_engine_properties_catalog_model = {}  # PrestissimoEnginePropertiesCatalog
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        engine_properties_oai_gen_configuration_model = {}  # EnginePropertiesOaiGenConfiguration
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        prestissimo_engine_properties_velox_model = {}  # PrestissimoEnginePropertiesVelox
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        prestissimo_engine_properties_oai_gen1_jvm_model = {}  # PrestissimoEnginePropertiesOaiGen1Jvm
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        prestissimo_engine_engine_properties_model = {}  # PrestissimoEngineEngineProperties
        prestissimo_engine_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        remove_engine_properties_configuration_model = {}  # RemoveEnginePropertiesConfiguration
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}  # RemoveEnginePropertiesPrestissimoOaiGenJvm
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        remove_engine_properties_model = {}  # RemoveEngineProperties
        remove_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model['velox'] = ['testString']

        # Construct a json representation of a PrestissimoEngine model
        prestissimo_engine_model_json = {}
        prestissimo_engine_model_json['actions'] = ['update', 'delete']
        prestissimo_engine_model_json['associated_catalogs'] = ['hive_data']
        prestissimo_engine_model_json['build_version'] = '1.0.3.0.0'
        prestissimo_engine_model_json['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_model_json['created_by'] = '<username>@<domain>.com'
        prestissimo_engine_model_json['created_on'] = 38
        prestissimo_engine_model_json['description'] = 'prestissimo engine for running sql queries'
        prestissimo_engine_model_json['engine_details'] = prestissimo_engine_details_model
        prestissimo_engine_model_json['engine_display_name'] = 'sampleEngine'
        prestissimo_engine_model_json['engine_id'] = 'sampleEngine123'
        prestissimo_engine_model_json['engine_properties'] = prestissimo_engine_engine_properties_model
        prestissimo_engine_model_json['engine_restart'] = 'force'
        prestissimo_engine_model_json['external_host_name'] = 'your-hostname.apps.your-domain.com'
        prestissimo_engine_model_json['group_id'] = 'new_group_id'
        prestissimo_engine_model_json['host_name'] = 'xyz-prestissimo-01-prestissimo-svc'
        prestissimo_engine_model_json['origin'] = 'native'
        prestissimo_engine_model_json['port'] = 38
        prestissimo_engine_model_json['region'] = 'us-south'
        prestissimo_engine_model_json['remove_engine_properties'] = remove_engine_properties_model
        prestissimo_engine_model_json['size_config'] = 'starter'
        prestissimo_engine_model_json['status'] = 'running'
        prestissimo_engine_model_json['status_code'] = 38
        prestissimo_engine_model_json['tags'] = ['tag1', 'tag2']
        prestissimo_engine_model_json['type'] = 'prestissimo'
        prestissimo_engine_model_json['version'] = '1.2.0'
        prestissimo_engine_model_json['worker'] = prestissimo_node_description_body_model

        # Construct a model instance of PrestissimoEngine by calling from_dict on the json representation
        prestissimo_engine_model = PrestissimoEngine.from_dict(prestissimo_engine_model_json)
        assert prestissimo_engine_model != False

        # Construct a model instance of PrestissimoEngine by calling from_dict on the json representation
        prestissimo_engine_model_dict = PrestissimoEngine.from_dict(prestissimo_engine_model_json).__dict__
        prestissimo_engine_model2 = PrestissimoEngine(**prestissimo_engine_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_model == prestissimo_engine_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_model_json2 = prestissimo_engine_model.to_dict()
        assert prestissimo_engine_model_json2 == prestissimo_engine_model_json


class TestModel_PrestissimoEngineCollection:
    """
    Test Class for PrestissimoEngineCollection
    """

    def test_prestissimo_engine_collection_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEngineCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_node_description_body_model = {}  # PrestissimoNodeDescriptionBody
        prestissimo_node_description_body_model['node_type'] = 'bx2.4x16'
        prestissimo_node_description_body_model['quantity'] = 1

        prestissimo_endpoints_model = {}  # PrestissimoEndpoints
        prestissimo_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model['view_history_server'] = 'testString'
        prestissimo_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        prestissimo_engine_details_model = {}  # PrestissimoEngineDetails
        prestissimo_engine_details_model['api_key'] = '<api_key>'
        prestissimo_engine_details_model['connection_string'] = '1.2.3.4'
        prestissimo_engine_details_model['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_details_model['endpoints'] = prestissimo_endpoints_model
        prestissimo_engine_details_model['instance_id'] = 'instance_id'
        prestissimo_engine_details_model['managed_by'] = 'fully/self'
        prestissimo_engine_details_model['metastore_host'] = '1.2.3.4'
        prestissimo_engine_details_model['size_config'] = 'starter'
        prestissimo_engine_details_model['worker'] = prestissimo_node_description_body_model

        prestissimo_engine_properties_catalog_model = {}  # PrestissimoEnginePropertiesCatalog
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        engine_properties_oai_gen_configuration_model = {}  # EnginePropertiesOaiGenConfiguration
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        prestissimo_engine_properties_velox_model = {}  # PrestissimoEnginePropertiesVelox
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        prestissimo_engine_properties_oai_gen1_jvm_model = {}  # PrestissimoEnginePropertiesOaiGen1Jvm
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        prestissimo_engine_engine_properties_model = {}  # PrestissimoEngineEngineProperties
        prestissimo_engine_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        remove_engine_properties_configuration_model = {}  # RemoveEnginePropertiesConfiguration
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}  # RemoveEnginePropertiesPrestissimoOaiGenJvm
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        remove_engine_properties_model = {}  # RemoveEngineProperties
        remove_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model['velox'] = ['testString']

        prestissimo_engine_model = {}  # PrestissimoEngine
        prestissimo_engine_model['actions'] = ['view', 'use', 'update', 'select', 'access_ui', 'associate', 'disassociate', 'restart', 'pause', 'resume', 'grant', 'revoke', 'delete', 'create', 'scale']
        prestissimo_engine_model['associated_catalogs'] = ['hive_data']
        prestissimo_engine_model['build_version'] = '1.1.0.0.0'
        prestissimo_engine_model['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_model['created_by'] = '<username>@<domain>.com'
        prestissimo_engine_model['created_on'] = 38
        prestissimo_engine_model['description'] = 'prestissimo engine for running sql queries'
        prestissimo_engine_model['engine_details'] = prestissimo_engine_details_model
        prestissimo_engine_model['engine_display_name'] = 'starter'
        prestissimo_engine_model['engine_id'] = 'prestissimo511'
        prestissimo_engine_model['engine_properties'] = prestissimo_engine_engine_properties_model
        prestissimo_engine_model['engine_restart'] = 'force'
        prestissimo_engine_model['external_host_name'] = 'your-hostname.apps.your-domain.com'
        prestissimo_engine_model['group_id'] = 'prestissimo511'
        prestissimo_engine_model['host_name'] = '1234-xyz456-abc4321.databases.appdomain.cloud'
        prestissimo_engine_model['origin'] = 'native'
        prestissimo_engine_model['port'] = 30156
        prestissimo_engine_model['region'] = 'us-south'
        prestissimo_engine_model['remove_engine_properties'] = remove_engine_properties_model
        prestissimo_engine_model['size_config'] = 'starter'
        prestissimo_engine_model['status'] = 'running'
        prestissimo_engine_model['status_code'] = 0
        prestissimo_engine_model['tags'] = ['tag1', 'tag2']
        prestissimo_engine_model['type'] = 'prestissimo'
        prestissimo_engine_model['version'] = 'v0.282'
        prestissimo_engine_model['worker'] = prestissimo_node_description_body_model

        # Construct a json representation of a PrestissimoEngineCollection model
        prestissimo_engine_collection_model_json = {}
        prestissimo_engine_collection_model_json['prestissimo_engines'] = [prestissimo_engine_model]

        # Construct a model instance of PrestissimoEngineCollection by calling from_dict on the json representation
        prestissimo_engine_collection_model = PrestissimoEngineCollection.from_dict(prestissimo_engine_collection_model_json)
        assert prestissimo_engine_collection_model != False

        # Construct a model instance of PrestissimoEngineCollection by calling from_dict on the json representation
        prestissimo_engine_collection_model_dict = PrestissimoEngineCollection.from_dict(prestissimo_engine_collection_model_json).__dict__
        prestissimo_engine_collection_model2 = PrestissimoEngineCollection(**prestissimo_engine_collection_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_collection_model == prestissimo_engine_collection_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_collection_model_json2 = prestissimo_engine_collection_model.to_dict()
        assert prestissimo_engine_collection_model_json2 == prestissimo_engine_collection_model_json


class TestModel_PrestissimoEngineDetails:
    """
    Test Class for PrestissimoEngineDetails
    """

    def test_prestissimo_engine_details_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEngineDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_node_description_body_model = {}  # PrestissimoNodeDescriptionBody
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        prestissimo_endpoints_model = {}  # PrestissimoEndpoints
        prestissimo_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        prestissimo_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        prestissimo_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        prestissimo_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        prestissimo_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        prestissimo_endpoints_model['view_history_server'] = 'testString'
        prestissimo_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'

        # Construct a json representation of a PrestissimoEngineDetails model
        prestissimo_engine_details_model_json = {}
        prestissimo_engine_details_model_json['api_key'] = '<api_key>'
        prestissimo_engine_details_model_json['connection_string'] = '1.2.3.4'
        prestissimo_engine_details_model_json['coordinator'] = prestissimo_node_description_body_model
        prestissimo_engine_details_model_json['endpoints'] = prestissimo_endpoints_model
        prestissimo_engine_details_model_json['instance_id'] = 'instance_id'
        prestissimo_engine_details_model_json['managed_by'] = 'fully/self'
        prestissimo_engine_details_model_json['metastore_host'] = '1.2.3.4'
        prestissimo_engine_details_model_json['size_config'] = 'starter'
        prestissimo_engine_details_model_json['worker'] = prestissimo_node_description_body_model

        # Construct a model instance of PrestissimoEngineDetails by calling from_dict on the json representation
        prestissimo_engine_details_model = PrestissimoEngineDetails.from_dict(prestissimo_engine_details_model_json)
        assert prestissimo_engine_details_model != False

        # Construct a model instance of PrestissimoEngineDetails by calling from_dict on the json representation
        prestissimo_engine_details_model_dict = PrestissimoEngineDetails.from_dict(prestissimo_engine_details_model_json).__dict__
        prestissimo_engine_details_model2 = PrestissimoEngineDetails(**prestissimo_engine_details_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_details_model == prestissimo_engine_details_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_details_model_json2 = prestissimo_engine_details_model.to_dict()
        assert prestissimo_engine_details_model_json2 == prestissimo_engine_details_model_json


class TestModel_PrestissimoEngineEngineProperties:
    """
    Test Class for PrestissimoEngineEngineProperties
    """

    def test_prestissimo_engine_engine_properties_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEngineEngineProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_engine_properties_catalog_model = {}  # PrestissimoEnginePropertiesCatalog
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        prestissimo_node_description_body_model = {}  # PrestissimoNodeDescriptionBody
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        engine_properties_oai_gen_configuration_model = {}  # EnginePropertiesOaiGenConfiguration
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        prestissimo_engine_properties_velox_model = {}  # PrestissimoEnginePropertiesVelox
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        prestissimo_engine_properties_oai_gen1_jvm_model = {}  # PrestissimoEnginePropertiesOaiGen1Jvm
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        # Construct a json representation of a PrestissimoEngineEngineProperties model
        prestissimo_engine_engine_properties_model_json = {}
        prestissimo_engine_engine_properties_model_json['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model_json['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model_json['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model_json['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        # Construct a model instance of PrestissimoEngineEngineProperties by calling from_dict on the json representation
        prestissimo_engine_engine_properties_model = PrestissimoEngineEngineProperties.from_dict(prestissimo_engine_engine_properties_model_json)
        assert prestissimo_engine_engine_properties_model != False

        # Construct a model instance of PrestissimoEngineEngineProperties by calling from_dict on the json representation
        prestissimo_engine_engine_properties_model_dict = PrestissimoEngineEngineProperties.from_dict(prestissimo_engine_engine_properties_model_json).__dict__
        prestissimo_engine_engine_properties_model2 = PrestissimoEngineEngineProperties(**prestissimo_engine_engine_properties_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_engine_properties_model == prestissimo_engine_engine_properties_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_engine_properties_model_json2 = prestissimo_engine_engine_properties_model.to_dict()
        assert prestissimo_engine_engine_properties_model_json2 == prestissimo_engine_engine_properties_model_json


class TestModel_PrestissimoEnginePatch:
    """
    Test Class for PrestissimoEnginePatch
    """

    def test_prestissimo_engine_patch_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEnginePatch
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_engine_properties_catalog_model = {}  # PrestissimoEnginePropertiesCatalog
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        prestissimo_node_description_body_model = {}  # PrestissimoNodeDescriptionBody
        prestissimo_node_description_body_model['node_type'] = 'worker'
        prestissimo_node_description_body_model['quantity'] = 38

        engine_properties_oai_gen_configuration_model = {}  # EnginePropertiesOaiGenConfiguration
        engine_properties_oai_gen_configuration_model['coordinator'] = prestissimo_node_description_body_model
        engine_properties_oai_gen_configuration_model['worker'] = prestissimo_node_description_body_model

        prestissimo_engine_properties_velox_model = {}  # PrestissimoEnginePropertiesVelox
        prestissimo_engine_properties_velox_model['velox_property'] = ['testString']

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        prestissimo_engine_properties_oai_gen1_jvm_model = {}  # PrestissimoEnginePropertiesOaiGen1Jvm
        prestissimo_engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model

        prestissimo_engine_engine_properties_model = {}  # PrestissimoEngineEngineProperties
        prestissimo_engine_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        prestissimo_engine_engine_properties_model['configuration'] = engine_properties_oai_gen_configuration_model
        prestissimo_engine_engine_properties_model['velox'] = prestissimo_engine_properties_velox_model
        prestissimo_engine_engine_properties_model['jvm'] = prestissimo_engine_properties_oai_gen1_jvm_model

        remove_engine_properties_configuration_model = {}  # RemoveEnginePropertiesConfiguration
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}  # RemoveEnginePropertiesPrestissimoOaiGenJvm
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        remove_engine_properties_model = {}  # RemoveEngineProperties
        remove_engine_properties_model['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model['velox'] = ['testString']

        # Construct a json representation of a PrestissimoEnginePatch model
        prestissimo_engine_patch_model_json = {}
        prestissimo_engine_patch_model_json['description'] = 'updated description for prestissimo engine'
        prestissimo_engine_patch_model_json['engine_display_name'] = 'sampleEngine'
        prestissimo_engine_patch_model_json['engine_properties'] = prestissimo_engine_engine_properties_model
        prestissimo_engine_patch_model_json['engine_restart'] = 'force'
        prestissimo_engine_patch_model_json['remove_engine_properties'] = remove_engine_properties_model
        prestissimo_engine_patch_model_json['tags'] = ['tag1', 'tag2']

        # Construct a model instance of PrestissimoEnginePatch by calling from_dict on the json representation
        prestissimo_engine_patch_model = PrestissimoEnginePatch.from_dict(prestissimo_engine_patch_model_json)
        assert prestissimo_engine_patch_model != False

        # Construct a model instance of PrestissimoEnginePatch by calling from_dict on the json representation
        prestissimo_engine_patch_model_dict = PrestissimoEnginePatch.from_dict(prestissimo_engine_patch_model_json).__dict__
        prestissimo_engine_patch_model2 = PrestissimoEnginePatch(**prestissimo_engine_patch_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_patch_model == prestissimo_engine_patch_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_patch_model_json2 = prestissimo_engine_patch_model.to_dict()
        assert prestissimo_engine_patch_model_json2 == prestissimo_engine_patch_model_json


class TestModel_PrestissimoEnginePropertiesCatalog:
    """
    Test Class for PrestissimoEnginePropertiesCatalog
    """

    def test_prestissimo_engine_properties_catalog_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEnginePropertiesCatalog
        """

        # Construct a json representation of a PrestissimoEnginePropertiesCatalog model
        prestissimo_engine_properties_catalog_model_json = {}
        prestissimo_engine_properties_catalog_model_json['catalog_name'] = ['testString']

        # Construct a model instance of PrestissimoEnginePropertiesCatalog by calling from_dict on the json representation
        prestissimo_engine_properties_catalog_model = PrestissimoEnginePropertiesCatalog.from_dict(prestissimo_engine_properties_catalog_model_json)
        assert prestissimo_engine_properties_catalog_model != False

        # Construct a model instance of PrestissimoEnginePropertiesCatalog by calling from_dict on the json representation
        prestissimo_engine_properties_catalog_model_dict = PrestissimoEnginePropertiesCatalog.from_dict(prestissimo_engine_properties_catalog_model_json).__dict__
        prestissimo_engine_properties_catalog_model2 = PrestissimoEnginePropertiesCatalog(**prestissimo_engine_properties_catalog_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_properties_catalog_model == prestissimo_engine_properties_catalog_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_properties_catalog_model_json2 = prestissimo_engine_properties_catalog_model.to_dict()
        assert prestissimo_engine_properties_catalog_model_json2 == prestissimo_engine_properties_catalog_model_json


class TestModel_PrestissimoEnginePropertiesOaiGen1Jvm:
    """
    Test Class for PrestissimoEnginePropertiesOaiGen1Jvm
    """

    def test_prestissimo_engine_properties_oai_gen1_jvm_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEnginePropertiesOaiGen1Jvm
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        # Construct a json representation of a PrestissimoEnginePropertiesOaiGen1Jvm model
        prestissimo_engine_properties_oai_gen1_jvm_model_json = {}
        prestissimo_engine_properties_oai_gen1_jvm_model_json['coordinator'] = node_description_body_model

        # Construct a model instance of PrestissimoEnginePropertiesOaiGen1Jvm by calling from_dict on the json representation
        prestissimo_engine_properties_oai_gen1_jvm_model = PrestissimoEnginePropertiesOaiGen1Jvm.from_dict(prestissimo_engine_properties_oai_gen1_jvm_model_json)
        assert prestissimo_engine_properties_oai_gen1_jvm_model != False

        # Construct a model instance of PrestissimoEnginePropertiesOaiGen1Jvm by calling from_dict on the json representation
        prestissimo_engine_properties_oai_gen1_jvm_model_dict = PrestissimoEnginePropertiesOaiGen1Jvm.from_dict(prestissimo_engine_properties_oai_gen1_jvm_model_json).__dict__
        prestissimo_engine_properties_oai_gen1_jvm_model2 = PrestissimoEnginePropertiesOaiGen1Jvm(**prestissimo_engine_properties_oai_gen1_jvm_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_properties_oai_gen1_jvm_model == prestissimo_engine_properties_oai_gen1_jvm_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_properties_oai_gen1_jvm_model_json2 = prestissimo_engine_properties_oai_gen1_jvm_model.to_dict()
        assert prestissimo_engine_properties_oai_gen1_jvm_model_json2 == prestissimo_engine_properties_oai_gen1_jvm_model_json


class TestModel_PrestissimoEnginePropertiesVelox:
    """
    Test Class for PrestissimoEnginePropertiesVelox
    """

    def test_prestissimo_engine_properties_velox_serialization(self):
        """
        Test serialization/deserialization for PrestissimoEnginePropertiesVelox
        """

        # Construct a json representation of a PrestissimoEnginePropertiesVelox model
        prestissimo_engine_properties_velox_model_json = {}
        prestissimo_engine_properties_velox_model_json['velox_property'] = ['testString']

        # Construct a model instance of PrestissimoEnginePropertiesVelox by calling from_dict on the json representation
        prestissimo_engine_properties_velox_model = PrestissimoEnginePropertiesVelox.from_dict(prestissimo_engine_properties_velox_model_json)
        assert prestissimo_engine_properties_velox_model != False

        # Construct a model instance of PrestissimoEnginePropertiesVelox by calling from_dict on the json representation
        prestissimo_engine_properties_velox_model_dict = PrestissimoEnginePropertiesVelox.from_dict(prestissimo_engine_properties_velox_model_json).__dict__
        prestissimo_engine_properties_velox_model2 = PrestissimoEnginePropertiesVelox(**prestissimo_engine_properties_velox_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_engine_properties_velox_model == prestissimo_engine_properties_velox_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_engine_properties_velox_model_json2 = prestissimo_engine_properties_velox_model.to_dict()
        assert prestissimo_engine_properties_velox_model_json2 == prestissimo_engine_properties_velox_model_json


class TestModel_PrestissimoNodeDescriptionBody:
    """
    Test Class for PrestissimoNodeDescriptionBody
    """

    def test_prestissimo_node_description_body_serialization(self):
        """
        Test serialization/deserialization for PrestissimoNodeDescriptionBody
        """

        # Construct a json representation of a PrestissimoNodeDescriptionBody model
        prestissimo_node_description_body_model_json = {}
        prestissimo_node_description_body_model_json['node_type'] = 'worker'
        prestissimo_node_description_body_model_json['quantity'] = 38

        # Construct a model instance of PrestissimoNodeDescriptionBody by calling from_dict on the json representation
        prestissimo_node_description_body_model = PrestissimoNodeDescriptionBody.from_dict(prestissimo_node_description_body_model_json)
        assert prestissimo_node_description_body_model != False

        # Construct a model instance of PrestissimoNodeDescriptionBody by calling from_dict on the json representation
        prestissimo_node_description_body_model_dict = PrestissimoNodeDescriptionBody.from_dict(prestissimo_node_description_body_model_json).__dict__
        prestissimo_node_description_body_model2 = PrestissimoNodeDescriptionBody(**prestissimo_node_description_body_model_dict)

        # Verify the model instances are equivalent
        assert prestissimo_node_description_body_model == prestissimo_node_description_body_model2

        # Convert model instance back to dict and verify no loss of data
        prestissimo_node_description_body_model_json2 = prestissimo_node_description_body_model.to_dict()
        assert prestissimo_node_description_body_model_json2 == prestissimo_node_description_body_model_json


class TestModel_PrestoEngine:
    """
    Test Class for PrestoEngine
    """

    def test_presto_engine_serialization(self):
        """
        Test serialization/deserialization for PrestoEngine
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_model = {}  # NodeDescription
        node_description_model['node_type'] = 'bx2.4x16'
        node_description_model['quantity'] = 1

        driver_model = {}  # Driver
        driver_model['connection_type'] = 'saphana'
        driver_model['driver_id'] = 'saphanadriver123'
        driver_model['driver_name'] = 'saphanadriver-1.2.3'
        driver_model['driver_version'] = '1.2.3'

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        engine_details_body_model = {}  # EngineDetailsBody
        engine_details_body_model['api_key'] = '<api_key>'
        engine_details_body_model['connection_string'] = '1.2.3.4'
        engine_details_body_model['coordinator'] = node_description_body_model
        engine_details_body_model['instance_id'] = 'instance_id'
        engine_details_body_model['managed_by'] = 'fully/self'
        engine_details_body_model['size_config'] = 'starter'
        engine_details_body_model['worker'] = node_description_body_model

        presto_engine_properties_catalog_model = {}  # PrestoEnginePropertiesCatalog
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        engine_properties_oai_gen1_configuration_model = {}  # EnginePropertiesOaiGen1Configuration
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        presto_engine_properties_event_listener_model = {}  # PrestoEnginePropertiesEventListener
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        presto_engine_properties_global_model = {}  # PrestoEnginePropertiesGlobal
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        engine_properties_oai_gen1_jvm_model = {}  # EnginePropertiesOaiGen1Jvm
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        presto_engine_properties_jmx_model = {}  # PrestoEnginePropertiesJMX
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        engine_properties_log_configuration_model = {}  # EnginePropertiesLogConfiguration
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        presto_engine_engine_properties_model = {}  # PrestoEngineEngineProperties
        presto_engine_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model['log_config'] = engine_properties_log_configuration_model

        remove_engine_properties_oai_gen_configuration_model = {}  # RemoveEnginePropertiesOaiGenConfiguration
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        remove_engine_properties_oai_gen_jvm_model = {}  # RemoveEnginePropertiesOaiGenJvm
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        remove_engine_properties_log_config_model = {}  # RemoveEnginePropertiesLogConfig
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        presto_engine_patch_remove_engine_properties_model = {}  # PrestoEnginePatchRemoveEngineProperties
        presto_engine_patch_remove_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['log_config'] = remove_engine_properties_log_config_model

        # Construct a json representation of a PrestoEngine model
        presto_engine_model_json = {}
        presto_engine_model_json['actions'] = ['update', 'delete']
        presto_engine_model_json['associated_catalogs'] = ['iceberg_data', 'hive_data']
        presto_engine_model_json['build_version'] = '1.0.3.0.0'
        presto_engine_model_json['coordinator'] = node_description_model
        presto_engine_model_json['created_by'] = '<username>@<domain>.com'
        presto_engine_model_json['created_on'] = 38
        presto_engine_model_json['description'] = 'presto engine for running sql queries'
        presto_engine_model_json['drivers'] = [driver_model]
        presto_engine_model_json['engine_details'] = engine_details_body_model
        presto_engine_model_json['engine_display_name'] = 'sampleEngine'
        presto_engine_model_json['engine_id'] = 'sampleEngine123'
        presto_engine_model_json['engine_properties'] = presto_engine_engine_properties_model
        presto_engine_model_json['engine_restart'] = 'force'
        presto_engine_model_json['external_host_name'] = 'your-hostname.apps.your-domain.com'
        presto_engine_model_json['group_id'] = 'new_group_id'
        presto_engine_model_json['host_name'] = 'ibm-lh-lakehouse-presto-01-presto-svc'
        presto_engine_model_json['origin'] = 'native'
        presto_engine_model_json['port'] = 38
        presto_engine_model_json['region'] = 'us-south'
        presto_engine_model_json['remove_engine_properties'] = presto_engine_patch_remove_engine_properties_model
        presto_engine_model_json['size_config'] = 'starter'
        presto_engine_model_json['status'] = 'running'
        presto_engine_model_json['status_code'] = 38
        presto_engine_model_json['tags'] = ['tag1', 'tag2']
        presto_engine_model_json['type'] = 'presto'
        presto_engine_model_json['version'] = '1.2.0'
        presto_engine_model_json['worker'] = node_description_model

        # Construct a model instance of PrestoEngine by calling from_dict on the json representation
        presto_engine_model = PrestoEngine.from_dict(presto_engine_model_json)
        assert presto_engine_model != False

        # Construct a model instance of PrestoEngine by calling from_dict on the json representation
        presto_engine_model_dict = PrestoEngine.from_dict(presto_engine_model_json).__dict__
        presto_engine_model2 = PrestoEngine(**presto_engine_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_model == presto_engine_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_model_json2 = presto_engine_model.to_dict()
        assert presto_engine_model_json2 == presto_engine_model_json


class TestModel_PrestoEngineCollection:
    """
    Test Class for PrestoEngineCollection
    """

    def test_presto_engine_collection_serialization(self):
        """
        Test serialization/deserialization for PrestoEngineCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        node_description_model = {}  # NodeDescription
        node_description_model['node_type'] = 'bx2.4x16'
        node_description_model['quantity'] = 1

        driver_model = {}  # Driver
        driver_model['connection_type'] = 'saphana'
        driver_model['driver_id'] = 'saphanadriver123'
        driver_model['driver_name'] = 'saphanadriver-1.2.3'
        driver_model['driver_version'] = '1.2.3'

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        engine_details_body_model = {}  # EngineDetailsBody
        engine_details_body_model['api_key'] = '<api_key>'
        engine_details_body_model['connection_string'] = '1.2.3.4'
        engine_details_body_model['coordinator'] = node_description_body_model
        engine_details_body_model['instance_id'] = 'instance_id'
        engine_details_body_model['managed_by'] = 'fully/self'
        engine_details_body_model['size_config'] = 'starter'
        engine_details_body_model['worker'] = node_description_body_model

        presto_engine_properties_catalog_model = {}  # PrestoEnginePropertiesCatalog
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        engine_properties_oai_gen1_configuration_model = {}  # EnginePropertiesOaiGen1Configuration
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        presto_engine_properties_event_listener_model = {}  # PrestoEnginePropertiesEventListener
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        presto_engine_properties_global_model = {}  # PrestoEnginePropertiesGlobal
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        engine_properties_oai_gen1_jvm_model = {}  # EnginePropertiesOaiGen1Jvm
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        presto_engine_properties_jmx_model = {}  # PrestoEnginePropertiesJMX
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        engine_properties_log_configuration_model = {}  # EnginePropertiesLogConfiguration
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        presto_engine_engine_properties_model = {}  # PrestoEngineEngineProperties
        presto_engine_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model['log_config'] = engine_properties_log_configuration_model

        remove_engine_properties_oai_gen_configuration_model = {}  # RemoveEnginePropertiesOaiGenConfiguration
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        remove_engine_properties_oai_gen_jvm_model = {}  # RemoveEnginePropertiesOaiGenJvm
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        remove_engine_properties_log_config_model = {}  # RemoveEnginePropertiesLogConfig
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        presto_engine_patch_remove_engine_properties_model = {}  # PrestoEnginePatchRemoveEngineProperties
        presto_engine_patch_remove_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['log_config'] = remove_engine_properties_log_config_model

        presto_engine_model = {}  # PrestoEngine
        presto_engine_model['actions'] = ['view', 'use', 'update', 'select', 'access_ui', 'associate', 'disassociate', 'restart', 'pause', 'resume', 'grant', 'revoke', 'delete', 'create', 'scale']
        presto_engine_model['associated_catalogs'] = ['iceberg_data', 'hive_data']
        presto_engine_model['build_version'] = '1.1.0.0.0'
        presto_engine_model['coordinator'] = node_description_model
        presto_engine_model['created_by'] = '<username>@<domain>.com'
        presto_engine_model['created_on'] = 38
        presto_engine_model['description'] = 'presto engine for running sql queries'
        presto_engine_model['drivers'] = [driver_model]
        presto_engine_model['engine_details'] = engine_details_body_model
        presto_engine_model['engine_display_name'] = 'starter'
        presto_engine_model['engine_id'] = 'presto511'
        presto_engine_model['engine_properties'] = presto_engine_engine_properties_model
        presto_engine_model['engine_restart'] = 'force'
        presto_engine_model['external_host_name'] = 'your-hostname.apps.your-domain.com'
        presto_engine_model['group_id'] = 'presto511'
        presto_engine_model['host_name'] = '1234-xyz456-abc4321.databases.appdomain.cloud'
        presto_engine_model['origin'] = 'native'
        presto_engine_model['port'] = 30156
        presto_engine_model['region'] = 'us-south'
        presto_engine_model['remove_engine_properties'] = presto_engine_patch_remove_engine_properties_model
        presto_engine_model['size_config'] = 'starter'
        presto_engine_model['status'] = 'running'
        presto_engine_model['status_code'] = 0
        presto_engine_model['tags'] = ['tag1', 'tag2']
        presto_engine_model['type'] = 'presto'
        presto_engine_model['version'] = 'v0.282'
        presto_engine_model['worker'] = node_description_model

        # Construct a json representation of a PrestoEngineCollection model
        presto_engine_collection_model_json = {}
        presto_engine_collection_model_json['presto_engines'] = [presto_engine_model]

        # Construct a model instance of PrestoEngineCollection by calling from_dict on the json representation
        presto_engine_collection_model = PrestoEngineCollection.from_dict(presto_engine_collection_model_json)
        assert presto_engine_collection_model != False

        # Construct a model instance of PrestoEngineCollection by calling from_dict on the json representation
        presto_engine_collection_model_dict = PrestoEngineCollection.from_dict(presto_engine_collection_model_json).__dict__
        presto_engine_collection_model2 = PrestoEngineCollection(**presto_engine_collection_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_collection_model == presto_engine_collection_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_collection_model_json2 = presto_engine_collection_model.to_dict()
        assert presto_engine_collection_model_json2 == presto_engine_collection_model_json


class TestModel_PrestoEngineEngineProperties:
    """
    Test Class for PrestoEngineEngineProperties
    """

    def test_presto_engine_engine_properties_serialization(self):
        """
        Test serialization/deserialization for PrestoEngineEngineProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        presto_engine_properties_catalog_model = {}  # PrestoEnginePropertiesCatalog
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        engine_properties_oai_gen1_configuration_model = {}  # EnginePropertiesOaiGen1Configuration
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        presto_engine_properties_event_listener_model = {}  # PrestoEnginePropertiesEventListener
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        presto_engine_properties_global_model = {}  # PrestoEnginePropertiesGlobal
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        engine_properties_oai_gen1_jvm_model = {}  # EnginePropertiesOaiGen1Jvm
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        presto_engine_properties_jmx_model = {}  # PrestoEnginePropertiesJMX
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        engine_properties_log_configuration_model = {}  # EnginePropertiesLogConfiguration
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        # Construct a json representation of a PrestoEngineEngineProperties model
        presto_engine_engine_properties_model_json = {}
        presto_engine_engine_properties_model_json['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model_json['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model_json['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model_json['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model_json['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model_json['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model_json['log_config'] = engine_properties_log_configuration_model

        # Construct a model instance of PrestoEngineEngineProperties by calling from_dict on the json representation
        presto_engine_engine_properties_model = PrestoEngineEngineProperties.from_dict(presto_engine_engine_properties_model_json)
        assert presto_engine_engine_properties_model != False

        # Construct a model instance of PrestoEngineEngineProperties by calling from_dict on the json representation
        presto_engine_engine_properties_model_dict = PrestoEngineEngineProperties.from_dict(presto_engine_engine_properties_model_json).__dict__
        presto_engine_engine_properties_model2 = PrestoEngineEngineProperties(**presto_engine_engine_properties_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_engine_properties_model == presto_engine_engine_properties_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_engine_properties_model_json2 = presto_engine_engine_properties_model.to_dict()
        assert presto_engine_engine_properties_model_json2 == presto_engine_engine_properties_model_json


class TestModel_PrestoEnginePatch:
    """
    Test Class for PrestoEnginePatch
    """

    def test_presto_engine_patch_serialization(self):
        """
        Test serialization/deserialization for PrestoEnginePatch
        """

        # Construct dict forms of any model objects needed in order to build this model.

        presto_engine_properties_catalog_model = {}  # PrestoEnginePropertiesCatalog
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        node_description_body_model = {}  # NodeDescriptionBody
        node_description_body_model['node_type'] = 'worker'
        node_description_body_model['quantity'] = 38

        engine_properties_oai_gen1_configuration_model = {}  # EnginePropertiesOaiGen1Configuration
        engine_properties_oai_gen1_configuration_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_configuration_model['worker'] = node_description_body_model

        presto_engine_properties_event_listener_model = {}  # PrestoEnginePropertiesEventListener
        presto_engine_properties_event_listener_model['event_listener_property'] = 'testString'

        presto_engine_properties_global_model = {}  # PrestoEnginePropertiesGlobal
        presto_engine_properties_global_model['global_property'] = 'enable-mixed-case-support:true'

        engine_properties_oai_gen1_jvm_model = {}  # EnginePropertiesOaiGen1Jvm
        engine_properties_oai_gen1_jvm_model['coordinator'] = node_description_body_model
        engine_properties_oai_gen1_jvm_model['worker'] = node_description_body_model

        presto_engine_properties_jmx_model = {}  # PrestoEnginePropertiesJMX
        presto_engine_properties_jmx_model['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        engine_properties_log_configuration_model = {}  # EnginePropertiesLogConfiguration
        engine_properties_log_configuration_model['coordinator'] = node_description_body_model
        engine_properties_log_configuration_model['worker'] = node_description_body_model

        presto_engine_engine_properties_model = {}  # PrestoEngineEngineProperties
        presto_engine_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_engine_properties_model['configuration'] = engine_properties_oai_gen1_configuration_model
        presto_engine_engine_properties_model['event_listener'] = presto_engine_properties_event_listener_model
        presto_engine_engine_properties_model['global'] = presto_engine_properties_global_model
        presto_engine_engine_properties_model['jvm'] = engine_properties_oai_gen1_jvm_model
        presto_engine_engine_properties_model['jmx_exporter_config'] = presto_engine_properties_jmx_model
        presto_engine_engine_properties_model['log_config'] = engine_properties_log_configuration_model

        remove_engine_properties_oai_gen_configuration_model = {}  # RemoveEnginePropertiesOaiGenConfiguration
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        remove_engine_properties_oai_gen_jvm_model = {}  # RemoveEnginePropertiesOaiGenJvm
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        remove_engine_properties_log_config_model = {}  # RemoveEnginePropertiesLogConfig
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        presto_engine_patch_remove_engine_properties_model = {}  # PrestoEnginePatchRemoveEngineProperties
        presto_engine_patch_remove_engine_properties_model['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model['log_config'] = remove_engine_properties_log_config_model

        # Construct a json representation of a PrestoEnginePatch model
        presto_engine_patch_model_json = {}
        presto_engine_patch_model_json['description'] = 'updated description for presto engine'
        presto_engine_patch_model_json['engine_display_name'] = 'sampleEngine'
        presto_engine_patch_model_json['engine_properties'] = presto_engine_engine_properties_model
        presto_engine_patch_model_json['engine_restart'] = 'force'
        presto_engine_patch_model_json['remove_engine_properties'] = presto_engine_patch_remove_engine_properties_model
        presto_engine_patch_model_json['tags'] = ['tag1', 'tag2']

        # Construct a model instance of PrestoEnginePatch by calling from_dict on the json representation
        presto_engine_patch_model = PrestoEnginePatch.from_dict(presto_engine_patch_model_json)
        assert presto_engine_patch_model != False

        # Construct a model instance of PrestoEnginePatch by calling from_dict on the json representation
        presto_engine_patch_model_dict = PrestoEnginePatch.from_dict(presto_engine_patch_model_json).__dict__
        presto_engine_patch_model2 = PrestoEnginePatch(**presto_engine_patch_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_patch_model == presto_engine_patch_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_patch_model_json2 = presto_engine_patch_model.to_dict()
        assert presto_engine_patch_model_json2 == presto_engine_patch_model_json


class TestModel_PrestoEnginePatchRemoveEngineProperties:
    """
    Test Class for PrestoEnginePatchRemoveEngineProperties
    """

    def test_presto_engine_patch_remove_engine_properties_serialization(self):
        """
        Test serialization/deserialization for PrestoEnginePatchRemoveEngineProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        presto_engine_properties_catalog_model = {}  # PrestoEnginePropertiesCatalog
        presto_engine_properties_catalog_model['catalog_name'] = 'testString'

        remove_engine_properties_oai_gen_configuration_model = {}  # RemoveEnginePropertiesOaiGenConfiguration
        remove_engine_properties_oai_gen_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model['worker'] = ['testString']

        remove_engine_properties_oai_gen_jvm_model = {}  # RemoveEnginePropertiesOaiGenJvm
        remove_engine_properties_oai_gen_jvm_model['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model['worker'] = ['testString']

        remove_engine_properties_log_config_model = {}  # RemoveEnginePropertiesLogConfig
        remove_engine_properties_log_config_model['coordinator'] = ['testString']
        remove_engine_properties_log_config_model['worker'] = ['testString']

        # Construct a json representation of a PrestoEnginePatchRemoveEngineProperties model
        presto_engine_patch_remove_engine_properties_model_json = {}
        presto_engine_patch_remove_engine_properties_model_json['catalog'] = presto_engine_properties_catalog_model
        presto_engine_patch_remove_engine_properties_model_json['configuration'] = remove_engine_properties_oai_gen_configuration_model
        presto_engine_patch_remove_engine_properties_model_json['jvm'] = remove_engine_properties_oai_gen_jvm_model
        presto_engine_patch_remove_engine_properties_model_json['event_listener'] = ['testString']
        presto_engine_patch_remove_engine_properties_model_json['global'] = ['testString']
        presto_engine_patch_remove_engine_properties_model_json['jmx_exporter_config'] = ['testString']
        presto_engine_patch_remove_engine_properties_model_json['log_config'] = remove_engine_properties_log_config_model

        # Construct a model instance of PrestoEnginePatchRemoveEngineProperties by calling from_dict on the json representation
        presto_engine_patch_remove_engine_properties_model = PrestoEnginePatchRemoveEngineProperties.from_dict(presto_engine_patch_remove_engine_properties_model_json)
        assert presto_engine_patch_remove_engine_properties_model != False

        # Construct a model instance of PrestoEnginePatchRemoveEngineProperties by calling from_dict on the json representation
        presto_engine_patch_remove_engine_properties_model_dict = PrestoEnginePatchRemoveEngineProperties.from_dict(presto_engine_patch_remove_engine_properties_model_json).__dict__
        presto_engine_patch_remove_engine_properties_model2 = PrestoEnginePatchRemoveEngineProperties(**presto_engine_patch_remove_engine_properties_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_patch_remove_engine_properties_model == presto_engine_patch_remove_engine_properties_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_patch_remove_engine_properties_model_json2 = presto_engine_patch_remove_engine_properties_model.to_dict()
        assert presto_engine_patch_remove_engine_properties_model_json2 == presto_engine_patch_remove_engine_properties_model_json


class TestModel_PrestoEnginePropertiesCatalog:
    """
    Test Class for PrestoEnginePropertiesCatalog
    """

    def test_presto_engine_properties_catalog_serialization(self):
        """
        Test serialization/deserialization for PrestoEnginePropertiesCatalog
        """

        # Construct a json representation of a PrestoEnginePropertiesCatalog model
        presto_engine_properties_catalog_model_json = {}
        presto_engine_properties_catalog_model_json['catalog_name'] = 'testString'

        # Construct a model instance of PrestoEnginePropertiesCatalog by calling from_dict on the json representation
        presto_engine_properties_catalog_model = PrestoEnginePropertiesCatalog.from_dict(presto_engine_properties_catalog_model_json)
        assert presto_engine_properties_catalog_model != False

        # Construct a model instance of PrestoEnginePropertiesCatalog by calling from_dict on the json representation
        presto_engine_properties_catalog_model_dict = PrestoEnginePropertiesCatalog.from_dict(presto_engine_properties_catalog_model_json).__dict__
        presto_engine_properties_catalog_model2 = PrestoEnginePropertiesCatalog(**presto_engine_properties_catalog_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_properties_catalog_model == presto_engine_properties_catalog_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_properties_catalog_model_json2 = presto_engine_properties_catalog_model.to_dict()
        assert presto_engine_properties_catalog_model_json2 == presto_engine_properties_catalog_model_json


class TestModel_PrestoEnginePropertiesEventListener:
    """
    Test Class for PrestoEnginePropertiesEventListener
    """

    def test_presto_engine_properties_event_listener_serialization(self):
        """
        Test serialization/deserialization for PrestoEnginePropertiesEventListener
        """

        # Construct a json representation of a PrestoEnginePropertiesEventListener model
        presto_engine_properties_event_listener_model_json = {}
        presto_engine_properties_event_listener_model_json['event_listener_property'] = 'testString'

        # Construct a model instance of PrestoEnginePropertiesEventListener by calling from_dict on the json representation
        presto_engine_properties_event_listener_model = PrestoEnginePropertiesEventListener.from_dict(presto_engine_properties_event_listener_model_json)
        assert presto_engine_properties_event_listener_model != False

        # Construct a model instance of PrestoEnginePropertiesEventListener by calling from_dict on the json representation
        presto_engine_properties_event_listener_model_dict = PrestoEnginePropertiesEventListener.from_dict(presto_engine_properties_event_listener_model_json).__dict__
        presto_engine_properties_event_listener_model2 = PrestoEnginePropertiesEventListener(**presto_engine_properties_event_listener_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_properties_event_listener_model == presto_engine_properties_event_listener_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_properties_event_listener_model_json2 = presto_engine_properties_event_listener_model.to_dict()
        assert presto_engine_properties_event_listener_model_json2 == presto_engine_properties_event_listener_model_json


class TestModel_PrestoEnginePropertiesGlobal:
    """
    Test Class for PrestoEnginePropertiesGlobal
    """

    def test_presto_engine_properties_global_serialization(self):
        """
        Test serialization/deserialization for PrestoEnginePropertiesGlobal
        """

        # Construct a json representation of a PrestoEnginePropertiesGlobal model
        presto_engine_properties_global_model_json = {}
        presto_engine_properties_global_model_json['global_property'] = 'enable-mixed-case-support:true'

        # Construct a model instance of PrestoEnginePropertiesGlobal by calling from_dict on the json representation
        presto_engine_properties_global_model = PrestoEnginePropertiesGlobal.from_dict(presto_engine_properties_global_model_json)
        assert presto_engine_properties_global_model != False

        # Construct a model instance of PrestoEnginePropertiesGlobal by calling from_dict on the json representation
        presto_engine_properties_global_model_dict = PrestoEnginePropertiesGlobal.from_dict(presto_engine_properties_global_model_json).__dict__
        presto_engine_properties_global_model2 = PrestoEnginePropertiesGlobal(**presto_engine_properties_global_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_properties_global_model == presto_engine_properties_global_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_properties_global_model_json2 = presto_engine_properties_global_model.to_dict()
        assert presto_engine_properties_global_model_json2 == presto_engine_properties_global_model_json


class TestModel_PrestoEnginePropertiesJMX:
    """
    Test Class for PrestoEnginePropertiesJMX
    """

    def test_presto_engine_properties_jmx_serialization(self):
        """
        Test serialization/deserialization for PrestoEnginePropertiesJMX
        """

        # Construct a json representation of a PrestoEnginePropertiesJMX model
        presto_engine_properties_jmx_model_json = {}
        presto_engine_properties_jmx_model_json['global_property'] = 'watsonx_data_presto_cluster_memory_manager_cluster_memory_bytes:presto.memory<name=ClusterMemoryManager><>ClusterMemoryBytes'

        # Construct a model instance of PrestoEnginePropertiesJMX by calling from_dict on the json representation
        presto_engine_properties_jmx_model = PrestoEnginePropertiesJMX.from_dict(presto_engine_properties_jmx_model_json)
        assert presto_engine_properties_jmx_model != False

        # Construct a model instance of PrestoEnginePropertiesJMX by calling from_dict on the json representation
        presto_engine_properties_jmx_model_dict = PrestoEnginePropertiesJMX.from_dict(presto_engine_properties_jmx_model_json).__dict__
        presto_engine_properties_jmx_model2 = PrestoEnginePropertiesJMX(**presto_engine_properties_jmx_model_dict)

        # Verify the model instances are equivalent
        assert presto_engine_properties_jmx_model == presto_engine_properties_jmx_model2

        # Convert model instance back to dict and verify no loss of data
        presto_engine_properties_jmx_model_json2 = presto_engine_properties_jmx_model.to_dict()
        assert presto_engine_properties_jmx_model_json2 == presto_engine_properties_jmx_model_json


class TestModel_PreviewIngestionFile:
    """
    Test Class for PreviewIngestionFile
    """

    def test_preview_ingestion_file_serialization(self):
        """
        Test serialization/deserialization for PreviewIngestionFile
        """

        # Construct dict forms of any model objects needed in order to build this model.

        preview_ingestion_file_rows_model = {}  # PreviewIngestionFileRows
        preview_ingestion_file_rows_model['row_eight'] = ['8', 'Jane Doe', '63.00']
        preview_ingestion_file_rows_model['row_five'] = ['5', 'Jane Doe', '57.00']
        preview_ingestion_file_rows_model['row_four'] = ['4', 'Jane Doe', '55.00']
        preview_ingestion_file_rows_model['row_nine'] = ['9', 'Jane Doe', '65.00']
        preview_ingestion_file_rows_model['row_one'] = ['1', 'Jane Doe', '49.00']
        preview_ingestion_file_rows_model['row_seven'] = ['7', 'Jane Doe', '61.00']
        preview_ingestion_file_rows_model['row_six'] = ['6', 'Jane Doe', '59.00']
        preview_ingestion_file_rows_model['row_ten'] = ['10', 'Jane Doe', '67.00']
        preview_ingestion_file_rows_model['row_three'] = ['3', 'Jane Doe', '53.00']
        preview_ingestion_file_rows_model['row_two'] = ['2', 'Jane Doe', '51.00']

        # Construct a json representation of a PreviewIngestionFile model
        preview_ingestion_file_model_json = {}
        preview_ingestion_file_model_json['column_names'] = ['col1', 'col2', 'col3']
        preview_ingestion_file_model_json['column_types'] = ['int', 'string', 'float']
        preview_ingestion_file_model_json['file_name'] = 's3://demobucket/data/yellow_tripdata_2022-01.parquet'
        preview_ingestion_file_model_json['rows'] = preview_ingestion_file_rows_model

        # Construct a model instance of PreviewIngestionFile by calling from_dict on the json representation
        preview_ingestion_file_model = PreviewIngestionFile.from_dict(preview_ingestion_file_model_json)
        assert preview_ingestion_file_model != False

        # Construct a model instance of PreviewIngestionFile by calling from_dict on the json representation
        preview_ingestion_file_model_dict = PreviewIngestionFile.from_dict(preview_ingestion_file_model_json).__dict__
        preview_ingestion_file_model2 = PreviewIngestionFile(**preview_ingestion_file_model_dict)

        # Verify the model instances are equivalent
        assert preview_ingestion_file_model == preview_ingestion_file_model2

        # Convert model instance back to dict and verify no loss of data
        preview_ingestion_file_model_json2 = preview_ingestion_file_model.to_dict()
        assert preview_ingestion_file_model_json2 == preview_ingestion_file_model_json


class TestModel_PreviewIngestionFilePrototypeCsvProperty:
    """
    Test Class for PreviewIngestionFilePrototypeCsvProperty
    """

    def test_preview_ingestion_file_prototype_csv_property_serialization(self):
        """
        Test serialization/deserialization for PreviewIngestionFilePrototypeCsvProperty
        """

        # Construct a json representation of a PreviewIngestionFilePrototypeCsvProperty model
        preview_ingestion_file_prototype_csv_property_model_json = {}
        preview_ingestion_file_prototype_csv_property_model_json['encoding'] = 'utf-8'
        preview_ingestion_file_prototype_csv_property_model_json['escape_character'] = '\\\\'
        preview_ingestion_file_prototype_csv_property_model_json['field_delimiter'] = ','
        preview_ingestion_file_prototype_csv_property_model_json['header'] = True
        preview_ingestion_file_prototype_csv_property_model_json['line_delimiter'] = '\\n'

        # Construct a model instance of PreviewIngestionFilePrototypeCsvProperty by calling from_dict on the json representation
        preview_ingestion_file_prototype_csv_property_model = PreviewIngestionFilePrototypeCsvProperty.from_dict(preview_ingestion_file_prototype_csv_property_model_json)
        assert preview_ingestion_file_prototype_csv_property_model != False

        # Construct a model instance of PreviewIngestionFilePrototypeCsvProperty by calling from_dict on the json representation
        preview_ingestion_file_prototype_csv_property_model_dict = PreviewIngestionFilePrototypeCsvProperty.from_dict(preview_ingestion_file_prototype_csv_property_model_json).__dict__
        preview_ingestion_file_prototype_csv_property_model2 = PreviewIngestionFilePrototypeCsvProperty(**preview_ingestion_file_prototype_csv_property_model_dict)

        # Verify the model instances are equivalent
        assert preview_ingestion_file_prototype_csv_property_model == preview_ingestion_file_prototype_csv_property_model2

        # Convert model instance back to dict and verify no loss of data
        preview_ingestion_file_prototype_csv_property_model_json2 = preview_ingestion_file_prototype_csv_property_model.to_dict()
        assert preview_ingestion_file_prototype_csv_property_model_json2 == preview_ingestion_file_prototype_csv_property_model_json


class TestModel_PreviewIngestionFileRows:
    """
    Test Class for PreviewIngestionFileRows
    """

    def test_preview_ingestion_file_rows_serialization(self):
        """
        Test serialization/deserialization for PreviewIngestionFileRows
        """

        # Construct a json representation of a PreviewIngestionFileRows model
        preview_ingestion_file_rows_model_json = {}
        preview_ingestion_file_rows_model_json['row_eight'] = ['8', 'Jane Doe', '63.00']
        preview_ingestion_file_rows_model_json['row_five'] = ['5', 'Jane Doe', '57.00']
        preview_ingestion_file_rows_model_json['row_four'] = ['4', 'Jane Doe', '55.00']
        preview_ingestion_file_rows_model_json['row_nine'] = ['9', 'Jane Doe', '65.00']
        preview_ingestion_file_rows_model_json['row_one'] = ['1', 'Jane Doe', '49.00']
        preview_ingestion_file_rows_model_json['row_seven'] = ['7', 'Jane Doe', '61.00']
        preview_ingestion_file_rows_model_json['row_six'] = ['6', 'Jane Doe', '59.00']
        preview_ingestion_file_rows_model_json['row_ten'] = ['10', 'Jane Doe', '67.00']
        preview_ingestion_file_rows_model_json['row_three'] = ['3', 'Jane Doe', '53.00']
        preview_ingestion_file_rows_model_json['row_two'] = ['2', 'Jane Doe', '51.00']

        # Construct a model instance of PreviewIngestionFileRows by calling from_dict on the json representation
        preview_ingestion_file_rows_model = PreviewIngestionFileRows.from_dict(preview_ingestion_file_rows_model_json)
        assert preview_ingestion_file_rows_model != False

        # Construct a model instance of PreviewIngestionFileRows by calling from_dict on the json representation
        preview_ingestion_file_rows_model_dict = PreviewIngestionFileRows.from_dict(preview_ingestion_file_rows_model_json).__dict__
        preview_ingestion_file_rows_model2 = PreviewIngestionFileRows(**preview_ingestion_file_rows_model_dict)

        # Verify the model instances are equivalent
        assert preview_ingestion_file_rows_model == preview_ingestion_file_rows_model2

        # Convert model instance back to dict and verify no loss of data
        preview_ingestion_file_rows_model_json2 = preview_ingestion_file_rows_model.to_dict()
        assert preview_ingestion_file_rows_model_json2 == preview_ingestion_file_rows_model_json


class TestModel_RegisterTableCreatedBody:
    """
    Test Class for RegisterTableCreatedBody
    """

    def test_register_table_created_body_serialization(self):
        """
        Test serialization/deserialization for RegisterTableCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'Register table success'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a RegisterTableCreatedBody model
        register_table_created_body_model_json = {}
        register_table_created_body_model_json['response'] = success_response_model

        # Construct a model instance of RegisterTableCreatedBody by calling from_dict on the json representation
        register_table_created_body_model = RegisterTableCreatedBody.from_dict(register_table_created_body_model_json)
        assert register_table_created_body_model != False

        # Construct a model instance of RegisterTableCreatedBody by calling from_dict on the json representation
        register_table_created_body_model_dict = RegisterTableCreatedBody.from_dict(register_table_created_body_model_json).__dict__
        register_table_created_body_model2 = RegisterTableCreatedBody(**register_table_created_body_model_dict)

        # Verify the model instances are equivalent
        assert register_table_created_body_model == register_table_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        register_table_created_body_model_json2 = register_table_created_body_model.to_dict()
        assert register_table_created_body_model_json2 == register_table_created_body_model_json


class TestModel_RemoveEngineProperties:
    """
    Test Class for RemoveEngineProperties
    """

    def test_remove_engine_properties_serialization(self):
        """
        Test serialization/deserialization for RemoveEngineProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        prestissimo_engine_properties_catalog_model = {}  # PrestissimoEnginePropertiesCatalog
        prestissimo_engine_properties_catalog_model['catalog_name'] = ['testString']

        remove_engine_properties_configuration_model = {}  # RemoveEnginePropertiesConfiguration
        remove_engine_properties_configuration_model['coordinator'] = ['testString']
        remove_engine_properties_configuration_model['worker'] = ['testString']

        remove_engine_properties_prestissimo_oai_gen_jvm_model = {}  # RemoveEnginePropertiesPrestissimoOaiGenJvm
        remove_engine_properties_prestissimo_oai_gen_jvm_model['coordinator'] = ['testString']

        # Construct a json representation of a RemoveEngineProperties model
        remove_engine_properties_model_json = {}
        remove_engine_properties_model_json['catalog'] = prestissimo_engine_properties_catalog_model
        remove_engine_properties_model_json['configuration'] = remove_engine_properties_configuration_model
        remove_engine_properties_model_json['jvm'] = remove_engine_properties_prestissimo_oai_gen_jvm_model
        remove_engine_properties_model_json['velox'] = ['testString']

        # Construct a model instance of RemoveEngineProperties by calling from_dict on the json representation
        remove_engine_properties_model = RemoveEngineProperties.from_dict(remove_engine_properties_model_json)
        assert remove_engine_properties_model != False

        # Construct a model instance of RemoveEngineProperties by calling from_dict on the json representation
        remove_engine_properties_model_dict = RemoveEngineProperties.from_dict(remove_engine_properties_model_json).__dict__
        remove_engine_properties_model2 = RemoveEngineProperties(**remove_engine_properties_model_dict)

        # Verify the model instances are equivalent
        assert remove_engine_properties_model == remove_engine_properties_model2

        # Convert model instance back to dict and verify no loss of data
        remove_engine_properties_model_json2 = remove_engine_properties_model.to_dict()
        assert remove_engine_properties_model_json2 == remove_engine_properties_model_json


class TestModel_RemoveEnginePropertiesConfiguration:
    """
    Test Class for RemoveEnginePropertiesConfiguration
    """

    def test_remove_engine_properties_configuration_serialization(self):
        """
        Test serialization/deserialization for RemoveEnginePropertiesConfiguration
        """

        # Construct a json representation of a RemoveEnginePropertiesConfiguration model
        remove_engine_properties_configuration_model_json = {}
        remove_engine_properties_configuration_model_json['coordinator'] = ['testString']
        remove_engine_properties_configuration_model_json['worker'] = ['testString']

        # Construct a model instance of RemoveEnginePropertiesConfiguration by calling from_dict on the json representation
        remove_engine_properties_configuration_model = RemoveEnginePropertiesConfiguration.from_dict(remove_engine_properties_configuration_model_json)
        assert remove_engine_properties_configuration_model != False

        # Construct a model instance of RemoveEnginePropertiesConfiguration by calling from_dict on the json representation
        remove_engine_properties_configuration_model_dict = RemoveEnginePropertiesConfiguration.from_dict(remove_engine_properties_configuration_model_json).__dict__
        remove_engine_properties_configuration_model2 = RemoveEnginePropertiesConfiguration(**remove_engine_properties_configuration_model_dict)

        # Verify the model instances are equivalent
        assert remove_engine_properties_configuration_model == remove_engine_properties_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        remove_engine_properties_configuration_model_json2 = remove_engine_properties_configuration_model.to_dict()
        assert remove_engine_properties_configuration_model_json2 == remove_engine_properties_configuration_model_json


class TestModel_RemoveEnginePropertiesLogConfig:
    """
    Test Class for RemoveEnginePropertiesLogConfig
    """

    def test_remove_engine_properties_log_config_serialization(self):
        """
        Test serialization/deserialization for RemoveEnginePropertiesLogConfig
        """

        # Construct a json representation of a RemoveEnginePropertiesLogConfig model
        remove_engine_properties_log_config_model_json = {}
        remove_engine_properties_log_config_model_json['coordinator'] = ['testString']
        remove_engine_properties_log_config_model_json['worker'] = ['testString']

        # Construct a model instance of RemoveEnginePropertiesLogConfig by calling from_dict on the json representation
        remove_engine_properties_log_config_model = RemoveEnginePropertiesLogConfig.from_dict(remove_engine_properties_log_config_model_json)
        assert remove_engine_properties_log_config_model != False

        # Construct a model instance of RemoveEnginePropertiesLogConfig by calling from_dict on the json representation
        remove_engine_properties_log_config_model_dict = RemoveEnginePropertiesLogConfig.from_dict(remove_engine_properties_log_config_model_json).__dict__
        remove_engine_properties_log_config_model2 = RemoveEnginePropertiesLogConfig(**remove_engine_properties_log_config_model_dict)

        # Verify the model instances are equivalent
        assert remove_engine_properties_log_config_model == remove_engine_properties_log_config_model2

        # Convert model instance back to dict and verify no loss of data
        remove_engine_properties_log_config_model_json2 = remove_engine_properties_log_config_model.to_dict()
        assert remove_engine_properties_log_config_model_json2 == remove_engine_properties_log_config_model_json


class TestModel_RemoveEnginePropertiesOaiGenConfiguration:
    """
    Test Class for RemoveEnginePropertiesOaiGenConfiguration
    """

    def test_remove_engine_properties_oai_gen_configuration_serialization(self):
        """
        Test serialization/deserialization for RemoveEnginePropertiesOaiGenConfiguration
        """

        # Construct a json representation of a RemoveEnginePropertiesOaiGenConfiguration model
        remove_engine_properties_oai_gen_configuration_model_json = {}
        remove_engine_properties_oai_gen_configuration_model_json['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_configuration_model_json['worker'] = ['testString']

        # Construct a model instance of RemoveEnginePropertiesOaiGenConfiguration by calling from_dict on the json representation
        remove_engine_properties_oai_gen_configuration_model = RemoveEnginePropertiesOaiGenConfiguration.from_dict(remove_engine_properties_oai_gen_configuration_model_json)
        assert remove_engine_properties_oai_gen_configuration_model != False

        # Construct a model instance of RemoveEnginePropertiesOaiGenConfiguration by calling from_dict on the json representation
        remove_engine_properties_oai_gen_configuration_model_dict = RemoveEnginePropertiesOaiGenConfiguration.from_dict(remove_engine_properties_oai_gen_configuration_model_json).__dict__
        remove_engine_properties_oai_gen_configuration_model2 = RemoveEnginePropertiesOaiGenConfiguration(**remove_engine_properties_oai_gen_configuration_model_dict)

        # Verify the model instances are equivalent
        assert remove_engine_properties_oai_gen_configuration_model == remove_engine_properties_oai_gen_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        remove_engine_properties_oai_gen_configuration_model_json2 = remove_engine_properties_oai_gen_configuration_model.to_dict()
        assert remove_engine_properties_oai_gen_configuration_model_json2 == remove_engine_properties_oai_gen_configuration_model_json


class TestModel_RemoveEnginePropertiesOaiGenJvm:
    """
    Test Class for RemoveEnginePropertiesOaiGenJvm
    """

    def test_remove_engine_properties_oai_gen_jvm_serialization(self):
        """
        Test serialization/deserialization for RemoveEnginePropertiesOaiGenJvm
        """

        # Construct a json representation of a RemoveEnginePropertiesOaiGenJvm model
        remove_engine_properties_oai_gen_jvm_model_json = {}
        remove_engine_properties_oai_gen_jvm_model_json['coordinator'] = ['testString']
        remove_engine_properties_oai_gen_jvm_model_json['worker'] = ['testString']

        # Construct a model instance of RemoveEnginePropertiesOaiGenJvm by calling from_dict on the json representation
        remove_engine_properties_oai_gen_jvm_model = RemoveEnginePropertiesOaiGenJvm.from_dict(remove_engine_properties_oai_gen_jvm_model_json)
        assert remove_engine_properties_oai_gen_jvm_model != False

        # Construct a model instance of RemoveEnginePropertiesOaiGenJvm by calling from_dict on the json representation
        remove_engine_properties_oai_gen_jvm_model_dict = RemoveEnginePropertiesOaiGenJvm.from_dict(remove_engine_properties_oai_gen_jvm_model_json).__dict__
        remove_engine_properties_oai_gen_jvm_model2 = RemoveEnginePropertiesOaiGenJvm(**remove_engine_properties_oai_gen_jvm_model_dict)

        # Verify the model instances are equivalent
        assert remove_engine_properties_oai_gen_jvm_model == remove_engine_properties_oai_gen_jvm_model2

        # Convert model instance back to dict and verify no loss of data
        remove_engine_properties_oai_gen_jvm_model_json2 = remove_engine_properties_oai_gen_jvm_model.to_dict()
        assert remove_engine_properties_oai_gen_jvm_model_json2 == remove_engine_properties_oai_gen_jvm_model_json


class TestModel_RemoveEnginePropertiesPrestissimoOaiGenJvm:
    """
    Test Class for RemoveEnginePropertiesPrestissimoOaiGenJvm
    """

    def test_remove_engine_properties_prestissimo_oai_gen_jvm_serialization(self):
        """
        Test serialization/deserialization for RemoveEnginePropertiesPrestissimoOaiGenJvm
        """

        # Construct a json representation of a RemoveEnginePropertiesPrestissimoOaiGenJvm model
        remove_engine_properties_prestissimo_oai_gen_jvm_model_json = {}
        remove_engine_properties_prestissimo_oai_gen_jvm_model_json['coordinator'] = ['testString']

        # Construct a model instance of RemoveEnginePropertiesPrestissimoOaiGenJvm by calling from_dict on the json representation
        remove_engine_properties_prestissimo_oai_gen_jvm_model = RemoveEnginePropertiesPrestissimoOaiGenJvm.from_dict(remove_engine_properties_prestissimo_oai_gen_jvm_model_json)
        assert remove_engine_properties_prestissimo_oai_gen_jvm_model != False

        # Construct a model instance of RemoveEnginePropertiesPrestissimoOaiGenJvm by calling from_dict on the json representation
        remove_engine_properties_prestissimo_oai_gen_jvm_model_dict = RemoveEnginePropertiesPrestissimoOaiGenJvm.from_dict(remove_engine_properties_prestissimo_oai_gen_jvm_model_json).__dict__
        remove_engine_properties_prestissimo_oai_gen_jvm_model2 = RemoveEnginePropertiesPrestissimoOaiGenJvm(**remove_engine_properties_prestissimo_oai_gen_jvm_model_dict)

        # Verify the model instances are equivalent
        assert remove_engine_properties_prestissimo_oai_gen_jvm_model == remove_engine_properties_prestissimo_oai_gen_jvm_model2

        # Convert model instance back to dict and verify no loss of data
        remove_engine_properties_prestissimo_oai_gen_jvm_model_json2 = remove_engine_properties_prestissimo_oai_gen_jvm_model.to_dict()
        assert remove_engine_properties_prestissimo_oai_gen_jvm_model_json2 == remove_engine_properties_prestissimo_oai_gen_jvm_model_json


class TestModel_ReplaceSnapshotCreatedBody:
    """
    Test Class for ReplaceSnapshotCreatedBody
    """

    def test_replace_snapshot_created_body_serialization(self):
        """
        Test serialization/deserialization for ReplaceSnapshotCreatedBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'Rollback to a table snapshot'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a ReplaceSnapshotCreatedBody model
        replace_snapshot_created_body_model_json = {}
        replace_snapshot_created_body_model_json['response'] = success_response_model

        # Construct a model instance of ReplaceSnapshotCreatedBody by calling from_dict on the json representation
        replace_snapshot_created_body_model = ReplaceSnapshotCreatedBody.from_dict(replace_snapshot_created_body_model_json)
        assert replace_snapshot_created_body_model != False

        # Construct a model instance of ReplaceSnapshotCreatedBody by calling from_dict on the json representation
        replace_snapshot_created_body_model_dict = ReplaceSnapshotCreatedBody.from_dict(replace_snapshot_created_body_model_json).__dict__
        replace_snapshot_created_body_model2 = ReplaceSnapshotCreatedBody(**replace_snapshot_created_body_model_dict)

        # Verify the model instances are equivalent
        assert replace_snapshot_created_body_model == replace_snapshot_created_body_model2

        # Convert model instance back to dict and verify no loss of data
        replace_snapshot_created_body_model_json2 = replace_snapshot_created_body_model.to_dict()
        assert replace_snapshot_created_body_model_json2 == replace_snapshot_created_body_model_json


class TestModel_ResultExecuteQuery:
    """
    Test Class for ResultExecuteQuery
    """

    def test_result_execute_query_serialization(self):
        """
        Test serialization/deserialization for ResultExecuteQuery
        """

        # Construct a json representation of a ResultExecuteQuery model
        result_execute_query_model_json = {}
        result_execute_query_model_json['result'] = [{'key1': 'testString'}]

        # Construct a model instance of ResultExecuteQuery by calling from_dict on the json representation
        result_execute_query_model = ResultExecuteQuery.from_dict(result_execute_query_model_json)
        assert result_execute_query_model != False

        # Construct a model instance of ResultExecuteQuery by calling from_dict on the json representation
        result_execute_query_model_dict = ResultExecuteQuery.from_dict(result_execute_query_model_json).__dict__
        result_execute_query_model2 = ResultExecuteQuery(**result_execute_query_model_dict)

        # Verify the model instances are equivalent
        assert result_execute_query_model == result_execute_query_model2

        # Convert model instance back to dict and verify no loss of data
        result_execute_query_model_json2 = result_execute_query_model.to_dict()
        assert result_execute_query_model_json2 == result_execute_query_model_json


class TestModel_ResultPrestissimoExplainStatement:
    """
    Test Class for ResultPrestissimoExplainStatement
    """

    def test_result_prestissimo_explain_statement_serialization(self):
        """
        Test serialization/deserialization for ResultPrestissimoExplainStatement
        """

        # Construct a json representation of a ResultPrestissimoExplainStatement model
        result_prestissimo_explain_statement_model_json = {}
        result_prestissimo_explain_statement_model_json['result'] = 'testString'

        # Construct a model instance of ResultPrestissimoExplainStatement by calling from_dict on the json representation
        result_prestissimo_explain_statement_model = ResultPrestissimoExplainStatement.from_dict(result_prestissimo_explain_statement_model_json)
        assert result_prestissimo_explain_statement_model != False

        # Construct a model instance of ResultPrestissimoExplainStatement by calling from_dict on the json representation
        result_prestissimo_explain_statement_model_dict = ResultPrestissimoExplainStatement.from_dict(result_prestissimo_explain_statement_model_json).__dict__
        result_prestissimo_explain_statement_model2 = ResultPrestissimoExplainStatement(**result_prestissimo_explain_statement_model_dict)

        # Verify the model instances are equivalent
        assert result_prestissimo_explain_statement_model == result_prestissimo_explain_statement_model2

        # Convert model instance back to dict and verify no loss of data
        result_prestissimo_explain_statement_model_json2 = result_prestissimo_explain_statement_model.to_dict()
        assert result_prestissimo_explain_statement_model_json2 == result_prestissimo_explain_statement_model_json


class TestModel_ResultRunPrestissimoExplainAnalyzeStatement:
    """
    Test Class for ResultRunPrestissimoExplainAnalyzeStatement
    """

    def test_result_run_prestissimo_explain_analyze_statement_serialization(self):
        """
        Test serialization/deserialization for ResultRunPrestissimoExplainAnalyzeStatement
        """

        # Construct a json representation of a ResultRunPrestissimoExplainAnalyzeStatement model
        result_run_prestissimo_explain_analyze_statement_model_json = {}
        result_run_prestissimo_explain_analyze_statement_model_json['result'] = 'testString'

        # Construct a model instance of ResultRunPrestissimoExplainAnalyzeStatement by calling from_dict on the json representation
        result_run_prestissimo_explain_analyze_statement_model = ResultRunPrestissimoExplainAnalyzeStatement.from_dict(result_run_prestissimo_explain_analyze_statement_model_json)
        assert result_run_prestissimo_explain_analyze_statement_model != False

        # Construct a model instance of ResultRunPrestissimoExplainAnalyzeStatement by calling from_dict on the json representation
        result_run_prestissimo_explain_analyze_statement_model_dict = ResultRunPrestissimoExplainAnalyzeStatement.from_dict(result_run_prestissimo_explain_analyze_statement_model_json).__dict__
        result_run_prestissimo_explain_analyze_statement_model2 = ResultRunPrestissimoExplainAnalyzeStatement(**result_run_prestissimo_explain_analyze_statement_model_dict)

        # Verify the model instances are equivalent
        assert result_run_prestissimo_explain_analyze_statement_model == result_run_prestissimo_explain_analyze_statement_model2

        # Convert model instance back to dict and verify no loss of data
        result_run_prestissimo_explain_analyze_statement_model_json2 = result_run_prestissimo_explain_analyze_statement_model.to_dict()
        assert result_run_prestissimo_explain_analyze_statement_model_json2 == result_run_prestissimo_explain_analyze_statement_model_json


class TestModel_Results:
    """
    Test Class for Results
    """

    def test_results_serialization(self):
        """
        Test serialization/deserialization for Results
        """

        # Construct a json representation of a Results model
        results_model_json = {}
        results_model_json['create_bucket_time_sec'] = 'testString'
        results_model_json['download_files_time_sec'] = 'testString'
        results_model_json['erase_bucket_time_sec'] = 'testString'
        results_model_json['erase_objects_time_sec'] = 'testString'
        results_model_json['list_files_time_sec'] = 'testString'
        results_model_json['total_operations_time_sec'] = 'testString'
        results_model_json['upload_files_time_sec'] = 'testString'

        # Construct a model instance of Results by calling from_dict on the json representation
        results_model = Results.from_dict(results_model_json)
        assert results_model != False

        # Construct a model instance of Results by calling from_dict on the json representation
        results_model_dict = Results.from_dict(results_model_json).__dict__
        results_model2 = Results(**results_model_dict)

        # Verify the model instances are equivalent
        assert results_model == results_model2

        # Convert model instance back to dict and verify no loss of data
        results_model_json2 = results_model.to_dict()
        assert results_model_json2 == results_model_json


class TestModel_RunExplainAnalyzeStatementOKBody:
    """
    Test Class for RunExplainAnalyzeStatementOKBody
    """

    def test_run_explain_analyze_statement_ok_body_serialization(self):
        """
        Test serialization/deserialization for RunExplainAnalyzeStatementOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'explain presto analyze'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a RunExplainAnalyzeStatementOKBody model
        run_explain_analyze_statement_ok_body_model_json = {}
        run_explain_analyze_statement_ok_body_model_json['response'] = success_response_model
        run_explain_analyze_statement_ok_body_model_json['result'] = 'testString'

        # Construct a model instance of RunExplainAnalyzeStatementOKBody by calling from_dict on the json representation
        run_explain_analyze_statement_ok_body_model = RunExplainAnalyzeStatementOKBody.from_dict(run_explain_analyze_statement_ok_body_model_json)
        assert run_explain_analyze_statement_ok_body_model != False

        # Construct a model instance of RunExplainAnalyzeStatementOKBody by calling from_dict on the json representation
        run_explain_analyze_statement_ok_body_model_dict = RunExplainAnalyzeStatementOKBody.from_dict(run_explain_analyze_statement_ok_body_model_json).__dict__
        run_explain_analyze_statement_ok_body_model2 = RunExplainAnalyzeStatementOKBody(**run_explain_analyze_statement_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert run_explain_analyze_statement_ok_body_model == run_explain_analyze_statement_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        run_explain_analyze_statement_ok_body_model_json2 = run_explain_analyze_statement_ok_body_model.to_dict()
        assert run_explain_analyze_statement_ok_body_model_json2 == run_explain_analyze_statement_ok_body_model_json


class TestModel_RunExplainStatementOKBody:
    """
    Test Class for RunExplainStatementOKBody
    """

    def test_run_explain_statement_ok_body_serialization(self):
        """
        Test serialization/deserialization for RunExplainStatementOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'explain statement'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a RunExplainStatementOKBody model
        run_explain_statement_ok_body_model_json = {}
        run_explain_statement_ok_body_model_json['response'] = success_response_model
        run_explain_statement_ok_body_model_json['result'] = 'testString'

        # Construct a model instance of RunExplainStatementOKBody by calling from_dict on the json representation
        run_explain_statement_ok_body_model = RunExplainStatementOKBody.from_dict(run_explain_statement_ok_body_model_json)
        assert run_explain_statement_ok_body_model != False

        # Construct a model instance of RunExplainStatementOKBody by calling from_dict on the json representation
        run_explain_statement_ok_body_model_dict = RunExplainStatementOKBody.from_dict(run_explain_statement_ok_body_model_json).__dict__
        run_explain_statement_ok_body_model2 = RunExplainStatementOKBody(**run_explain_statement_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert run_explain_statement_ok_body_model == run_explain_statement_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        run_explain_statement_ok_body_model_json2 = run_explain_statement_ok_body_model.to_dict()
        assert run_explain_statement_ok_body_model_json2 == run_explain_statement_ok_body_model_json


class TestModel_SalIntegration:
    """
    Test Class for SalIntegration
    """

    def test_sal_integration_serialization(self):
        """
        Test serialization/deserialization for SalIntegration
        """

        # Construct dict forms of any model objects needed in order to build this model.

        error_obj_model = {}  # ErrorObj
        error_obj_model['code'] = 'unable_to_perform'
        error_obj_model['message'] = 'Failed to process integration settings for watsonx.data instance'

        # Construct a json representation of a SalIntegration model
        sal_integration_model_json = {}
        sal_integration_model_json['category_id'] = '10e64285-bf37-4d5d-b759-bc6a46589234'
        sal_integration_model_json['engine_id'] = 'presto-01'
        sal_integration_model_json['errors'] = [error_obj_model]
        sal_integration_model_json['governance_scope_id'] = '10e64285-bf37-4d5d-b759-bc6a46589234'
        sal_integration_model_json['governance_scope_type'] = 'category'
        sal_integration_model_json['instance_id'] = '18b49d7a-9519-4539-8db5-ff080623c226'
        sal_integration_model_json['status'] = 'provisioning'
        sal_integration_model_json['storage_resource_crn'] = 'crn:v1:staging:public:cloud-object-storage:global:a/04e9bc47612523rr19ac22759cb69bebd:asd23df-6ada-45ff-bfe8-4343222'
        sal_integration_model_json['storage_type'] = 'bmcos_object_storage'
        sal_integration_model_json['timestamp'] = '1715056266'
        sal_integration_model_json['trial_plan'] = False
        sal_integration_model_json['username'] = 'xyz@abc.com'

        # Construct a model instance of SalIntegration by calling from_dict on the json representation
        sal_integration_model = SalIntegration.from_dict(sal_integration_model_json)
        assert sal_integration_model != False

        # Construct a model instance of SalIntegration by calling from_dict on the json representation
        sal_integration_model_dict = SalIntegration.from_dict(sal_integration_model_json).__dict__
        sal_integration_model2 = SalIntegration(**sal_integration_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_model == sal_integration_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_model_json2 = sal_integration_model.to_dict()
        assert sal_integration_model_json2 == sal_integration_model_json


class TestModel_SalIntegrationEnrichmentAssets:
    """
    Test Class for SalIntegrationEnrichmentAssets
    """

    def test_sal_integration_enrichment_assets_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentAssets
        """

        # Construct dict forms of any model objects needed in order to build this model.

        enrichment_asset_model = {}  # EnrichmentAsset
        enrichment_asset_model['asset_attributes'] = ['attribute1', 'attribute2', 'attribute3']
        enrichment_asset_model['asset_id'] = 'ee0383b9-dcab-4c1a-b03d-bf521837b6ed'
        enrichment_asset_model['asset_name'] = 'newtable'
        enrichment_asset_model['resource_key'] = '0000:0000:0000:0000:0000:FFFF:9EB0:04E2|31134|:/iceberg_data/new_schema/sampletable'
        enrichment_asset_model['schema_name'] = 'sampleschema'

        # Construct a json representation of a SalIntegrationEnrichmentAssets model
        sal_integration_enrichment_assets_model_json = {}
        sal_integration_enrichment_assets_model_json['enrichment_asset'] = enrichment_asset_model

        # Construct a model instance of SalIntegrationEnrichmentAssets by calling from_dict on the json representation
        sal_integration_enrichment_assets_model = SalIntegrationEnrichmentAssets.from_dict(sal_integration_enrichment_assets_model_json)
        assert sal_integration_enrichment_assets_model != False

        # Construct a model instance of SalIntegrationEnrichmentAssets by calling from_dict on the json representation
        sal_integration_enrichment_assets_model_dict = SalIntegrationEnrichmentAssets.from_dict(sal_integration_enrichment_assets_model_json).__dict__
        sal_integration_enrichment_assets_model2 = SalIntegrationEnrichmentAssets(**sal_integration_enrichment_assets_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_assets_model == sal_integration_enrichment_assets_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_assets_model_json2 = sal_integration_enrichment_assets_model.to_dict()
        assert sal_integration_enrichment_assets_model_json2 == sal_integration_enrichment_assets_model_json


class TestModel_SalIntegrationEnrichmentDataAsset:
    """
    Test Class for SalIntegrationEnrichmentDataAsset
    """

    def test_sal_integration_enrichment_data_asset_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentDataAsset
        """

        # Construct a json representation of a SalIntegrationEnrichmentDataAsset model
        sal_integration_enrichment_data_asset_model_json = {}
        sal_integration_enrichment_data_asset_model_json['asset'] = '{}'

        # Construct a model instance of SalIntegrationEnrichmentDataAsset by calling from_dict on the json representation
        sal_integration_enrichment_data_asset_model = SalIntegrationEnrichmentDataAsset.from_dict(sal_integration_enrichment_data_asset_model_json)
        assert sal_integration_enrichment_data_asset_model != False

        # Construct a model instance of SalIntegrationEnrichmentDataAsset by calling from_dict on the json representation
        sal_integration_enrichment_data_asset_model_dict = SalIntegrationEnrichmentDataAsset.from_dict(sal_integration_enrichment_data_asset_model_json).__dict__
        sal_integration_enrichment_data_asset_model2 = SalIntegrationEnrichmentDataAsset(**sal_integration_enrichment_data_asset_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_data_asset_model == sal_integration_enrichment_data_asset_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_data_asset_model_json2 = sal_integration_enrichment_data_asset_model.to_dict()
        assert sal_integration_enrichment_data_asset_model_json2 == sal_integration_enrichment_data_asset_model_json


class TestModel_SalIntegrationEnrichmentJobRun:
    """
    Test Class for SalIntegrationEnrichmentJobRun
    """

    def test_sal_integration_enrichment_job_run_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobRun
        """

        # Construct a json representation of a SalIntegrationEnrichmentJobRun model
        sal_integration_enrichment_job_run_model_json = {}
        sal_integration_enrichment_job_run_model_json['response'] = '{}'

        # Construct a model instance of SalIntegrationEnrichmentJobRun by calling from_dict on the json representation
        sal_integration_enrichment_job_run_model = SalIntegrationEnrichmentJobRun.from_dict(sal_integration_enrichment_job_run_model_json)
        assert sal_integration_enrichment_job_run_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobRun by calling from_dict on the json representation
        sal_integration_enrichment_job_run_model_dict = SalIntegrationEnrichmentJobRun.from_dict(sal_integration_enrichment_job_run_model_json).__dict__
        sal_integration_enrichment_job_run_model2 = SalIntegrationEnrichmentJobRun(**sal_integration_enrichment_job_run_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_job_run_model == sal_integration_enrichment_job_run_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_job_run_model_json2 = sal_integration_enrichment_job_run_model.to_dict()
        assert sal_integration_enrichment_job_run_model_json2 == sal_integration_enrichment_job_run_model_json


class TestModel_SalIntegrationEnrichmentJobRunLogs:
    """
    Test Class for SalIntegrationEnrichmentJobRunLogs
    """

    def test_sal_integration_enrichment_job_run_logs_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobRunLogs
        """

        # Construct a json representation of a SalIntegrationEnrichmentJobRunLogs model
        sal_integration_enrichment_job_run_logs_model_json = {}
        sal_integration_enrichment_job_run_logs_model_json['results'] = ['testString']
        sal_integration_enrichment_job_run_logs_model_json['total_count'] = 12

        # Construct a model instance of SalIntegrationEnrichmentJobRunLogs by calling from_dict on the json representation
        sal_integration_enrichment_job_run_logs_model = SalIntegrationEnrichmentJobRunLogs.from_dict(sal_integration_enrichment_job_run_logs_model_json)
        assert sal_integration_enrichment_job_run_logs_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobRunLogs by calling from_dict on the json representation
        sal_integration_enrichment_job_run_logs_model_dict = SalIntegrationEnrichmentJobRunLogs.from_dict(sal_integration_enrichment_job_run_logs_model_json).__dict__
        sal_integration_enrichment_job_run_logs_model2 = SalIntegrationEnrichmentJobRunLogs(**sal_integration_enrichment_job_run_logs_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_job_run_logs_model == sal_integration_enrichment_job_run_logs_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_job_run_logs_model_json2 = sal_integration_enrichment_job_run_logs_model.to_dict()
        assert sal_integration_enrichment_job_run_logs_model_json2 == sal_integration_enrichment_job_run_logs_model_json


class TestModel_SalIntegrationEnrichmentJobs:
    """
    Test Class for SalIntegrationEnrichmentJobs
    """

    def test_sal_integration_enrichment_jobs_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobs
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_type'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_variables'] = []

        schedule_info_model = {}  # ScheduleInfo
        schedule_info_model['frequency'] = 'testString'

        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['account_id'] = '04e9bc4761254b719ac22759cb69bebd'
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['task_credentials_enabled'] = True
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['user_id'] = 'IBMid-55000832RK'

        sal_integration_enrichment_jobs_result_item_entity_job_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJob
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref'] = '8688a3b6-a946-499e-a93c-b7d099db80dd'
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref_type'] = 'metadata_enrichment_area'
        sal_integration_enrichment_jobs_result_item_entity_job_model['configuration'] = sal_integration_enrichment_jobs_result_item_entity_job_configuration_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['enable_notifications'] = False
        sal_integration_enrichment_jobs_result_item_entity_job_model['future_scheduled_runs'] = []
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_initiator'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status_timestamp'] = 0
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_time'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['project_name'] = 'SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_creator_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_info'] = schedule_info_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['task_credentials_support'] = sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model

        sal_integration_enrichment_jobs_result_item_entity_model = {}  # SalIntegrationEnrichmentJobsResultItemEntity
        sal_integration_enrichment_jobs_result_item_entity_model['job'] = sal_integration_enrichment_jobs_result_item_entity_job_model

        sal_integration_enrichment_jobs_result_item_metadata_model = {}  # SalIntegrationEnrichmentJobsResultItemMetadata
        sal_integration_enrichment_jobs_result_item_metadata_model['asset_id'] = 'ea73ce44-8aa0-4c75-bd69-6ca7074a1030'
        sal_integration_enrichment_jobs_result_item_metadata_model['name'] = 'SAL_MDE job'
        sal_integration_enrichment_jobs_result_item_metadata_model['owner_id'] = 'IBMid-55000832RK'
        sal_integration_enrichment_jobs_result_item_metadata_model['version'] = 0

        sal_integration_enrichment_jobs_result_item_model = {}  # SalIntegrationEnrichmentJobsResultItem
        sal_integration_enrichment_jobs_result_item_model['entity'] = sal_integration_enrichment_jobs_result_item_entity_model
        sal_integration_enrichment_jobs_result_item_model['metadata'] = sal_integration_enrichment_jobs_result_item_metadata_model

        sal_integration_enrichment_jobs_properties_model = {}  # SalIntegrationEnrichmentJobsProperties
        sal_integration_enrichment_jobs_properties_model['results'] = [sal_integration_enrichment_jobs_result_item_model]
        sal_integration_enrichment_jobs_properties_model['total_rows'] = 1

        # Construct a json representation of a SalIntegrationEnrichmentJobs model
        sal_integration_enrichment_jobs_model_json = {}
        sal_integration_enrichment_jobs_model_json['jobs'] = sal_integration_enrichment_jobs_properties_model

        # Construct a model instance of SalIntegrationEnrichmentJobs by calling from_dict on the json representation
        sal_integration_enrichment_jobs_model = SalIntegrationEnrichmentJobs.from_dict(sal_integration_enrichment_jobs_model_json)
        assert sal_integration_enrichment_jobs_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobs by calling from_dict on the json representation
        sal_integration_enrichment_jobs_model_dict = SalIntegrationEnrichmentJobs.from_dict(sal_integration_enrichment_jobs_model_json).__dict__
        sal_integration_enrichment_jobs_model2 = SalIntegrationEnrichmentJobs(**sal_integration_enrichment_jobs_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_model == sal_integration_enrichment_jobs_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_model_json2 = sal_integration_enrichment_jobs_model.to_dict()
        assert sal_integration_enrichment_jobs_model_json2 == sal_integration_enrichment_jobs_model_json


class TestModel_SalIntegrationEnrichmentJobsProperties:
    """
    Test Class for SalIntegrationEnrichmentJobsProperties
    """

    def test_sal_integration_enrichment_jobs_properties_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsProperties
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_type'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_variables'] = []

        schedule_info_model = {}  # ScheduleInfo
        schedule_info_model['frequency'] = 'testString'

        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['account_id'] = '04e9bc4761254b719ac22759cb69bebd'
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['task_credentials_enabled'] = True
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['user_id'] = 'IBMid-55000832RK'

        sal_integration_enrichment_jobs_result_item_entity_job_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJob
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref'] = '8688a3b6-a946-499e-a93c-b7d099db80dd'
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref_type'] = 'metadata_enrichment_area'
        sal_integration_enrichment_jobs_result_item_entity_job_model['configuration'] = sal_integration_enrichment_jobs_result_item_entity_job_configuration_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['enable_notifications'] = False
        sal_integration_enrichment_jobs_result_item_entity_job_model['future_scheduled_runs'] = []
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_initiator'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status_timestamp'] = 0
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_time'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['project_name'] = 'SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_creator_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_info'] = schedule_info_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['task_credentials_support'] = sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model

        sal_integration_enrichment_jobs_result_item_entity_model = {}  # SalIntegrationEnrichmentJobsResultItemEntity
        sal_integration_enrichment_jobs_result_item_entity_model['job'] = sal_integration_enrichment_jobs_result_item_entity_job_model

        sal_integration_enrichment_jobs_result_item_metadata_model = {}  # SalIntegrationEnrichmentJobsResultItemMetadata
        sal_integration_enrichment_jobs_result_item_metadata_model['asset_id'] = 'ea73ce44-8aa0-4c75-bd69-6ca7074a1030'
        sal_integration_enrichment_jobs_result_item_metadata_model['name'] = 'SAL_MDE job'
        sal_integration_enrichment_jobs_result_item_metadata_model['owner_id'] = 'IBMid-55000832RK'
        sal_integration_enrichment_jobs_result_item_metadata_model['version'] = 0

        sal_integration_enrichment_jobs_result_item_model = {}  # SalIntegrationEnrichmentJobsResultItem
        sal_integration_enrichment_jobs_result_item_model['entity'] = sal_integration_enrichment_jobs_result_item_entity_model
        sal_integration_enrichment_jobs_result_item_model['metadata'] = sal_integration_enrichment_jobs_result_item_metadata_model

        # Construct a json representation of a SalIntegrationEnrichmentJobsProperties model
        sal_integration_enrichment_jobs_properties_model_json = {}
        sal_integration_enrichment_jobs_properties_model_json['results'] = [sal_integration_enrichment_jobs_result_item_model]
        sal_integration_enrichment_jobs_properties_model_json['total_rows'] = 1

        # Construct a model instance of SalIntegrationEnrichmentJobsProperties by calling from_dict on the json representation
        sal_integration_enrichment_jobs_properties_model = SalIntegrationEnrichmentJobsProperties.from_dict(sal_integration_enrichment_jobs_properties_model_json)
        assert sal_integration_enrichment_jobs_properties_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsProperties by calling from_dict on the json representation
        sal_integration_enrichment_jobs_properties_model_dict = SalIntegrationEnrichmentJobsProperties.from_dict(sal_integration_enrichment_jobs_properties_model_json).__dict__
        sal_integration_enrichment_jobs_properties_model2 = SalIntegrationEnrichmentJobsProperties(**sal_integration_enrichment_jobs_properties_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_properties_model == sal_integration_enrichment_jobs_properties_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_properties_model_json2 = sal_integration_enrichment_jobs_properties_model.to_dict()
        assert sal_integration_enrichment_jobs_properties_model_json2 == sal_integration_enrichment_jobs_properties_model_json


class TestModel_SalIntegrationEnrichmentJobsResultItem:
    """
    Test Class for SalIntegrationEnrichmentJobsResultItem
    """

    def test_sal_integration_enrichment_jobs_result_item_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsResultItem
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_type'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_variables'] = []

        schedule_info_model = {}  # ScheduleInfo
        schedule_info_model['frequency'] = 'testString'

        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['account_id'] = '04e9bc4761254b719ac22759cb69bebd'
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['task_credentials_enabled'] = True
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['user_id'] = 'IBMid-55000832RK'

        sal_integration_enrichment_jobs_result_item_entity_job_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJob
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref'] = '8688a3b6-a946-499e-a93c-b7d099db80dd'
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref_type'] = 'metadata_enrichment_area'
        sal_integration_enrichment_jobs_result_item_entity_job_model['configuration'] = sal_integration_enrichment_jobs_result_item_entity_job_configuration_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['enable_notifications'] = False
        sal_integration_enrichment_jobs_result_item_entity_job_model['future_scheduled_runs'] = []
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_initiator'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status_timestamp'] = 0
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_time'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['project_name'] = 'SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_creator_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_info'] = schedule_info_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['task_credentials_support'] = sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model

        sal_integration_enrichment_jobs_result_item_entity_model = {}  # SalIntegrationEnrichmentJobsResultItemEntity
        sal_integration_enrichment_jobs_result_item_entity_model['job'] = sal_integration_enrichment_jobs_result_item_entity_job_model

        sal_integration_enrichment_jobs_result_item_metadata_model = {}  # SalIntegrationEnrichmentJobsResultItemMetadata
        sal_integration_enrichment_jobs_result_item_metadata_model['asset_id'] = 'ea73ce44-8aa0-4c75-bd69-6ca7074a1030'
        sal_integration_enrichment_jobs_result_item_metadata_model['name'] = 'SAL_MDE job'
        sal_integration_enrichment_jobs_result_item_metadata_model['owner_id'] = 'IBMid-55000832RK'
        sal_integration_enrichment_jobs_result_item_metadata_model['version'] = 0

        # Construct a json representation of a SalIntegrationEnrichmentJobsResultItem model
        sal_integration_enrichment_jobs_result_item_model_json = {}
        sal_integration_enrichment_jobs_result_item_model_json['entity'] = sal_integration_enrichment_jobs_result_item_entity_model
        sal_integration_enrichment_jobs_result_item_model_json['metadata'] = sal_integration_enrichment_jobs_result_item_metadata_model

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItem by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_model = SalIntegrationEnrichmentJobsResultItem.from_dict(sal_integration_enrichment_jobs_result_item_model_json)
        assert sal_integration_enrichment_jobs_result_item_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItem by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_model_dict = SalIntegrationEnrichmentJobsResultItem.from_dict(sal_integration_enrichment_jobs_result_item_model_json).__dict__
        sal_integration_enrichment_jobs_result_item_model2 = SalIntegrationEnrichmentJobsResultItem(**sal_integration_enrichment_jobs_result_item_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_result_item_model == sal_integration_enrichment_jobs_result_item_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_result_item_model_json2 = sal_integration_enrichment_jobs_result_item_model.to_dict()
        assert sal_integration_enrichment_jobs_result_item_model_json2 == sal_integration_enrichment_jobs_result_item_model_json


class TestModel_SalIntegrationEnrichmentJobsResultItemEntity:
    """
    Test Class for SalIntegrationEnrichmentJobsResultItemEntity
    """

    def test_sal_integration_enrichment_jobs_result_item_entity_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsResultItemEntity
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_type'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_variables'] = []

        schedule_info_model = {}  # ScheduleInfo
        schedule_info_model['frequency'] = 'testString'

        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['account_id'] = '04e9bc4761254b719ac22759cb69bebd'
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['task_credentials_enabled'] = True
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['user_id'] = 'IBMid-55000832RK'

        sal_integration_enrichment_jobs_result_item_entity_job_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJob
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref'] = '8688a3b6-a946-499e-a93c-b7d099db80dd'
        sal_integration_enrichment_jobs_result_item_entity_job_model['asset_ref_type'] = 'metadata_enrichment_area'
        sal_integration_enrichment_jobs_result_item_entity_job_model['configuration'] = sal_integration_enrichment_jobs_result_item_entity_job_configuration_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['enable_notifications'] = False
        sal_integration_enrichment_jobs_result_item_entity_job_model['future_scheduled_runs'] = []
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_initiator'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_status_timestamp'] = 0
        sal_integration_enrichment_jobs_result_item_entity_job_model['last_run_time'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model['project_name'] = 'SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_creator_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model['schedule_info'] = schedule_info_model
        sal_integration_enrichment_jobs_result_item_entity_job_model['task_credentials_support'] = sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model

        # Construct a json representation of a SalIntegrationEnrichmentJobsResultItemEntity model
        sal_integration_enrichment_jobs_result_item_entity_model_json = {}
        sal_integration_enrichment_jobs_result_item_entity_model_json['job'] = sal_integration_enrichment_jobs_result_item_entity_job_model

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntity by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_model = SalIntegrationEnrichmentJobsResultItemEntity.from_dict(sal_integration_enrichment_jobs_result_item_entity_model_json)
        assert sal_integration_enrichment_jobs_result_item_entity_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntity by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_model_dict = SalIntegrationEnrichmentJobsResultItemEntity.from_dict(sal_integration_enrichment_jobs_result_item_entity_model_json).__dict__
        sal_integration_enrichment_jobs_result_item_entity_model2 = SalIntegrationEnrichmentJobsResultItemEntity(**sal_integration_enrichment_jobs_result_item_entity_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_result_item_entity_model == sal_integration_enrichment_jobs_result_item_entity_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_result_item_entity_model_json2 = sal_integration_enrichment_jobs_result_item_entity_model.to_dict()
        assert sal_integration_enrichment_jobs_result_item_entity_model_json2 == sal_integration_enrichment_jobs_result_item_entity_model_json


class TestModel_SalIntegrationEnrichmentJobsResultItemEntityJob:
    """
    Test Class for SalIntegrationEnrichmentJobsResultItemEntityJob
    """

    def test_sal_integration_enrichment_jobs_result_item_entity_job_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsResultItemEntityJob
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_type'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model['env_variables'] = []

        schedule_info_model = {}  # ScheduleInfo
        schedule_info_model['frequency'] = 'testString'

        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model = {}  # SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['account_id'] = '04e9bc4761254b719ac22759cb69bebd'
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['task_credentials_enabled'] = True
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model['user_id'] = 'IBMid-55000832RK'

        # Construct a json representation of a SalIntegrationEnrichmentJobsResultItemEntityJob model
        sal_integration_enrichment_jobs_result_item_entity_job_model_json = {}
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['asset_ref'] = '8688a3b6-a946-499e-a93c-b7d099db80dd'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['asset_ref_type'] = 'metadata_enrichment_area'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['configuration'] = sal_integration_enrichment_jobs_result_item_entity_job_configuration_model
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['enable_notifications'] = False
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['future_scheduled_runs'] = []
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['last_run_initiator'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['last_run_status'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['last_run_status_timestamp'] = 0
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['last_run_time'] = 'deprecated field'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['project_name'] = 'SAL Mapping /iceberg_data/new_schema 9aae5be3-87cf-4c31-b17d-9256ab42c14e'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['schedule_creator_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['schedule_id'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['schedule_info'] = schedule_info_model
        sal_integration_enrichment_jobs_result_item_entity_job_model_json['task_credentials_support'] = sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntityJob by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_job_model = SalIntegrationEnrichmentJobsResultItemEntityJob.from_dict(sal_integration_enrichment_jobs_result_item_entity_job_model_json)
        assert sal_integration_enrichment_jobs_result_item_entity_job_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntityJob by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_job_model_dict = SalIntegrationEnrichmentJobsResultItemEntityJob.from_dict(sal_integration_enrichment_jobs_result_item_entity_job_model_json).__dict__
        sal_integration_enrichment_jobs_result_item_entity_job_model2 = SalIntegrationEnrichmentJobsResultItemEntityJob(**sal_integration_enrichment_jobs_result_item_entity_job_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_result_item_entity_job_model == sal_integration_enrichment_jobs_result_item_entity_job_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_result_item_entity_job_model_json2 = sal_integration_enrichment_jobs_result_item_entity_job_model.to_dict()
        assert sal_integration_enrichment_jobs_result_item_entity_job_model_json2 == sal_integration_enrichment_jobs_result_item_entity_job_model_json


class TestModel_SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration:
    """
    Test Class for SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
    """

    def test_sal_integration_enrichment_jobs_result_item_entity_job_configuration_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration
        """

        # Construct a json representation of a SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration model
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json = {}
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json['env_type'] = 'testString'
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json['env_variables'] = []

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model = SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration.from_dict(sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json)
        assert sal_integration_enrichment_jobs_result_item_entity_job_configuration_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_dict = SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration.from_dict(sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json).__dict__
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model2 = SalIntegrationEnrichmentJobsResultItemEntityJobConfiguration(**sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_result_item_entity_job_configuration_model == sal_integration_enrichment_jobs_result_item_entity_job_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json2 = sal_integration_enrichment_jobs_result_item_entity_job_configuration_model.to_dict()
        assert sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json2 == sal_integration_enrichment_jobs_result_item_entity_job_configuration_model_json


class TestModel_SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport:
    """
    Test Class for SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
    """

    def test_sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport
        """

        # Construct a json representation of a SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport model
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json = {}
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json['account_id'] = '04e9bc4761254b719ac22759cb69bebd'
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json['task_credentials_enabled'] = True
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json['user_id'] = 'IBMid-55000832RK'

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model = SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport.from_dict(sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json)
        assert sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_dict = SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport.from_dict(sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json).__dict__
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model2 = SalIntegrationEnrichmentJobsResultItemEntityTaskCredentialsSupport(**sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model == sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json2 = sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model.to_dict()
        assert sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json2 == sal_integration_enrichment_jobs_result_item_entity_task_credentials_support_model_json


class TestModel_SalIntegrationEnrichmentJobsResultItemMetadata:
    """
    Test Class for SalIntegrationEnrichmentJobsResultItemMetadata
    """

    def test_sal_integration_enrichment_jobs_result_item_metadata_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentJobsResultItemMetadata
        """

        # Construct a json representation of a SalIntegrationEnrichmentJobsResultItemMetadata model
        sal_integration_enrichment_jobs_result_item_metadata_model_json = {}
        sal_integration_enrichment_jobs_result_item_metadata_model_json['asset_id'] = 'ea73ce44-8aa0-4c75-bd69-6ca7074a1030'
        sal_integration_enrichment_jobs_result_item_metadata_model_json['name'] = 'SAL_MDE job'
        sal_integration_enrichment_jobs_result_item_metadata_model_json['owner_id'] = 'IBMid-55000832RK'
        sal_integration_enrichment_jobs_result_item_metadata_model_json['version'] = 0

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemMetadata by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_metadata_model = SalIntegrationEnrichmentJobsResultItemMetadata.from_dict(sal_integration_enrichment_jobs_result_item_metadata_model_json)
        assert sal_integration_enrichment_jobs_result_item_metadata_model != False

        # Construct a model instance of SalIntegrationEnrichmentJobsResultItemMetadata by calling from_dict on the json representation
        sal_integration_enrichment_jobs_result_item_metadata_model_dict = SalIntegrationEnrichmentJobsResultItemMetadata.from_dict(sal_integration_enrichment_jobs_result_item_metadata_model_json).__dict__
        sal_integration_enrichment_jobs_result_item_metadata_model2 = SalIntegrationEnrichmentJobsResultItemMetadata(**sal_integration_enrichment_jobs_result_item_metadata_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_jobs_result_item_metadata_model == sal_integration_enrichment_jobs_result_item_metadata_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_jobs_result_item_metadata_model_json2 = sal_integration_enrichment_jobs_result_item_metadata_model.to_dict()
        assert sal_integration_enrichment_jobs_result_item_metadata_model_json2 == sal_integration_enrichment_jobs_result_item_metadata_model_json


class TestModel_SalIntegrationEnrichmentSettings:
    """
    Test Class for SalIntegrationEnrichmentSettings
    """

    def test_sal_integration_enrichment_settings_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentSettings
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = {}  # SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['suggestion_threshold'] = 0.9

        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = {}  # SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['suggestion_threshold'] = 0.1

        sal_integration_enrichment_settings_semantic_expansion_model = {}  # SalIntegrationEnrichmentSettingsSemanticExpansion
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['description_generation_configuration'] = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion'] = True
        sal_integration_enrichment_settings_semantic_expansion_model['name_expansion_configuration'] = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model

        sal_integration_enrichment_settings_term_assignment_model = {}  # SalIntegrationEnrichmentSettingsTermAssignment
        sal_integration_enrichment_settings_term_assignment_model['class_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['evaluate_negative_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['llm_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_custom'] = False
        sal_integration_enrichment_settings_term_assignment_model['ml_based_assignments_default'] = False
        sal_integration_enrichment_settings_term_assignment_model['name_matching'] = False
        sal_integration_enrichment_settings_term_assignment_model['term_assignment_threshold'] = 0.3
        sal_integration_enrichment_settings_term_assignment_model['term_suggestion_threshold'] = 0.4

        # Construct a json representation of a SalIntegrationEnrichmentSettings model
        sal_integration_enrichment_settings_model_json = {}
        sal_integration_enrichment_settings_model_json['semantic_expansion'] = sal_integration_enrichment_settings_semantic_expansion_model
        sal_integration_enrichment_settings_model_json['term_assignment'] = sal_integration_enrichment_settings_term_assignment_model

        # Construct a model instance of SalIntegrationEnrichmentSettings by calling from_dict on the json representation
        sal_integration_enrichment_settings_model = SalIntegrationEnrichmentSettings.from_dict(sal_integration_enrichment_settings_model_json)
        assert sal_integration_enrichment_settings_model != False

        # Construct a model instance of SalIntegrationEnrichmentSettings by calling from_dict on the json representation
        sal_integration_enrichment_settings_model_dict = SalIntegrationEnrichmentSettings.from_dict(sal_integration_enrichment_settings_model_json).__dict__
        sal_integration_enrichment_settings_model2 = SalIntegrationEnrichmentSettings(**sal_integration_enrichment_settings_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_settings_model == sal_integration_enrichment_settings_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_settings_model_json2 = sal_integration_enrichment_settings_model.to_dict()
        assert sal_integration_enrichment_settings_model_json2 == sal_integration_enrichment_settings_model_json


class TestModel_SalIntegrationEnrichmentSettingsSemanticExpansion:
    """
    Test Class for SalIntegrationEnrichmentSettingsSemanticExpansion
    """

    def test_sal_integration_enrichment_settings_semantic_expansion_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentSettingsSemanticExpansion
        """

        # Construct dict forms of any model objects needed in order to build this model.

        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = {}  # SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model['suggestion_threshold'] = 0.9

        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = {}  # SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model['suggestion_threshold'] = 0.1

        # Construct a json representation of a SalIntegrationEnrichmentSettingsSemanticExpansion model
        sal_integration_enrichment_settings_semantic_expansion_model_json = {}
        sal_integration_enrichment_settings_semantic_expansion_model_json['description_generation'] = True
        sal_integration_enrichment_settings_semantic_expansion_model_json['description_generation_configuration'] = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model
        sal_integration_enrichment_settings_semantic_expansion_model_json['name_expansion'] = True
        sal_integration_enrichment_settings_semantic_expansion_model_json['name_expansion_configuration'] = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model

        # Construct a model instance of SalIntegrationEnrichmentSettingsSemanticExpansion by calling from_dict on the json representation
        sal_integration_enrichment_settings_semantic_expansion_model = SalIntegrationEnrichmentSettingsSemanticExpansion.from_dict(sal_integration_enrichment_settings_semantic_expansion_model_json)
        assert sal_integration_enrichment_settings_semantic_expansion_model != False

        # Construct a model instance of SalIntegrationEnrichmentSettingsSemanticExpansion by calling from_dict on the json representation
        sal_integration_enrichment_settings_semantic_expansion_model_dict = SalIntegrationEnrichmentSettingsSemanticExpansion.from_dict(sal_integration_enrichment_settings_semantic_expansion_model_json).__dict__
        sal_integration_enrichment_settings_semantic_expansion_model2 = SalIntegrationEnrichmentSettingsSemanticExpansion(**sal_integration_enrichment_settings_semantic_expansion_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_settings_semantic_expansion_model == sal_integration_enrichment_settings_semantic_expansion_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_settings_semantic_expansion_model_json2 = sal_integration_enrichment_settings_semantic_expansion_model.to_dict()
        assert sal_integration_enrichment_settings_semantic_expansion_model_json2 == sal_integration_enrichment_settings_semantic_expansion_model_json


class TestModel_SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration:
    """
    Test Class for SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration
    """

    def test_sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration
        """

        # Construct a json representation of a SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json = {}
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json['assignment_threshold'] = 0.14
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json['suggestion_threshold'] = 0.9

        # Construct a model instance of SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration by calling from_dict on the json representation
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model = SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration.from_dict(sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json)
        assert sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model != False

        # Construct a model instance of SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration by calling from_dict on the json representation
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_dict = SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration.from_dict(sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json).__dict__
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model2 = SalIntegrationEnrichmentSettingsSemanticExpansionDescriptionGenerationConfiguration(**sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model == sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json2 = sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model.to_dict()
        assert sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json2 == sal_integration_enrichment_settings_semantic_expansion_description_generation_configuration_model_json


class TestModel_SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration:
    """
    Test Class for SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration
    """

    def test_sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration
        """

        # Construct a json representation of a SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration model
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json = {}
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json['assignment_threshold'] = 0.1
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json['suggestion_threshold'] = 0.1

        # Construct a model instance of SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration by calling from_dict on the json representation
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model = SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration.from_dict(sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json)
        assert sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model != False

        # Construct a model instance of SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration by calling from_dict on the json representation
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_dict = SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration.from_dict(sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json).__dict__
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model2 = SalIntegrationEnrichmentSettingsSemanticExpansionNameExpansionConfiguration(**sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model == sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json2 = sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model.to_dict()
        assert sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json2 == sal_integration_enrichment_settings_semantic_expansion_name_expansion_configuration_model_json


class TestModel_SalIntegrationEnrichmentSettingsTermAssignment:
    """
    Test Class for SalIntegrationEnrichmentSettingsTermAssignment
    """

    def test_sal_integration_enrichment_settings_term_assignment_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationEnrichmentSettingsTermAssignment
        """

        # Construct a json representation of a SalIntegrationEnrichmentSettingsTermAssignment model
        sal_integration_enrichment_settings_term_assignment_model_json = {}
        sal_integration_enrichment_settings_term_assignment_model_json['class_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model_json['evaluate_negative_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model_json['llm_based_assignments'] = False
        sal_integration_enrichment_settings_term_assignment_model_json['ml_based_assignments_custom'] = False
        sal_integration_enrichment_settings_term_assignment_model_json['ml_based_assignments_default'] = False
        sal_integration_enrichment_settings_term_assignment_model_json['name_matching'] = False
        sal_integration_enrichment_settings_term_assignment_model_json['term_assignment_threshold'] = 0.3
        sal_integration_enrichment_settings_term_assignment_model_json['term_suggestion_threshold'] = 0.4

        # Construct a model instance of SalIntegrationEnrichmentSettingsTermAssignment by calling from_dict on the json representation
        sal_integration_enrichment_settings_term_assignment_model = SalIntegrationEnrichmentSettingsTermAssignment.from_dict(sal_integration_enrichment_settings_term_assignment_model_json)
        assert sal_integration_enrichment_settings_term_assignment_model != False

        # Construct a model instance of SalIntegrationEnrichmentSettingsTermAssignment by calling from_dict on the json representation
        sal_integration_enrichment_settings_term_assignment_model_dict = SalIntegrationEnrichmentSettingsTermAssignment.from_dict(sal_integration_enrichment_settings_term_assignment_model_json).__dict__
        sal_integration_enrichment_settings_term_assignment_model2 = SalIntegrationEnrichmentSettingsTermAssignment(**sal_integration_enrichment_settings_term_assignment_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_enrichment_settings_term_assignment_model == sal_integration_enrichment_settings_term_assignment_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_enrichment_settings_term_assignment_model_json2 = sal_integration_enrichment_settings_term_assignment_model.to_dict()
        assert sal_integration_enrichment_settings_term_assignment_model_json2 == sal_integration_enrichment_settings_term_assignment_model_json


class TestModel_SalIntegrationGlossaryTerms:
    """
    Test Class for SalIntegrationGlossaryTerms
    """

    def test_sal_integration_glossary_terms_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationGlossaryTerms
        """

        # Construct dict forms of any model objects needed in order to build this model.

        glossary_object_model = {}  # GlossaryObject
        glossary_object_model['description'] = 'First Name'
        glossary_object_model['name'] = 'Name'

        # Construct a json representation of a SalIntegrationGlossaryTerms model
        sal_integration_glossary_terms_model_json = {}
        sal_integration_glossary_terms_model_json['glossary_term'] = glossary_object_model

        # Construct a model instance of SalIntegrationGlossaryTerms by calling from_dict on the json representation
        sal_integration_glossary_terms_model = SalIntegrationGlossaryTerms.from_dict(sal_integration_glossary_terms_model_json)
        assert sal_integration_glossary_terms_model != False

        # Construct a model instance of SalIntegrationGlossaryTerms by calling from_dict on the json representation
        sal_integration_glossary_terms_model_dict = SalIntegrationGlossaryTerms.from_dict(sal_integration_glossary_terms_model_json).__dict__
        sal_integration_glossary_terms_model2 = SalIntegrationGlossaryTerms(**sal_integration_glossary_terms_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_glossary_terms_model == sal_integration_glossary_terms_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_glossary_terms_model_json2 = sal_integration_glossary_terms_model.to_dict()
        assert sal_integration_glossary_terms_model_json2 == sal_integration_glossary_terms_model_json


class TestModel_SalIntegrationMappings:
    """
    Test Class for SalIntegrationMappings
    """

    def test_sal_integration_mappings_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationMappings
        """

        # Construct a json representation of a SalIntegrationMappings model
        sal_integration_mappings_model_json = {}
        sal_integration_mappings_model_json['wkc_catalog_id'] = 'iceberg_data'
        sal_integration_mappings_model_json['wkc_project_id'] = 'create'

        # Construct a model instance of SalIntegrationMappings by calling from_dict on the json representation
        sal_integration_mappings_model = SalIntegrationMappings.from_dict(sal_integration_mappings_model_json)
        assert sal_integration_mappings_model != False

        # Construct a model instance of SalIntegrationMappings by calling from_dict on the json representation
        sal_integration_mappings_model_dict = SalIntegrationMappings.from_dict(sal_integration_mappings_model_json).__dict__
        sal_integration_mappings_model2 = SalIntegrationMappings(**sal_integration_mappings_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_mappings_model == sal_integration_mappings_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_mappings_model_json2 = sal_integration_mappings_model.to_dict()
        assert sal_integration_mappings_model_json2 == sal_integration_mappings_model_json


class TestModel_SalIntegrationPatch:
    """
    Test Class for SalIntegrationPatch
    """

    def test_sal_integration_patch_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationPatch
        """

        # Construct a json representation of a SalIntegrationPatch model
        sal_integration_patch_model_json = {}
        sal_integration_patch_model_json['op'] = 'add'
        sal_integration_patch_model_json['path'] = 'storage'
        sal_integration_patch_model_json['value'] = 'new-apikey'

        # Construct a model instance of SalIntegrationPatch by calling from_dict on the json representation
        sal_integration_patch_model = SalIntegrationPatch.from_dict(sal_integration_patch_model_json)
        assert sal_integration_patch_model != False

        # Construct a model instance of SalIntegrationPatch by calling from_dict on the json representation
        sal_integration_patch_model_dict = SalIntegrationPatch.from_dict(sal_integration_patch_model_json).__dict__
        sal_integration_patch_model2 = SalIntegrationPatch(**sal_integration_patch_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_patch_model == sal_integration_patch_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_patch_model_json2 = sal_integration_patch_model.to_dict()
        assert sal_integration_patch_model_json2 == sal_integration_patch_model_json


class TestModel_SalIntegrationUploadGlossary:
    """
    Test Class for SalIntegrationUploadGlossary
    """

    def test_sal_integration_upload_glossary_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationUploadGlossary
        """

        # Construct a json representation of a SalIntegrationUploadGlossary model
        sal_integration_upload_glossary_model_json = {}
        sal_integration_upload_glossary_model_json['process_id'] = '18b49d7a-9519-4539-8db5-ff080623c226'

        # Construct a model instance of SalIntegrationUploadGlossary by calling from_dict on the json representation
        sal_integration_upload_glossary_model = SalIntegrationUploadGlossary.from_dict(sal_integration_upload_glossary_model_json)
        assert sal_integration_upload_glossary_model != False

        # Construct a model instance of SalIntegrationUploadGlossary by calling from_dict on the json representation
        sal_integration_upload_glossary_model_dict = SalIntegrationUploadGlossary.from_dict(sal_integration_upload_glossary_model_json).__dict__
        sal_integration_upload_glossary_model2 = SalIntegrationUploadGlossary(**sal_integration_upload_glossary_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_upload_glossary_model == sal_integration_upload_glossary_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_upload_glossary_model_json2 = sal_integration_upload_glossary_model.to_dict()
        assert sal_integration_upload_glossary_model_json2 == sal_integration_upload_glossary_model_json


class TestModel_SalIntegrationUploadGlossaryStatus:
    """
    Test Class for SalIntegrationUploadGlossaryStatus
    """

    def test_sal_integration_upload_glossary_status_serialization(self):
        """
        Test serialization/deserialization for SalIntegrationUploadGlossaryStatus
        """

        # Construct a json representation of a SalIntegrationUploadGlossaryStatus model
        sal_integration_upload_glossary_status_model_json = {}
        sal_integration_upload_glossary_status_model_json['response'] = 'Import status available'

        # Construct a model instance of SalIntegrationUploadGlossaryStatus by calling from_dict on the json representation
        sal_integration_upload_glossary_status_model = SalIntegrationUploadGlossaryStatus.from_dict(sal_integration_upload_glossary_status_model_json)
        assert sal_integration_upload_glossary_status_model != False

        # Construct a model instance of SalIntegrationUploadGlossaryStatus by calling from_dict on the json representation
        sal_integration_upload_glossary_status_model_dict = SalIntegrationUploadGlossaryStatus.from_dict(sal_integration_upload_glossary_status_model_json).__dict__
        sal_integration_upload_glossary_status_model2 = SalIntegrationUploadGlossaryStatus(**sal_integration_upload_glossary_status_model_dict)

        # Verify the model instances are equivalent
        assert sal_integration_upload_glossary_status_model == sal_integration_upload_glossary_status_model2

        # Convert model instance back to dict and verify no loss of data
        sal_integration_upload_glossary_status_model_json2 = sal_integration_upload_glossary_status_model.to_dict()
        assert sal_integration_upload_glossary_status_model_json2 == sal_integration_upload_glossary_status_model_json


class TestModel_ScheduleInfo:
    """
    Test Class for ScheduleInfo
    """

    def test_schedule_info_serialization(self):
        """
        Test serialization/deserialization for ScheduleInfo
        """

        # Construct a json representation of a ScheduleInfo model
        schedule_info_model_json = {}
        schedule_info_model_json['frequency'] = 'testString'

        # Construct a model instance of ScheduleInfo by calling from_dict on the json representation
        schedule_info_model = ScheduleInfo.from_dict(schedule_info_model_json)
        assert schedule_info_model != False

        # Construct a model instance of ScheduleInfo by calling from_dict on the json representation
        schedule_info_model_dict = ScheduleInfo.from_dict(schedule_info_model_json).__dict__
        schedule_info_model2 = ScheduleInfo(**schedule_info_model_dict)

        # Verify the model instances are equivalent
        assert schedule_info_model == schedule_info_model2

        # Convert model instance back to dict and verify no loss of data
        schedule_info_model_json2 = schedule_info_model.to_dict()
        assert schedule_info_model_json2 == schedule_info_model_json


class TestModel_SchemaResponse:
    """
    Test Class for SchemaResponse
    """

    def test_schema_response_serialization(self):
        """
        Test serialization/deserialization for SchemaResponse
        """

        # Construct dict forms of any model objects needed in order to build this model.

        schema_response_summary_model = {}  # SchemaResponseSummary
        schema_response_summary_model['bucket'] = 'iceberg-bucket'
        schema_response_summary_model['catalog'] = 'iceberg_data'
        schema_response_summary_model['owner'] = 'ibmlhadmin'
        schema_response_summary_model['schema_name'] = 's3'

        # Construct a json representation of a SchemaResponse model
        schema_response_model_json = {}
        schema_response_model_json['bucket'] = 'testString'
        schema_response_model_json['catalog'] = 'testString'
        schema_response_model_json['message'] = 'testString'
        schema_response_model_json['message_code'] = 'testString'
        schema_response_model_json['owner'] = 'testString'
        schema_response_model_json['schema'] = schema_response_summary_model
        schema_response_model_json['schema_name'] = 'testString'

        # Construct a model instance of SchemaResponse by calling from_dict on the json representation
        schema_response_model = SchemaResponse.from_dict(schema_response_model_json)
        assert schema_response_model != False

        # Construct a model instance of SchemaResponse by calling from_dict on the json representation
        schema_response_model_dict = SchemaResponse.from_dict(schema_response_model_json).__dict__
        schema_response_model2 = SchemaResponse(**schema_response_model_dict)

        # Verify the model instances are equivalent
        assert schema_response_model == schema_response_model2

        # Convert model instance back to dict and verify no loss of data
        schema_response_model_json2 = schema_response_model.to_dict()
        assert schema_response_model_json2 == schema_response_model_json


class TestModel_SchemaResponseCollection:
    """
    Test Class for SchemaResponseCollection
    """

    def test_schema_response_collection_serialization(self):
        """
        Test serialization/deserialization for SchemaResponseCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        schema_response_summary_model = {}  # SchemaResponseSummary
        schema_response_summary_model['bucket'] = 'iceberg-bucket'
        schema_response_summary_model['catalog'] = 'iceberg_data'
        schema_response_summary_model['owner'] = 'ibmlhadmin'
        schema_response_summary_model['schema_name'] = 's3'

        # Construct a json representation of a SchemaResponseCollection model
        schema_response_collection_model_json = {}
        schema_response_collection_model_json['message'] = 'testString'
        schema_response_collection_model_json['message_code'] = 'testString'
        schema_response_collection_model_json['schemas'] = [schema_response_summary_model]

        # Construct a model instance of SchemaResponseCollection by calling from_dict on the json representation
        schema_response_collection_model = SchemaResponseCollection.from_dict(schema_response_collection_model_json)
        assert schema_response_collection_model != False

        # Construct a model instance of SchemaResponseCollection by calling from_dict on the json representation
        schema_response_collection_model_dict = SchemaResponseCollection.from_dict(schema_response_collection_model_json).__dict__
        schema_response_collection_model2 = SchemaResponseCollection(**schema_response_collection_model_dict)

        # Verify the model instances are equivalent
        assert schema_response_collection_model == schema_response_collection_model2

        # Convert model instance back to dict and verify no loss of data
        schema_response_collection_model_json2 = schema_response_collection_model.to_dict()
        assert schema_response_collection_model_json2 == schema_response_collection_model_json


class TestModel_SchemaResponseSummary:
    """
    Test Class for SchemaResponseSummary
    """

    def test_schema_response_summary_serialization(self):
        """
        Test serialization/deserialization for SchemaResponseSummary
        """

        # Construct a json representation of a SchemaResponseSummary model
        schema_response_summary_model_json = {}
        schema_response_summary_model_json['bucket'] = 'testString'
        schema_response_summary_model_json['catalog'] = 'testString'
        schema_response_summary_model_json['owner'] = 'testString'
        schema_response_summary_model_json['schema_name'] = 'testString'

        # Construct a model instance of SchemaResponseSummary by calling from_dict on the json representation
        schema_response_summary_model = SchemaResponseSummary.from_dict(schema_response_summary_model_json)
        assert schema_response_summary_model != False

        # Construct a model instance of SchemaResponseSummary by calling from_dict on the json representation
        schema_response_summary_model_dict = SchemaResponseSummary.from_dict(schema_response_summary_model_json).__dict__
        schema_response_summary_model2 = SchemaResponseSummary(**schema_response_summary_model_dict)

        # Verify the model instances are equivalent
        assert schema_response_summary_model == schema_response_summary_model2

        # Convert model instance back to dict and verify no loss of data
        schema_response_summary_model_json2 = schema_response_summary_model.to_dict()
        assert schema_response_summary_model_json2 == schema_response_summary_model_json


class TestModel_ServicesDetails:
    """
    Test Class for ServicesDetails
    """

    def test_services_details_serialization(self):
        """
        Test serialization/deserialization for ServicesDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        external_details_model = {}  # ExternalDetails
        external_details_model['port'] = 4553
        external_details_model['hostname'] = 'external hostname'

        internal_details_model = {}  # InternalDetails
        internal_details_model['port'] = 4553
        internal_details_model['hostname'] = 'internal hostname'

        jdbc_thrift_urls_model = {}  # JdbcThriftUrls
        jdbc_thrift_urls_model['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        details_model = {}  # Details
        details_model['ca_certificate'] = 'sample ca certificate'
        details_model['default_configs'] = {'key1': 'testString'}
        details_model['external'] = external_details_model
        details_model['grpc_api_endpoint'] = internal_details_model
        details_model['hostname'] = 'sample hostname'
        details_model['id'] = 'sample ID'
        details_model['instance_crn'] = 'sample instance CRN'
        details_model['instance_id'] = 'sample instance ID'
        details_model['internal'] = internal_details_model
        details_model['jdbc_class'] = 'com.facebook.presto.jdbc.PrestoDriver'
        details_model['jdbc_urls'] = jdbc_thrift_urls_model
        details_model['name'] = 'sample name'
        details_model['port'] = 4553
        details_model['rest_api_endpoint'] = internal_details_model
        details_model['spark_engine_endpoint'] = 'Spark Engine endpoint'
        details_model['ssl_certificate'] = 'sample ssl certificate'
        details_model['thrift_urls'] = jdbc_thrift_urls_model
        details_model['version'] = 'java'
        details_model['watsonx_data_application_endpoint'] = 'sample application end point'

        connection_properties_details_properties_connection_items_model = {}  # ConnectionPropertiesDetailsPropertiesConnectionItems
        connection_properties_details_properties_connection_items_model['name'] = 'host'
        connection_properties_details_properties_connection_items_model['value'] = 'sample_value'

        connection_properties_details_properties_model = {}  # ConnectionPropertiesDetailsProperties
        connection_properties_details_properties_model['connection'] = [connection_properties_details_properties_connection_items_model]

        connection_properties_details_model = {}  # ConnectionPropertiesDetails
        connection_properties_details_model['connection_name'] = 'presto-01'
        connection_properties_details_model['details'] = details_model
        connection_properties_details_model['properties'] = connection_properties_details_properties_model
        connection_properties_details_model['type'] = 'presto'

        # Construct a json representation of a ServicesDetails model
        services_details_model_json = {}
        services_details_model_json['engines_services'] = [connection_properties_details_model]

        # Construct a model instance of ServicesDetails by calling from_dict on the json representation
        services_details_model = ServicesDetails.from_dict(services_details_model_json)
        assert services_details_model != False

        # Construct a model instance of ServicesDetails by calling from_dict on the json representation
        services_details_model_dict = ServicesDetails.from_dict(services_details_model_json).__dict__
        services_details_model2 = ServicesDetails(**services_details_model_dict)

        # Verify the model instances are equivalent
        assert services_details_model == services_details_model2

        # Convert model instance back to dict and verify no loss of data
        services_details_model_json2 = services_details_model.to_dict()
        assert services_details_model_json2 == services_details_model_json


class TestModel_SparkApplicationConfig:
    """
    Test Class for SparkApplicationConfig
    """

    def test_spark_application_config_serialization(self):
        """
        Test serialization/deserialization for SparkApplicationConfig
        """

        # Construct a json representation of a SparkApplicationConfig model
        spark_application_config_model_json = {}
        spark_application_config_model_json['spark_sample_config_properpty'] = 'testString'

        # Construct a model instance of SparkApplicationConfig by calling from_dict on the json representation
        spark_application_config_model = SparkApplicationConfig.from_dict(spark_application_config_model_json)
        assert spark_application_config_model != False

        # Construct a model instance of SparkApplicationConfig by calling from_dict on the json representation
        spark_application_config_model_dict = SparkApplicationConfig.from_dict(spark_application_config_model_json).__dict__
        spark_application_config_model2 = SparkApplicationConfig(**spark_application_config_model_dict)

        # Verify the model instances are equivalent
        assert spark_application_config_model == spark_application_config_model2

        # Convert model instance back to dict and verify no loss of data
        spark_application_config_model_json2 = spark_application_config_model.to_dict()
        assert spark_application_config_model_json2 == spark_application_config_model_json


class TestModel_SparkApplicationDetails:
    """
    Test Class for SparkApplicationDetails
    """

    def test_spark_application_details_serialization(self):
        """
        Test serialization/deserialization for SparkApplicationDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_application_config_model = {}  # SparkApplicationConfig
        spark_application_config_model['spark_sample_config_properpty'] = 'testString'

        spark_application_env_model = {}  # SparkApplicationEnv
        spark_application_env_model['sample_env_key'] = 'testString'

        # Construct a json representation of a SparkApplicationDetails model
        spark_application_details_model_json = {}
        spark_application_details_model_json['application'] = 's3://mybucket/wordcount.py'
        spark_application_details_model_json['arguments'] = ['people.txt']
        spark_application_details_model_json['class'] = 'org.apache.spark.examples.SparkPi'
        spark_application_details_model_json['conf'] = spark_application_config_model
        spark_application_details_model_json['env'] = spark_application_env_model
        spark_application_details_model_json['files'] = 's3://mybucket/myfile.txt'
        spark_application_details_model_json['jars'] = 'testString'
        spark_application_details_model_json['name'] = 'SparkApplicaton1'
        spark_application_details_model_json['packages'] = 'org.apache.spark:example_1.2.3'
        spark_application_details_model_json['repositories'] = 'https://repo1.maven.org/maven2/'
        spark_application_details_model_json['spark_version'] = '3.3'

        # Construct a model instance of SparkApplicationDetails by calling from_dict on the json representation
        spark_application_details_model = SparkApplicationDetails.from_dict(spark_application_details_model_json)
        assert spark_application_details_model != False

        # Construct a model instance of SparkApplicationDetails by calling from_dict on the json representation
        spark_application_details_model_dict = SparkApplicationDetails.from_dict(spark_application_details_model_json).__dict__
        spark_application_details_model2 = SparkApplicationDetails(**spark_application_details_model_dict)

        # Verify the model instances are equivalent
        assert spark_application_details_model == spark_application_details_model2

        # Convert model instance back to dict and verify no loss of data
        spark_application_details_model_json2 = spark_application_details_model.to_dict()
        assert spark_application_details_model_json2 == spark_application_details_model_json


class TestModel_SparkApplicationEnv:
    """
    Test Class for SparkApplicationEnv
    """

    def test_spark_application_env_serialization(self):
        """
        Test serialization/deserialization for SparkApplicationEnv
        """

        # Construct a json representation of a SparkApplicationEnv model
        spark_application_env_model_json = {}
        spark_application_env_model_json['sample_env_key'] = 'testString'

        # Construct a model instance of SparkApplicationEnv by calling from_dict on the json representation
        spark_application_env_model = SparkApplicationEnv.from_dict(spark_application_env_model_json)
        assert spark_application_env_model != False

        # Construct a model instance of SparkApplicationEnv by calling from_dict on the json representation
        spark_application_env_model_dict = SparkApplicationEnv.from_dict(spark_application_env_model_json).__dict__
        spark_application_env_model2 = SparkApplicationEnv(**spark_application_env_model_dict)

        # Verify the model instances are equivalent
        assert spark_application_env_model == spark_application_env_model2

        # Convert model instance back to dict and verify no loss of data
        spark_application_env_model_json2 = spark_application_env_model.to_dict()
        assert spark_application_env_model_json2 == spark_application_env_model_json


class TestModel_SparkDefaultConfig:
    """
    Test Class for SparkDefaultConfig
    """

    def test_spark_default_config_serialization(self):
        """
        Test serialization/deserialization for SparkDefaultConfig
        """

        # Construct a json representation of a SparkDefaultConfig model
        spark_default_config_model_json = {}
        spark_default_config_model_json['config1'] = 'testString'
        spark_default_config_model_json['config2'] = 'testString'

        # Construct a model instance of SparkDefaultConfig by calling from_dict on the json representation
        spark_default_config_model = SparkDefaultConfig.from_dict(spark_default_config_model_json)
        assert spark_default_config_model != False

        # Construct a model instance of SparkDefaultConfig by calling from_dict on the json representation
        spark_default_config_model_dict = SparkDefaultConfig.from_dict(spark_default_config_model_json).__dict__
        spark_default_config_model2 = SparkDefaultConfig(**spark_default_config_model_dict)

        # Verify the model instances are equivalent
        assert spark_default_config_model == spark_default_config_model2

        # Convert model instance back to dict and verify no loss of data
        spark_default_config_model_json2 = spark_default_config_model.to_dict()
        assert spark_default_config_model_json2 == spark_default_config_model_json


class TestModel_SparkEndpoints:
    """
    Test Class for SparkEndpoints
    """

    def test_spark_endpoints_serialization(self):
        """
        Test serialization/deserialization for SparkEndpoints
        """

        # Construct a json representation of a SparkEndpoints model
        spark_endpoints_model_json = {}
        spark_endpoints_model_json['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        spark_endpoints_model_json['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        spark_endpoints_model_json['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        spark_endpoints_model_json['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        spark_endpoints_model_json['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        spark_endpoints_model_json['view_history_server'] = 'testString'
        spark_endpoints_model_json['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'
        spark_endpoints_model_json['wxd_engine_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817'
        spark_endpoints_model_json['wxd_history_server_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server'
        spark_endpoints_model_json['wxd_history_server_ui_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server/ui'

        # Construct a model instance of SparkEndpoints by calling from_dict on the json representation
        spark_endpoints_model = SparkEndpoints.from_dict(spark_endpoints_model_json)
        assert spark_endpoints_model != False

        # Construct a model instance of SparkEndpoints by calling from_dict on the json representation
        spark_endpoints_model_dict = SparkEndpoints.from_dict(spark_endpoints_model_json).__dict__
        spark_endpoints_model2 = SparkEndpoints(**spark_endpoints_model_dict)

        # Verify the model instances are equivalent
        assert spark_endpoints_model == spark_endpoints_model2

        # Convert model instance back to dict and verify no loss of data
        spark_endpoints_model_json2 = spark_endpoints_model.to_dict()
        assert spark_endpoints_model_json2 == spark_endpoints_model_json


class TestModel_SparkEngine:
    """
    Test Class for SparkEngine
    """

    def test_spark_engine_serialization(self):
        """
        Test serialization/deserialization for SparkEngine
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_default_config_model = {}  # SparkDefaultConfig
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        spark_endpoints_model = {}  # SparkEndpoints
        spark_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        spark_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        spark_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        spark_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        spark_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        spark_endpoints_model['view_history_server'] = 'testString'
        spark_endpoints_model['wxd_application_endpoint'] = '{$HOST}/lakehouse/api/v2/{$INSTANCE_ID}/spark_engines/spark875/applications'
        spark_endpoints_model['wxd_engine_endpoint'] = '{$HOST}/lakehouse/api/v2/{$INSTANCE_ID}/spark_engines/spark875'
        spark_endpoints_model['wxd_history_server_endpoint'] = '{$HOST}/lakehouse/api/v2/{$INSTANCE_ID}/spark_engines/spark875/history_server'
        spark_endpoints_model['wxd_history_server_ui_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server/ui'

        spark_scale_config_model = {}  # SparkScaleConfig
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'medium'
        spark_scale_config_model['number_of_nodes'] = 2

        spark_engine_details_model = {}  # SparkEngineDetails
        spark_engine_details_model['api_key'] = 'apikey'
        spark_engine_details_model['connection_string'] = 'https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>'
        spark_engine_details_model['default_config'] = spark_default_config_model
        spark_engine_details_model['default_version'] = '3.3'
        spark_engine_details_model['endpoints'] = spark_endpoints_model
        spark_engine_details_model['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_model['engine_home_bucket_name'] = 'test-spark-bucket'
        spark_engine_details_model['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_model['engine_home_volume'] = 'cpd-instance::Spark-Volume'
        spark_engine_details_model['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_model['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_model['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_model['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_model['instance_id'] = 'spark-id'
        spark_engine_details_model['engine_sub_type'] = 'java/cpp'
        spark_engine_details_model['managed_by'] = 'fully/self'
        spark_engine_details_model['scale_config'] = spark_scale_config_model

        # Construct a json representation of a SparkEngine model
        spark_engine_model_json = {}
        spark_engine_model_json['actions'] = ['update', 'delete']
        spark_engine_model_json['associated_catalogs'] = ['iceberg_data', 'hive_data']
        spark_engine_model_json['build_version'] = '1.0.3.0.0'
        spark_engine_model_json['created_by'] = '<username>@<domain>.com'
        spark_engine_model_json['created_on'] = 38
        spark_engine_model_json['description'] = 'spark engine for running sql queries'
        spark_engine_model_json['engine_details'] = spark_engine_details_model
        spark_engine_model_json['engine_display_name'] = 'sampleEngine'
        spark_engine_model_json['engine_id'] = 'sampleEngine123'
        spark_engine_model_json['origin'] = 'external'
        spark_engine_model_json['status'] = 'Registered'
        spark_engine_model_json['tags'] = ['tag1', 'tag2']
        spark_engine_model_json['type'] = 'spark'

        # Construct a model instance of SparkEngine by calling from_dict on the json representation
        spark_engine_model = SparkEngine.from_dict(spark_engine_model_json)
        assert spark_engine_model != False

        # Construct a model instance of SparkEngine by calling from_dict on the json representation
        spark_engine_model_dict = SparkEngine.from_dict(spark_engine_model_json).__dict__
        spark_engine_model2 = SparkEngine(**spark_engine_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_model == spark_engine_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_model_json2 = spark_engine_model.to_dict()
        assert spark_engine_model_json2 == spark_engine_model_json


class TestModel_SparkEngineApplicationStatus:
    """
    Test Class for SparkEngineApplicationStatus
    """

    def test_spark_engine_application_status_serialization(self):
        """
        Test serialization/deserialization for SparkEngineApplicationStatus
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_application_config_model = {}  # SparkApplicationConfig
        spark_application_config_model['spark_sample_config_properpty'] = 'testString'

        spark_application_env_model = {}  # SparkApplicationEnv
        spark_application_env_model['sample_env_key'] = 'testString'

        spark_application_details_model = {}  # SparkApplicationDetails
        spark_application_details_model['application'] = 's3://mybucket/wordcount.py'
        spark_application_details_model['arguments'] = ['people.txt']
        spark_application_details_model['class'] = 'org.apache.spark.examples.SparkPi'
        spark_application_details_model['conf'] = spark_application_config_model
        spark_application_details_model['env'] = spark_application_env_model
        spark_application_details_model['files'] = 's3://mybucket/myfile.txt'
        spark_application_details_model['jars'] = 'testString'
        spark_application_details_model['name'] = 'SparkApplicaton1'
        spark_application_details_model['packages'] = 'org.apache.spark:example_1.2.3'
        spark_application_details_model['repositories'] = 'https://repo1.maven.org/maven2/'
        spark_application_details_model['spark_version'] = '3.3'

        spark_engine_application_status_runtime_model = {}  # SparkEngineApplicationStatusRuntime
        spark_engine_application_status_runtime_model['spark_version'] = '3.3'

        spark_engine_application_status_state_details_items_model = {}  # SparkEngineApplicationStatusStateDetailsItems
        spark_engine_application_status_state_details_items_model['code'] = 'testString'
        spark_engine_application_status_state_details_items_model['message'] = 'testString'
        spark_engine_application_status_state_details_items_model['type'] = 'testString'

        spark_volume_details_model = {}  # SparkVolumeDetails
        spark_volume_details_model['mount_path'] = '/mount/path'
        spark_volume_details_model['name'] = 'my-volume'
        spark_volume_details_model['read_only'] = True
        spark_volume_details_model['source_sub_path'] = '/source/path'

        # Construct a json representation of a SparkEngineApplicationStatus model
        spark_engine_application_status_model_json = {}
        spark_engine_application_status_model_json['application_details'] = spark_application_details_model
        spark_engine_application_status_model_json['application_id'] = 'cd7cbf1f-8893-4c51-aa3d-d92729f05e99'
        spark_engine_application_status_model_json['auto_termination_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model_json['creation_time'] = 'Saturday 28 October 2023 07:17:06.856+0000'
        spark_engine_application_status_model_json['deploy_mode'] = 'stand-alone'
        spark_engine_application_status_model_json['end_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model_json['failed_time'] = 'testString'
        spark_engine_application_status_model_json['finish_time'] = 'Saturday 28 October 2023 07:17:38.966+0000'
        spark_engine_application_status_model_json['id'] = 'cd7cbf1f-8893-4c51-aa3d-d92729f05e99'
        spark_engine_application_status_model_json['job_endpoint'] = '<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications'
        spark_engine_application_status_model_json['return_code'] = '0'
        spark_engine_application_status_model_json['runtime'] = spark_engine_application_status_runtime_model
        spark_engine_application_status_model_json['service_instance_id'] = 'testString'
        spark_engine_application_status_model_json['spark_application_id'] = 'app-20231028071726-0000'
        spark_engine_application_status_model_json['spark_application_name'] = 'PythonWordCount'
        spark_engine_application_status_model_json['spark_version'] = '3.3'
        spark_engine_application_status_model_json['start_time'] = 'Saturday 28 October 2023 07:17:26.649+0000'
        spark_engine_application_status_model_json['state'] = 'FINISHED'
        spark_engine_application_status_model_json['state_details'] = [spark_engine_application_status_state_details_items_model]
        spark_engine_application_status_model_json['submission_time'] = '2023-11-01T11:18:49.758Z'
        spark_engine_application_status_model_json['template_id'] = 'spark-3.3-jaas-v2-cp4d-template'
        spark_engine_application_status_model_json['type'] = 'iae'
        spark_engine_application_status_model_json['volumes'] = [spark_volume_details_model]
        spark_engine_application_status_model_json['wxd_application_ui_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui'

        # Construct a model instance of SparkEngineApplicationStatus by calling from_dict on the json representation
        spark_engine_application_status_model = SparkEngineApplicationStatus.from_dict(spark_engine_application_status_model_json)
        assert spark_engine_application_status_model != False

        # Construct a model instance of SparkEngineApplicationStatus by calling from_dict on the json representation
        spark_engine_application_status_model_dict = SparkEngineApplicationStatus.from_dict(spark_engine_application_status_model_json).__dict__
        spark_engine_application_status_model2 = SparkEngineApplicationStatus(**spark_engine_application_status_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_application_status_model == spark_engine_application_status_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_application_status_model_json2 = spark_engine_application_status_model.to_dict()
        assert spark_engine_application_status_model_json2 == spark_engine_application_status_model_json


class TestModel_SparkEngineApplicationStatusCollection:
    """
    Test Class for SparkEngineApplicationStatusCollection
    """

    def test_spark_engine_application_status_collection_serialization(self):
        """
        Test serialization/deserialization for SparkEngineApplicationStatusCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_application_config_model = {}  # SparkApplicationConfig
        spark_application_config_model['spark_sample_config_properpty'] = 'testString'

        spark_application_env_model = {}  # SparkApplicationEnv
        spark_application_env_model['sample_env_key'] = 'testString'

        spark_application_details_model = {}  # SparkApplicationDetails
        spark_application_details_model['application'] = 's3://mybucket/wordcount.py'
        spark_application_details_model['arguments'] = ['people.txt']
        spark_application_details_model['class'] = 'org.apache.spark.examples.SparkPi'
        spark_application_details_model['conf'] = spark_application_config_model
        spark_application_details_model['env'] = spark_application_env_model
        spark_application_details_model['files'] = 's3://mybucket/myfile.txt'
        spark_application_details_model['jars'] = 'testString'
        spark_application_details_model['name'] = 'SparkApplicaton1'
        spark_application_details_model['packages'] = 'org.apache.spark:example_1.2.3'
        spark_application_details_model['repositories'] = 'https://repo1.maven.org/maven2/'
        spark_application_details_model['spark_version'] = '3.3'

        spark_engine_application_status_runtime_model = {}  # SparkEngineApplicationStatusRuntime
        spark_engine_application_status_runtime_model['spark_version'] = '3.3'

        spark_engine_application_status_state_details_items_model = {}  # SparkEngineApplicationStatusStateDetailsItems
        spark_engine_application_status_state_details_items_model['code'] = 'testString'
        spark_engine_application_status_state_details_items_model['message'] = 'testString'
        spark_engine_application_status_state_details_items_model['type'] = 'testString'

        spark_volume_details_model = {}  # SparkVolumeDetails
        spark_volume_details_model['mount_path'] = '/mount/path'
        spark_volume_details_model['name'] = 'my-volume'
        spark_volume_details_model['read_only'] = True
        spark_volume_details_model['source_sub_path'] = '/source/path'

        spark_engine_application_status_model = {}  # SparkEngineApplicationStatus
        spark_engine_application_status_model['application_details'] = spark_application_details_model
        spark_engine_application_status_model['application_id'] = '<application_id>'
        spark_engine_application_status_model['auto_termination_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model['creation_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model['deploy_mode'] = 'stand-alone'
        spark_engine_application_status_model['end_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model['failed_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model['finish_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model['id'] = 'cd7cbf1f-8893-4c51-aa3d-d92729f05e99'
        spark_engine_application_status_model['job_endpoint'] = '<host>/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/engine_applications'
        spark_engine_application_status_model['return_code'] = '0'
        spark_engine_application_status_model['runtime'] = spark_engine_application_status_runtime_model
        spark_engine_application_status_model['service_instance_id'] = 'testString'
        spark_engine_application_status_model['spark_application_id'] = 'spark-application-16073847388_0001'
        spark_engine_application_status_model['spark_application_name'] = 'sample-application-name'
        spark_engine_application_status_model['spark_version'] = '3.3'
        spark_engine_application_status_model['start_time'] = '2020-12-08T10:00:00.000Z'
        spark_engine_application_status_model['state'] = 'running'
        spark_engine_application_status_model['state_details'] = [spark_engine_application_status_state_details_items_model]
        spark_engine_application_status_model['submission_time'] = '2023-11-01T11:18:49.758Z'
        spark_engine_application_status_model['template_id'] = 'spark-3.3-jaas-v2-cp4d-template'
        spark_engine_application_status_model['type'] = 'iae'
        spark_engine_application_status_model['volumes'] = [spark_volume_details_model]
        spark_engine_application_status_model['wxd_application_ui_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications/c7b3fccf-badb-46b0-b1ef-9b3154424021/ui'

        # Construct a json representation of a SparkEngineApplicationStatusCollection model
        spark_engine_application_status_collection_model_json = {}
        spark_engine_application_status_collection_model_json['applications'] = [spark_engine_application_status_model]

        # Construct a model instance of SparkEngineApplicationStatusCollection by calling from_dict on the json representation
        spark_engine_application_status_collection_model = SparkEngineApplicationStatusCollection.from_dict(spark_engine_application_status_collection_model_json)
        assert spark_engine_application_status_collection_model != False

        # Construct a model instance of SparkEngineApplicationStatusCollection by calling from_dict on the json representation
        spark_engine_application_status_collection_model_dict = SparkEngineApplicationStatusCollection.from_dict(spark_engine_application_status_collection_model_json).__dict__
        spark_engine_application_status_collection_model2 = SparkEngineApplicationStatusCollection(**spark_engine_application_status_collection_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_application_status_collection_model == spark_engine_application_status_collection_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_application_status_collection_model_json2 = spark_engine_application_status_collection_model.to_dict()
        assert spark_engine_application_status_collection_model_json2 == spark_engine_application_status_collection_model_json


class TestModel_SparkEngineApplicationStatusRuntime:
    """
    Test Class for SparkEngineApplicationStatusRuntime
    """

    def test_spark_engine_application_status_runtime_serialization(self):
        """
        Test serialization/deserialization for SparkEngineApplicationStatusRuntime
        """

        # Construct a json representation of a SparkEngineApplicationStatusRuntime model
        spark_engine_application_status_runtime_model_json = {}
        spark_engine_application_status_runtime_model_json['spark_version'] = '3.3'

        # Construct a model instance of SparkEngineApplicationStatusRuntime by calling from_dict on the json representation
        spark_engine_application_status_runtime_model = SparkEngineApplicationStatusRuntime.from_dict(spark_engine_application_status_runtime_model_json)
        assert spark_engine_application_status_runtime_model != False

        # Construct a model instance of SparkEngineApplicationStatusRuntime by calling from_dict on the json representation
        spark_engine_application_status_runtime_model_dict = SparkEngineApplicationStatusRuntime.from_dict(spark_engine_application_status_runtime_model_json).__dict__
        spark_engine_application_status_runtime_model2 = SparkEngineApplicationStatusRuntime(**spark_engine_application_status_runtime_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_application_status_runtime_model == spark_engine_application_status_runtime_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_application_status_runtime_model_json2 = spark_engine_application_status_runtime_model.to_dict()
        assert spark_engine_application_status_runtime_model_json2 == spark_engine_application_status_runtime_model_json


class TestModel_SparkEngineApplicationStatusStateDetailsItems:
    """
    Test Class for SparkEngineApplicationStatusStateDetailsItems
    """

    def test_spark_engine_application_status_state_details_items_serialization(self):
        """
        Test serialization/deserialization for SparkEngineApplicationStatusStateDetailsItems
        """

        # Construct a json representation of a SparkEngineApplicationStatusStateDetailsItems model
        spark_engine_application_status_state_details_items_model_json = {}
        spark_engine_application_status_state_details_items_model_json['code'] = 'testString'
        spark_engine_application_status_state_details_items_model_json['message'] = 'testString'
        spark_engine_application_status_state_details_items_model_json['type'] = 'testString'

        # Construct a model instance of SparkEngineApplicationStatusStateDetailsItems by calling from_dict on the json representation
        spark_engine_application_status_state_details_items_model = SparkEngineApplicationStatusStateDetailsItems.from_dict(spark_engine_application_status_state_details_items_model_json)
        assert spark_engine_application_status_state_details_items_model != False

        # Construct a model instance of SparkEngineApplicationStatusStateDetailsItems by calling from_dict on the json representation
        spark_engine_application_status_state_details_items_model_dict = SparkEngineApplicationStatusStateDetailsItems.from_dict(spark_engine_application_status_state_details_items_model_json).__dict__
        spark_engine_application_status_state_details_items_model2 = SparkEngineApplicationStatusStateDetailsItems(**spark_engine_application_status_state_details_items_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_application_status_state_details_items_model == spark_engine_application_status_state_details_items_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_application_status_state_details_items_model_json2 = spark_engine_application_status_state_details_items_model.to_dict()
        assert spark_engine_application_status_state_details_items_model_json2 == spark_engine_application_status_state_details_items_model_json


class TestModel_SparkEngineCollection:
    """
    Test Class for SparkEngineCollection
    """

    def test_spark_engine_collection_serialization(self):
        """
        Test serialization/deserialization for SparkEngineCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_default_config_model = {}  # SparkDefaultConfig
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        spark_endpoints_model = {}  # SparkEndpoints
        spark_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/<spark_id>/spark_applications/<application_id>'
        spark_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/<spark_id>/spark_history_server'
        spark_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        spark_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/<spark_id>/spark_applications'
        spark_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/<spark_id>/jkg/api/kernels'
        spark_endpoints_model['view_history_server'] = 'View history server'
        spark_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/<wxd_instance_id>/engines/<engine_id>/applications'
        spark_endpoints_model['wxd_engine_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817'
        spark_endpoints_model['wxd_history_server_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server'
        spark_endpoints_model['wxd_history_server_ui_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server/ui'

        spark_scale_config_model = {}  # SparkScaleConfig
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'medium'
        spark_scale_config_model['number_of_nodes'] = 2

        spark_engine_details_model = {}  # SparkEngineDetails
        spark_engine_details_model['api_key'] = 'apikey'
        spark_engine_details_model['connection_string'] = 'https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>'
        spark_engine_details_model['default_config'] = spark_default_config_model
        spark_engine_details_model['default_version'] = '4.8.3'
        spark_engine_details_model['endpoints'] = spark_endpoints_model
        spark_engine_details_model['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_model['engine_home_bucket_name'] = 'test-spark-bucket'
        spark_engine_details_model['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_model['engine_home_volume'] = 'test-spark-volume'
        spark_engine_details_model['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_model['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_model['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_model['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_model['instance_id'] = 'spark-id'
        spark_engine_details_model['engine_sub_type'] = 'java/cpp'
        spark_engine_details_model['managed_by'] = 'fully/self'
        spark_engine_details_model['scale_config'] = spark_scale_config_model

        spark_engine_model = {}  # SparkEngine
        spark_engine_model['actions'] = ['update', 'delete']
        spark_engine_model['associated_catalogs'] = ['iceberg_data', 'hive_data']
        spark_engine_model['build_version'] = '1.0.3.0.0'
        spark_engine_model['created_by'] = '<username>@<domain>.com'
        spark_engine_model['created_on'] = 163788384993
        spark_engine_model['description'] = 'Spark engines for running spark applications'
        spark_engine_model['engine_details'] = spark_engine_details_model
        spark_engine_model['engine_display_name'] = 'sampleEngine'
        spark_engine_model['engine_id'] = 'sampleEngine123'
        spark_engine_model['origin'] = 'discover'
        spark_engine_model['status'] = 'REGISTERED'
        spark_engine_model['tags'] = ['tag1', 'tag2']
        spark_engine_model['type'] = 'spark'

        # Construct a json representation of a SparkEngineCollection model
        spark_engine_collection_model_json = {}
        spark_engine_collection_model_json['spark_engines'] = [spark_engine_model]

        # Construct a model instance of SparkEngineCollection by calling from_dict on the json representation
        spark_engine_collection_model = SparkEngineCollection.from_dict(spark_engine_collection_model_json)
        assert spark_engine_collection_model != False

        # Construct a model instance of SparkEngineCollection by calling from_dict on the json representation
        spark_engine_collection_model_dict = SparkEngineCollection.from_dict(spark_engine_collection_model_json).__dict__
        spark_engine_collection_model2 = SparkEngineCollection(**spark_engine_collection_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_collection_model == spark_engine_collection_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_collection_model_json2 = spark_engine_collection_model.to_dict()
        assert spark_engine_collection_model_json2 == spark_engine_collection_model_json


class TestModel_SparkEngineDetails:
    """
    Test Class for SparkEngineDetails
    """

    def test_spark_engine_details_serialization(self):
        """
        Test serialization/deserialization for SparkEngineDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_default_config_model = {}  # SparkDefaultConfig
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        spark_endpoints_model = {}  # SparkEndpoints
        spark_endpoints_model['applications_api'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications/<application_id>'
        spark_endpoints_model['history_server_endpoint'] = '$HOST/v2/spark/v3/instances/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_history_server'
        spark_endpoints_model['spark_access_endpoint'] = '$HOST/analytics-engine/details/spark-<instance_id>'
        spark_endpoints_model['spark_jobs_v4_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/spark_applications'
        spark_endpoints_model['spark_kernel_endpoint'] = '$HOST/v4/analytics_engines/c7b3fccf-badb-46b0-b1ef-9b3154424021/jkg/api/kernels'
        spark_endpoints_model['view_history_server'] = 'testString'
        spark_endpoints_model['wxd_application_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/applications'
        spark_endpoints_model['wxd_engine_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817'
        spark_endpoints_model['wxd_history_server_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server'
        spark_endpoints_model['wxd_history_server_ui_endpoint'] = '$HOST/v1/1698311655308796/engines/spark817/history_server/ui'

        spark_scale_config_model = {}  # SparkScaleConfig
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'medium'
        spark_scale_config_model['number_of_nodes'] = 2

        # Construct a json representation of a SparkEngineDetails model
        spark_engine_details_model_json = {}
        spark_engine_details_model_json['api_key'] = 'apikey'
        spark_engine_details_model_json['connection_string'] = 'https://xyz.<region>.ae.cloud.123.com/v3/analytics-engines/<spark-iae-id>'
        spark_engine_details_model_json['default_config'] = spark_default_config_model
        spark_engine_details_model_json['default_version'] = '4.8.3'
        spark_engine_details_model_json['endpoints'] = spark_endpoints_model
        spark_engine_details_model_json['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_model_json['engine_home_bucket_name'] = 'test-spark-bucket'
        spark_engine_details_model_json['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_model_json['engine_home_volume'] = 'test-spark-volume'
        spark_engine_details_model_json['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_model_json['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_model_json['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_model_json['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_model_json['instance_id'] = 'spark-id'
        spark_engine_details_model_json['engine_sub_type'] = 'java/cpp'
        spark_engine_details_model_json['managed_by'] = 'fully/self'
        spark_engine_details_model_json['scale_config'] = spark_scale_config_model

        # Construct a model instance of SparkEngineDetails by calling from_dict on the json representation
        spark_engine_details_model = SparkEngineDetails.from_dict(spark_engine_details_model_json)
        assert spark_engine_details_model != False

        # Construct a model instance of SparkEngineDetails by calling from_dict on the json representation
        spark_engine_details_model_dict = SparkEngineDetails.from_dict(spark_engine_details_model_json).__dict__
        spark_engine_details_model2 = SparkEngineDetails(**spark_engine_details_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_details_model == spark_engine_details_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_details_model_json2 = spark_engine_details_model.to_dict()
        assert spark_engine_details_model_json2 == spark_engine_details_model_json


class TestModel_SparkEngineDetailsPrototype:
    """
    Test Class for SparkEngineDetailsPrototype
    """

    def test_spark_engine_details_prototype_serialization(self):
        """
        Test serialization/deserialization for SparkEngineDetailsPrototype
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_default_config_model = {}  # SparkDefaultConfig
        spark_default_config_model['config1'] = 'testString'
        spark_default_config_model['config2'] = 'testString'

        spark_scale_config_model = {}  # SparkScaleConfig
        spark_scale_config_model['auto_scale_enabled'] = True
        spark_scale_config_model['current_number_of_nodes'] = 2
        spark_scale_config_model['maximum_number_of_nodes'] = 5
        spark_scale_config_model['minimum_number_of_nodes'] = 1
        spark_scale_config_model['node_type'] = 'medium'
        spark_scale_config_model['number_of_nodes'] = 2

        # Construct a json representation of a SparkEngineDetailsPrototype model
        spark_engine_details_prototype_model_json = {}
        spark_engine_details_prototype_model_json['api_key'] = 'apikey'
        spark_engine_details_prototype_model_json['connection_string'] = '1.2.3.4'
        spark_engine_details_prototype_model_json['default_config'] = spark_default_config_model
        spark_engine_details_prototype_model_json['default_version'] = '4.8.3'
        spark_engine_details_prototype_model_json['engine_home_bucket_display_name'] = 'test-spark-bucket'
        spark_engine_details_prototype_model_json['engine_home_bucket_name'] = 'test-spark-bucket'
        spark_engine_details_prototype_model_json['engine_home_path'] = 'spark/spark1234'
        spark_engine_details_prototype_model_json['engine_home_volume_id'] = '1704979825978585'
        spark_engine_details_prototype_model_json['engine_home_volume_name'] = 'my-volume'
        spark_engine_details_prototype_model_json['engine_home_volume_storage_class'] = 'nfs-client'
        spark_engine_details_prototype_model_json['engine_home_volume_storage_size'] = '5Gi'
        spark_engine_details_prototype_model_json['engine_sub_type'] = 'java/cpp'
        spark_engine_details_prototype_model_json['instance_id'] = 'spark-id'
        spark_engine_details_prototype_model_json['managed_by'] = 'fully/self'
        spark_engine_details_prototype_model_json['scale_config'] = spark_scale_config_model

        # Construct a model instance of SparkEngineDetailsPrototype by calling from_dict on the json representation
        spark_engine_details_prototype_model = SparkEngineDetailsPrototype.from_dict(spark_engine_details_prototype_model_json)
        assert spark_engine_details_prototype_model != False

        # Construct a model instance of SparkEngineDetailsPrototype by calling from_dict on the json representation
        spark_engine_details_prototype_model_dict = SparkEngineDetailsPrototype.from_dict(spark_engine_details_prototype_model_json).__dict__
        spark_engine_details_prototype_model2 = SparkEngineDetailsPrototype(**spark_engine_details_prototype_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_details_prototype_model == spark_engine_details_prototype_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_details_prototype_model_json2 = spark_engine_details_prototype_model.to_dict()
        assert spark_engine_details_prototype_model_json2 == spark_engine_details_prototype_model_json


class TestModel_SparkEngineResourceLimit:
    """
    Test Class for SparkEngineResourceLimit
    """

    def test_spark_engine_resource_limit_serialization(self):
        """
        Test serialization/deserialization for SparkEngineResourceLimit
        """

        # Construct a json representation of a SparkEngineResourceLimit model
        spark_engine_resource_limit_model_json = {}
        spark_engine_resource_limit_model_json['cores'] = '1'
        spark_engine_resource_limit_model_json['memory'] = '4G'

        # Construct a model instance of SparkEngineResourceLimit by calling from_dict on the json representation
        spark_engine_resource_limit_model = SparkEngineResourceLimit.from_dict(spark_engine_resource_limit_model_json)
        assert spark_engine_resource_limit_model != False

        # Construct a model instance of SparkEngineResourceLimit by calling from_dict on the json representation
        spark_engine_resource_limit_model_dict = SparkEngineResourceLimit.from_dict(spark_engine_resource_limit_model_json).__dict__
        spark_engine_resource_limit_model2 = SparkEngineResourceLimit(**spark_engine_resource_limit_model_dict)

        # Verify the model instances are equivalent
        assert spark_engine_resource_limit_model == spark_engine_resource_limit_model2

        # Convert model instance back to dict and verify no loss of data
        spark_engine_resource_limit_model_json2 = spark_engine_resource_limit_model.to_dict()
        assert spark_engine_resource_limit_model_json2 == spark_engine_resource_limit_model_json


class TestModel_SparkHistoryServer:
    """
    Test Class for SparkHistoryServer
    """

    def test_spark_history_server_serialization(self):
        """
        Test serialization/deserialization for SparkHistoryServer
        """

        # Construct a json representation of a SparkHistoryServer model
        spark_history_server_model_json = {}
        spark_history_server_model_json['auto_termination_time'] = '2022-02-24T07:37:47Z'
        spark_history_server_model_json['cores'] = '1'
        spark_history_server_model_json['memory'] = '4G'
        spark_history_server_model_json['start_time'] = '2022-02-21T07:37:47Z'
        spark_history_server_model_json['state'] = 'started'

        # Construct a model instance of SparkHistoryServer by calling from_dict on the json representation
        spark_history_server_model = SparkHistoryServer.from_dict(spark_history_server_model_json)
        assert spark_history_server_model != False

        # Construct a model instance of SparkHistoryServer by calling from_dict on the json representation
        spark_history_server_model_dict = SparkHistoryServer.from_dict(spark_history_server_model_json).__dict__
        spark_history_server_model2 = SparkHistoryServer(**spark_history_server_model_dict)

        # Verify the model instances are equivalent
        assert spark_history_server_model == spark_history_server_model2

        # Convert model instance back to dict and verify no loss of data
        spark_history_server_model_json2 = spark_history_server_model.to_dict()
        assert spark_history_server_model_json2 == spark_history_server_model_json


class TestModel_SparkScaleConfig:
    """
    Test Class for SparkScaleConfig
    """

    def test_spark_scale_config_serialization(self):
        """
        Test serialization/deserialization for SparkScaleConfig
        """

        # Construct a json representation of a SparkScaleConfig model
        spark_scale_config_model_json = {}
        spark_scale_config_model_json['auto_scale_enabled'] = True
        spark_scale_config_model_json['current_number_of_nodes'] = 2
        spark_scale_config_model_json['maximum_number_of_nodes'] = 5
        spark_scale_config_model_json['minimum_number_of_nodes'] = 1
        spark_scale_config_model_json['node_type'] = 'medium'
        spark_scale_config_model_json['number_of_nodes'] = 2

        # Construct a model instance of SparkScaleConfig by calling from_dict on the json representation
        spark_scale_config_model = SparkScaleConfig.from_dict(spark_scale_config_model_json)
        assert spark_scale_config_model != False

        # Construct a model instance of SparkScaleConfig by calling from_dict on the json representation
        spark_scale_config_model_dict = SparkScaleConfig.from_dict(spark_scale_config_model_json).__dict__
        spark_scale_config_model2 = SparkScaleConfig(**spark_scale_config_model_dict)

        # Verify the model instances are equivalent
        assert spark_scale_config_model == spark_scale_config_model2

        # Convert model instance back to dict and verify no loss of data
        spark_scale_config_model_json2 = spark_scale_config_model.to_dict()
        assert spark_scale_config_model_json2 == spark_scale_config_model_json


class TestModel_SparkVersions:
    """
    Test Class for SparkVersions
    """

    def test_spark_versions_serialization(self):
        """
        Test serialization/deserialization for SparkVersions
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_versions_info_response_model = {}  # SparkVersionsInfoResponse
        spark_versions_info_response_model['display_name'] = 'Instance Name'
        spark_versions_info_response_model['value'] = 'Instance Name'

        # Construct a json representation of a SparkVersions model
        spark_versions_model_json = {}
        spark_versions_model_json['cpp'] = [spark_versions_info_response_model]
        spark_versions_model_json['java'] = [spark_versions_info_response_model]

        # Construct a model instance of SparkVersions by calling from_dict on the json representation
        spark_versions_model = SparkVersions.from_dict(spark_versions_model_json)
        assert spark_versions_model != False

        # Construct a model instance of SparkVersions by calling from_dict on the json representation
        spark_versions_model_dict = SparkVersions.from_dict(spark_versions_model_json).__dict__
        spark_versions_model2 = SparkVersions(**spark_versions_model_dict)

        # Verify the model instances are equivalent
        assert spark_versions_model == spark_versions_model2

        # Convert model instance back to dict and verify no loss of data
        spark_versions_model_json2 = spark_versions_model.to_dict()
        assert spark_versions_model_json2 == spark_versions_model_json


class TestModel_SparkVersionsInfoResponse:
    """
    Test Class for SparkVersionsInfoResponse
    """

    def test_spark_versions_info_response_serialization(self):
        """
        Test serialization/deserialization for SparkVersionsInfoResponse
        """

        # Construct a json representation of a SparkVersionsInfoResponse model
        spark_versions_info_response_model_json = {}
        spark_versions_info_response_model_json['display_name'] = 'Instance Name'
        spark_versions_info_response_model_json['value'] = 'Instance Name'

        # Construct a model instance of SparkVersionsInfoResponse by calling from_dict on the json representation
        spark_versions_info_response_model = SparkVersionsInfoResponse.from_dict(spark_versions_info_response_model_json)
        assert spark_versions_info_response_model != False

        # Construct a model instance of SparkVersionsInfoResponse by calling from_dict on the json representation
        spark_versions_info_response_model_dict = SparkVersionsInfoResponse.from_dict(spark_versions_info_response_model_json).__dict__
        spark_versions_info_response_model2 = SparkVersionsInfoResponse(**spark_versions_info_response_model_dict)

        # Verify the model instances are equivalent
        assert spark_versions_info_response_model == spark_versions_info_response_model2

        # Convert model instance back to dict and verify no loss of data
        spark_versions_info_response_model_json2 = spark_versions_info_response_model.to_dict()
        assert spark_versions_info_response_model_json2 == spark_versions_info_response_model_json


class TestModel_SparkVolumeDetails:
    """
    Test Class for SparkVolumeDetails
    """

    def test_spark_volume_details_serialization(self):
        """
        Test serialization/deserialization for SparkVolumeDetails
        """

        # Construct a json representation of a SparkVolumeDetails model
        spark_volume_details_model_json = {}
        spark_volume_details_model_json['mount_path'] = '/mount/path'
        spark_volume_details_model_json['name'] = 'my-volume'
        spark_volume_details_model_json['read_only'] = True
        spark_volume_details_model_json['source_sub_path'] = '/source/path'

        # Construct a model instance of SparkVolumeDetails by calling from_dict on the json representation
        spark_volume_details_model = SparkVolumeDetails.from_dict(spark_volume_details_model_json)
        assert spark_volume_details_model != False

        # Construct a model instance of SparkVolumeDetails by calling from_dict on the json representation
        spark_volume_details_model_dict = SparkVolumeDetails.from_dict(spark_volume_details_model_json).__dict__
        spark_volume_details_model2 = SparkVolumeDetails(**spark_volume_details_model_dict)

        # Verify the model instances are equivalent
        assert spark_volume_details_model == spark_volume_details_model2

        # Convert model instance back to dict and verify no loss of data
        spark_volume_details_model_json2 = spark_volume_details_model.to_dict()
        assert spark_volume_details_model_json2 == spark_volume_details_model_json


class TestModel_StorageDetails:
    """
    Test Class for StorageDetails
    """

    def test_storage_details_serialization(self):
        """
        Test serialization/deserialization for StorageDetails
        """

        # Construct a json representation of a StorageDetails model
        storage_details_model_json = {}
        storage_details_model_json['access_key'] = '<access_key>'
        storage_details_model_json['application_id'] = '<application_id>'
        storage_details_model_json['auth_mode'] = '<account_key/sas/service_principle>'
        storage_details_model_json['container_name'] = 'sample-container'
        storage_details_model_json['directory_id'] = '<directory_id>'
        storage_details_model_json['endpoint'] = 'abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/'
        storage_details_model_json['sas_token'] = '<sas_token>'
        storage_details_model_json['secret_key'] = 'secret_key'
        storage_details_model_json['storage_account_name'] = 'sample-storage'

        # Construct a model instance of StorageDetails by calling from_dict on the json representation
        storage_details_model = StorageDetails.from_dict(storage_details_model_json)
        assert storage_details_model != False

        # Construct a model instance of StorageDetails by calling from_dict on the json representation
        storage_details_model_dict = StorageDetails.from_dict(storage_details_model_json).__dict__
        storage_details_model2 = StorageDetails(**storage_details_model_dict)

        # Verify the model instances are equivalent
        assert storage_details_model == storage_details_model2

        # Convert model instance back to dict and verify no loss of data
        storage_details_model_json2 = storage_details_model.to_dict()
        assert storage_details_model_json2 == storage_details_model_json


class TestModel_SuccessResponse:
    """
    Test Class for SuccessResponse
    """

    def test_success_response_serialization(self):
        """
        Test serialization/deserialization for SuccessResponse
        """

        # Construct a json representation of a SuccessResponse model
        success_response_model_json = {}
        success_response_model_json['message'] = 'testString'
        success_response_model_json['message_code'] = 'testString'

        # Construct a model instance of SuccessResponse by calling from_dict on the json representation
        success_response_model = SuccessResponse.from_dict(success_response_model_json)
        assert success_response_model != False

        # Construct a model instance of SuccessResponse by calling from_dict on the json representation
        success_response_model_dict = SuccessResponse.from_dict(success_response_model_json).__dict__
        success_response_model2 = SuccessResponse(**success_response_model_dict)

        # Verify the model instances are equivalent
        assert success_response_model == success_response_model2

        # Convert model instance back to dict and verify no loss of data
        success_response_model_json2 = success_response_model.to_dict()
        assert success_response_model_json2 == success_response_model_json


class TestModel_SyncCatalogs:
    """
    Test Class for SyncCatalogs
    """

    def test_sync_catalogs_serialization(self):
        """
        Test serialization/deserialization for SyncCatalogs
        """

        # Construct a json representation of a SyncCatalogs model
        sync_catalogs_model_json = {}
        sync_catalogs_model_json['auto_add_new_tables'] = True
        sync_catalogs_model_json['sync_iceberg_md'] = True

        # Construct a model instance of SyncCatalogs by calling from_dict on the json representation
        sync_catalogs_model = SyncCatalogs.from_dict(sync_catalogs_model_json)
        assert sync_catalogs_model != False

        # Construct a model instance of SyncCatalogs by calling from_dict on the json representation
        sync_catalogs_model_dict = SyncCatalogs.from_dict(sync_catalogs_model_json).__dict__
        sync_catalogs_model2 = SyncCatalogs(**sync_catalogs_model_dict)

        # Verify the model instances are equivalent
        assert sync_catalogs_model == sync_catalogs_model2

        # Convert model instance back to dict and verify no loss of data
        sync_catalogs_model_json2 = sync_catalogs_model.to_dict()
        assert sync_catalogs_model_json2 == sync_catalogs_model_json


class TestModel_Table:
    """
    Test Class for Table
    """

    def test_table_serialization(self):
        """
        Test serialization/deserialization for Table
        """

        # Construct dict forms of any model objects needed in order to build this model.

        column_model = {}  # Column
        column_model['column_name'] = 'expenses'
        column_model['comment'] = 'testString'
        column_model['extra'] = 'testString'
        column_model['length'] = '30'
        column_model['precision'] = '1234567890'
        column_model['scale'] = '2'
        column_model['type'] = 'varchar'

        # Construct a json representation of a Table model
        table_model_json = {}
        table_model_json['columns'] = [column_model]
        table_model_json['table_name'] = 'testString'

        # Construct a model instance of Table by calling from_dict on the json representation
        table_model = Table.from_dict(table_model_json)
        assert table_model != False

        # Construct a model instance of Table by calling from_dict on the json representation
        table_model_dict = Table.from_dict(table_model_json).__dict__
        table_model2 = Table(**table_model_dict)

        # Verify the model instances are equivalent
        assert table_model == table_model2

        # Convert model instance back to dict and verify no loss of data
        table_model_json2 = table_model.to_dict()
        assert table_model_json2 == table_model_json


class TestModel_TableCollection:
    """
    Test Class for TableCollection
    """

    def test_table_collection_serialization(self):
        """
        Test serialization/deserialization for TableCollection
        """

        # Construct a json representation of a TableCollection model
        table_collection_model_json = {}
        table_collection_model_json['tables'] = ['testString']

        # Construct a model instance of TableCollection by calling from_dict on the json representation
        table_collection_model = TableCollection.from_dict(table_collection_model_json)
        assert table_collection_model != False

        # Construct a model instance of TableCollection by calling from_dict on the json representation
        table_collection_model_dict = TableCollection.from_dict(table_collection_model_json).__dict__
        table_collection_model2 = TableCollection(**table_collection_model_dict)

        # Verify the model instances are equivalent
        assert table_collection_model == table_collection_model2

        # Convert model instance back to dict and verify no loss of data
        table_collection_model_json2 = table_collection_model.to_dict()
        assert table_collection_model_json2 == table_collection_model_json


class TestModel_TableColumDetail:
    """
    Test Class for TableColumDetail
    """

    def test_table_colum_detail_serialization(self):
        """
        Test serialization/deserialization for TableColumDetail
        """

        # Construct dict forms of any model objects needed in order to build this model.

        table_colum_detail_columns_items_model = {}  # TableColumDetailColumnsItems
        table_colum_detail_columns_items_model['column'] = 'testString'
        table_colum_detail_columns_items_model['index'] = 38
        table_colum_detail_columns_items_model['type'] = 'testString'

        # Construct a json representation of a TableColumDetail model
        table_colum_detail_model_json = {}
        table_colum_detail_model_json['bucket'] = 'testString'
        table_colum_detail_model_json['catalog'] = 'testString'
        table_colum_detail_model_json['columns'] = [table_colum_detail_columns_items_model]
        table_colum_detail_model_json['owner'] = 'testString'
        table_colum_detail_model_json['schema'] = 'testString'
        table_colum_detail_model_json['table'] = 'testString'

        # Construct a model instance of TableColumDetail by calling from_dict on the json representation
        table_colum_detail_model = TableColumDetail.from_dict(table_colum_detail_model_json)
        assert table_colum_detail_model != False

        # Construct a model instance of TableColumDetail by calling from_dict on the json representation
        table_colum_detail_model_dict = TableColumDetail.from_dict(table_colum_detail_model_json).__dict__
        table_colum_detail_model2 = TableColumDetail(**table_colum_detail_model_dict)

        # Verify the model instances are equivalent
        assert table_colum_detail_model == table_colum_detail_model2

        # Convert model instance back to dict and verify no loss of data
        table_colum_detail_model_json2 = table_colum_detail_model.to_dict()
        assert table_colum_detail_model_json2 == table_colum_detail_model_json


class TestModel_TableColumDetailColumnsItems:
    """
    Test Class for TableColumDetailColumnsItems
    """

    def test_table_colum_detail_columns_items_serialization(self):
        """
        Test serialization/deserialization for TableColumDetailColumnsItems
        """

        # Construct a json representation of a TableColumDetailColumnsItems model
        table_colum_detail_columns_items_model_json = {}
        table_colum_detail_columns_items_model_json['column'] = 'testString'
        table_colum_detail_columns_items_model_json['index'] = 38
        table_colum_detail_columns_items_model_json['type'] = 'testString'

        # Construct a model instance of TableColumDetailColumnsItems by calling from_dict on the json representation
        table_colum_detail_columns_items_model = TableColumDetailColumnsItems.from_dict(table_colum_detail_columns_items_model_json)
        assert table_colum_detail_columns_items_model != False

        # Construct a model instance of TableColumDetailColumnsItems by calling from_dict on the json representation
        table_colum_detail_columns_items_model_dict = TableColumDetailColumnsItems.from_dict(table_colum_detail_columns_items_model_json).__dict__
        table_colum_detail_columns_items_model2 = TableColumDetailColumnsItems(**table_colum_detail_columns_items_model_dict)

        # Verify the model instances are equivalent
        assert table_colum_detail_columns_items_model == table_colum_detail_columns_items_model2

        # Convert model instance back to dict and verify no loss of data
        table_colum_detail_columns_items_model_json2 = table_colum_detail_columns_items_model.to_dict()
        assert table_colum_detail_columns_items_model_json2 == table_colum_detail_columns_items_model_json


class TestModel_TablePatch:
    """
    Test Class for TablePatch
    """

    def test_table_patch_serialization(self):
        """
        Test serialization/deserialization for TablePatch
        """

        # Construct a json representation of a TablePatch model
        table_patch_model_json = {}
        table_patch_model_json['table_name'] = 'updated_table_name'

        # Construct a model instance of TablePatch by calling from_dict on the json representation
        table_patch_model = TablePatch.from_dict(table_patch_model_json)
        assert table_patch_model != False

        # Construct a model instance of TablePatch by calling from_dict on the json representation
        table_patch_model_dict = TablePatch.from_dict(table_patch_model_json).__dict__
        table_patch_model2 = TablePatch(**table_patch_model_dict)

        # Verify the model instances are equivalent
        assert table_patch_model == table_patch_model2

        # Convert model instance back to dict and verify no loss of data
        table_patch_model_json2 = table_patch_model.to_dict()
        assert table_patch_model_json2 == table_patch_model_json


class TestModel_TableResponse:
    """
    Test Class for TableResponse
    """

    def test_table_response_serialization(self):
        """
        Test serialization/deserialization for TableResponse
        """

        # Construct dict forms of any model objects needed in order to build this model.

        table_colum_detail_columns_items_model = {}  # TableColumDetailColumnsItems
        table_colum_detail_columns_items_model['column'] = 'club_name'
        table_colum_detail_columns_items_model['index'] = 38
        table_colum_detail_columns_items_model['type'] = 'string'

        table_colum_detail_model = {}  # TableColumDetail
        table_colum_detail_model['bucket'] = 'iceberg-bucket'
        table_colum_detail_model['catalog'] = 'iceberg_data'
        table_colum_detail_model['columns'] = [table_colum_detail_columns_items_model]
        table_colum_detail_model['owner'] = 'ibmlhadmin'
        table_colum_detail_model['schema'] = 's3'
        table_colum_detail_model['table'] = 'clubs'

        # Construct a json representation of a TableResponse model
        table_response_model_json = {}
        table_response_model_json['message'] = 'testString'
        table_response_model_json['message_code'] = 'testString'
        table_response_model_json['tables'] = [table_colum_detail_model]

        # Construct a model instance of TableResponse by calling from_dict on the json representation
        table_response_model = TableResponse.from_dict(table_response_model_json)
        assert table_response_model != False

        # Construct a model instance of TableResponse by calling from_dict on the json representation
        table_response_model_dict = TableResponse.from_dict(table_response_model_json).__dict__
        table_response_model2 = TableResponse(**table_response_model_dict)

        # Verify the model instances are equivalent
        assert table_response_model == table_response_model2

        # Convert model instance back to dict and verify no loss of data
        table_response_model_json2 = table_response_model.to_dict()
        assert table_response_model_json2 == table_response_model_json


class TestModel_TableResponseCollection:
    """
    Test Class for TableResponseCollection
    """

    def test_table_response_collection_serialization(self):
        """
        Test serialization/deserialization for TableResponseCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        table_colum_detail_columns_items_model = {}  # TableColumDetailColumnsItems
        table_colum_detail_columns_items_model['column'] = 'testString'
        table_colum_detail_columns_items_model['index'] = 38
        table_colum_detail_columns_items_model['type'] = 'testString'

        table_colum_detail_model = {}  # TableColumDetail
        table_colum_detail_model['bucket'] = 'testString'
        table_colum_detail_model['catalog'] = 'testString'
        table_colum_detail_model['columns'] = [table_colum_detail_columns_items_model]
        table_colum_detail_model['owner'] = 'testString'
        table_colum_detail_model['schema'] = 'testString'
        table_colum_detail_model['table'] = 'testString'

        table_response_model = {}  # TableResponse
        table_response_model['message'] = 'testString'
        table_response_model['message_code'] = 'testString'
        table_response_model['tables'] = [table_colum_detail_model]

        # Construct a json representation of a TableResponseCollection model
        table_response_collection_model_json = {}
        table_response_collection_model_json['message'] = 'testString'
        table_response_collection_model_json['message_code'] = 'testString'
        table_response_collection_model_json['tables'] = [table_response_model]

        # Construct a model instance of TableResponseCollection by calling from_dict on the json representation
        table_response_collection_model = TableResponseCollection.from_dict(table_response_collection_model_json)
        assert table_response_collection_model != False

        # Construct a model instance of TableResponseCollection by calling from_dict on the json representation
        table_response_collection_model_dict = TableResponseCollection.from_dict(table_response_collection_model_json).__dict__
        table_response_collection_model2 = TableResponseCollection(**table_response_collection_model_dict)

        # Verify the model instances are equivalent
        assert table_response_collection_model == table_response_collection_model2

        # Convert model instance back to dict and verify no loss of data
        table_response_collection_model_json2 = table_response_collection_model.to_dict()
        assert table_response_collection_model_json2 == table_response_collection_model_json


class TestModel_TableSnapshot:
    """
    Test Class for TableSnapshot
    """

    def test_table_snapshot_serialization(self):
        """
        Test serialization/deserialization for TableSnapshot
        """

        # Construct a json representation of a TableSnapshot model
        table_snapshot_model_json = {}
        table_snapshot_model_json['added_data_files'] = '1'
        table_snapshot_model_json['added_files_size'] = '17425'
        table_snapshot_model_json['added_records'] = '3277'
        table_snapshot_model_json['changed_partition_count'] = '1'
        table_snapshot_model_json['committed_at'] = '1609379392'
        table_snapshot_model_json['operation'] = 'alter'
        table_snapshot_model_json['snapshot_id'] = '2332342122211222'
        table_snapshot_model_json['total_data_files'] = '2'
        table_snapshot_model_json['total_delete_files'] = '0'
        table_snapshot_model_json['total_equality_deletes'] = '0'
        table_snapshot_model_json['total_position_deletes'] = '0'
        table_snapshot_model_json['total_records'] = '5000'

        # Construct a model instance of TableSnapshot by calling from_dict on the json representation
        table_snapshot_model = TableSnapshot.from_dict(table_snapshot_model_json)
        assert table_snapshot_model != False

        # Construct a model instance of TableSnapshot by calling from_dict on the json representation
        table_snapshot_model_dict = TableSnapshot.from_dict(table_snapshot_model_json).__dict__
        table_snapshot_model2 = TableSnapshot(**table_snapshot_model_dict)

        # Verify the model instances are equivalent
        assert table_snapshot_model == table_snapshot_model2

        # Convert model instance back to dict and verify no loss of data
        table_snapshot_model_json2 = table_snapshot_model.to_dict()
        assert table_snapshot_model_json2 == table_snapshot_model_json


class TestModel_TableSnapshotCollection:
    """
    Test Class for TableSnapshotCollection
    """

    def test_table_snapshot_collection_serialization(self):
        """
        Test serialization/deserialization for TableSnapshotCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        table_snapshot_model = {}  # TableSnapshot
        table_snapshot_model['added_data_files'] = '1'
        table_snapshot_model['added_files_size'] = '17425'
        table_snapshot_model['added_records'] = '3277'
        table_snapshot_model['changed_partition_count'] = '1'
        table_snapshot_model['committed_at'] = '1609379392'
        table_snapshot_model['operation'] = 'alter'
        table_snapshot_model['snapshot_id'] = '2332342122211222'
        table_snapshot_model['total_data_files'] = '2'
        table_snapshot_model['total_delete_files'] = '0'
        table_snapshot_model['total_equality_deletes'] = '0'
        table_snapshot_model['total_position_deletes'] = '0'
        table_snapshot_model['total_records'] = '5000'

        # Construct a json representation of a TableSnapshotCollection model
        table_snapshot_collection_model_json = {}
        table_snapshot_collection_model_json['snapshots'] = [table_snapshot_model]

        # Construct a model instance of TableSnapshotCollection by calling from_dict on the json representation
        table_snapshot_collection_model = TableSnapshotCollection.from_dict(table_snapshot_collection_model_json)
        assert table_snapshot_collection_model != False

        # Construct a model instance of TableSnapshotCollection by calling from_dict on the json representation
        table_snapshot_collection_model_dict = TableSnapshotCollection.from_dict(table_snapshot_collection_model_json).__dict__
        table_snapshot_collection_model2 = TableSnapshotCollection(**table_snapshot_collection_model_dict)

        # Verify the model instances are equivalent
        assert table_snapshot_collection_model == table_snapshot_collection_model2

        # Convert model instance back to dict and verify no loss of data
        table_snapshot_collection_model_json2 = table_snapshot_collection_model.to_dict()
        assert table_snapshot_collection_model_json2 == table_snapshot_collection_model_json


class TestModel_UpdateSparkEngineBody:
    """
    Test Class for UpdateSparkEngineBody
    """

    def test_update_spark_engine_body_serialization(self):
        """
        Test serialization/deserialization for UpdateSparkEngineBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_engine_resource_limit_model = {}  # SparkEngineResourceLimit
        spark_engine_resource_limit_model['cores'] = '1'
        spark_engine_resource_limit_model['memory'] = '4G'

        update_spark_engine_body_engine_details_model = {}  # UpdateSparkEngineBodyEngineDetails
        update_spark_engine_body_engine_details_model['default_config'] = {'key1': 'testString'}
        update_spark_engine_body_engine_details_model['default_version'] = '4.8.3'
        update_spark_engine_body_engine_details_model['engine_home_bucket_name'] = 'test-spark-bucket'
        update_spark_engine_body_engine_details_model['resource_limit_enabled'] = True
        update_spark_engine_body_engine_details_model['resource_limits'] = spark_engine_resource_limit_model

        # Construct a json representation of a UpdateSparkEngineBody model
        update_spark_engine_body_model_json = {}
        update_spark_engine_body_model_json['description'] = 'updated description for spark engine'
        update_spark_engine_body_model_json['engine_details'] = update_spark_engine_body_engine_details_model
        update_spark_engine_body_model_json['engine_display_name'] = 'sampleEngine'
        update_spark_engine_body_model_json['tags'] = ['tag1', 'tag2']

        # Construct a model instance of UpdateSparkEngineBody by calling from_dict on the json representation
        update_spark_engine_body_model = UpdateSparkEngineBody.from_dict(update_spark_engine_body_model_json)
        assert update_spark_engine_body_model != False

        # Construct a model instance of UpdateSparkEngineBody by calling from_dict on the json representation
        update_spark_engine_body_model_dict = UpdateSparkEngineBody.from_dict(update_spark_engine_body_model_json).__dict__
        update_spark_engine_body_model2 = UpdateSparkEngineBody(**update_spark_engine_body_model_dict)

        # Verify the model instances are equivalent
        assert update_spark_engine_body_model == update_spark_engine_body_model2

        # Convert model instance back to dict and verify no loss of data
        update_spark_engine_body_model_json2 = update_spark_engine_body_model.to_dict()
        assert update_spark_engine_body_model_json2 == update_spark_engine_body_model_json


class TestModel_UpdateSparkEngineBodyEngineDetails:
    """
    Test Class for UpdateSparkEngineBodyEngineDetails
    """

    def test_update_spark_engine_body_engine_details_serialization(self):
        """
        Test serialization/deserialization for UpdateSparkEngineBodyEngineDetails
        """

        # Construct dict forms of any model objects needed in order to build this model.

        spark_engine_resource_limit_model = {}  # SparkEngineResourceLimit
        spark_engine_resource_limit_model['cores'] = '1'
        spark_engine_resource_limit_model['memory'] = '4G'

        # Construct a json representation of a UpdateSparkEngineBodyEngineDetails model
        update_spark_engine_body_engine_details_model_json = {}
        update_spark_engine_body_engine_details_model_json['default_config'] = {'key1': 'testString'}
        update_spark_engine_body_engine_details_model_json['default_version'] = '4.8.3'
        update_spark_engine_body_engine_details_model_json['engine_home_bucket_name'] = 'test-spark-bucket'
        update_spark_engine_body_engine_details_model_json['resource_limit_enabled'] = True
        update_spark_engine_body_engine_details_model_json['resource_limits'] = spark_engine_resource_limit_model

        # Construct a model instance of UpdateSparkEngineBodyEngineDetails by calling from_dict on the json representation
        update_spark_engine_body_engine_details_model = UpdateSparkEngineBodyEngineDetails.from_dict(update_spark_engine_body_engine_details_model_json)
        assert update_spark_engine_body_engine_details_model != False

        # Construct a model instance of UpdateSparkEngineBodyEngineDetails by calling from_dict on the json representation
        update_spark_engine_body_engine_details_model_dict = UpdateSparkEngineBodyEngineDetails.from_dict(update_spark_engine_body_engine_details_model_json).__dict__
        update_spark_engine_body_engine_details_model2 = UpdateSparkEngineBodyEngineDetails(**update_spark_engine_body_engine_details_model_dict)

        # Verify the model instances are equivalent
        assert update_spark_engine_body_engine_details_model == update_spark_engine_body_engine_details_model2

        # Convert model instance back to dict and verify no loss of data
        update_spark_engine_body_engine_details_model_json2 = update_spark_engine_body_engine_details_model.to_dict()
        assert update_spark_engine_body_engine_details_model_json2 == update_spark_engine_body_engine_details_model_json


class TestModel_UpdateSyncCatalogOKBody:
    """
    Test Class for UpdateSyncCatalogOKBody
    """

    def test_update_sync_catalog_ok_body_serialization(self):
        """
        Test serialization/deserialization for UpdateSyncCatalogOKBody
        """

        # Construct dict forms of any model objects needed in order to build this model.

        success_response_model = {}  # SuccessResponse
        success_response_model['message'] = 'sync catalog'
        success_response_model['message_code'] = 'success'

        # Construct a json representation of a UpdateSyncCatalogOKBody model
        update_sync_catalog_ok_body_model_json = {}
        update_sync_catalog_ok_body_model_json['response'] = success_response_model

        # Construct a model instance of UpdateSyncCatalogOKBody by calling from_dict on the json representation
        update_sync_catalog_ok_body_model = UpdateSyncCatalogOKBody.from_dict(update_sync_catalog_ok_body_model_json)
        assert update_sync_catalog_ok_body_model != False

        # Construct a model instance of UpdateSyncCatalogOKBody by calling from_dict on the json representation
        update_sync_catalog_ok_body_model_dict = UpdateSyncCatalogOKBody.from_dict(update_sync_catalog_ok_body_model_json).__dict__
        update_sync_catalog_ok_body_model2 = UpdateSyncCatalogOKBody(**update_sync_catalog_ok_body_model_dict)

        # Verify the model instances are equivalent
        assert update_sync_catalog_ok_body_model == update_sync_catalog_ok_body_model2

        # Convert model instance back to dict and verify no loss of data
        update_sync_catalog_ok_body_model_json2 = update_sync_catalog_ok_body_model.to_dict()
        assert update_sync_catalog_ok_body_model_json2 == update_sync_catalog_ok_body_model_json


class TestModel_WatsonxInstanceDetailsCollection:
    """
    Test Class for WatsonxInstanceDetailsCollection
    """

    def test_watsonx_instance_details_collection_serialization(self):
        """
        Test serialization/deserialization for WatsonxInstanceDetailsCollection
        """

        # Construct dict forms of any model objects needed in order to build this model.

        external_details_model = {}  # ExternalDetails
        external_details_model['port'] = 443
        external_details_model['hostname'] = 'presto-java1-external-hostname'

        internal_details_model = {}  # InternalDetails
        internal_details_model['port'] = 4553
        internal_details_model['hostname'] = 'internal hostname'

        jdbc_thrift_urls_model = {}  # JdbcThriftUrls
        jdbc_thrift_urls_model['external'] = 'thrift://username:password@metastore1-internal-hostname:9083'
        jdbc_thrift_urls_model['internal'] = 'thrift://username:password@metastore1-internal-hostname:9083'

        details_model = {}  # Details
        details_model['ca_certificate'] = 'sample ca certificate'
        details_model['default_configs'] = {'key1': 'testString'}
        details_model['external'] = external_details_model
        details_model['grpc_api_endpoint'] = internal_details_model
        details_model['hostname'] = 'sample hostname'
        details_model['id'] = 'presto-java1-id'
        details_model['instance_crn'] = 'sample instance CRN'
        details_model['instance_id'] = 'sample instance ID'
        details_model['internal'] = internal_details_model
        details_model['jdbc_class'] = 'com.facebook.presto.jdbc.PrestoDriver'
        details_model['jdbc_urls'] = jdbc_thrift_urls_model
        details_model['name'] = 'PrestoJava1'
        details_model['port'] = 4553
        details_model['rest_api_endpoint'] = internal_details_model
        details_model['spark_engine_endpoint'] = 'Spark Engine endpoint'
        details_model['ssl_certificate'] = 'sample ssl certificate'
        details_model['thrift_urls'] = jdbc_thrift_urls_model
        details_model['version'] = 'Java'
        details_model['watsonx_data_application_endpoint'] = 'sample application end point'

        engine_service_details_collection_model = {}  # EngineServiceDetailsCollection
        engine_service_details_collection_model['details'] = [details_model]
        engine_service_details_collection_model['type'] = 'Presto'

        # Construct a json representation of a WatsonxInstanceDetailsCollection model
        watsonx_instance_details_collection_model_json = {}
        watsonx_instance_details_collection_model_json['engines_services'] = [engine_service_details_collection_model]
        watsonx_instance_details_collection_model_json['watsonx_data_instance'] = details_model

        # Construct a model instance of WatsonxInstanceDetailsCollection by calling from_dict on the json representation
        watsonx_instance_details_collection_model = WatsonxInstanceDetailsCollection.from_dict(watsonx_instance_details_collection_model_json)
        assert watsonx_instance_details_collection_model != False

        # Construct a model instance of WatsonxInstanceDetailsCollection by calling from_dict on the json representation
        watsonx_instance_details_collection_model_dict = WatsonxInstanceDetailsCollection.from_dict(watsonx_instance_details_collection_model_json).__dict__
        watsonx_instance_details_collection_model2 = WatsonxInstanceDetailsCollection(**watsonx_instance_details_collection_model_dict)

        # Verify the model instances are equivalent
        assert watsonx_instance_details_collection_model == watsonx_instance_details_collection_model2

        # Convert model instance back to dict and verify no loss of data
        watsonx_instance_details_collection_model_json2 = watsonx_instance_details_collection_model.to_dict()
        assert watsonx_instance_details_collection_model_json2 == watsonx_instance_details_collection_model_json


# endregion
##############################################################################
# End of Model Tests
##############################################################################
